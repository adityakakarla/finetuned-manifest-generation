{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "print('==========================================================')\nprint(\"Loading libraries: optparse, Matrix, dplyr, pagoda2, conos, conosPanel\")\nlibrary(\"optparse\")\nlibrary(\"Matrix\")\nlibrary(\"dplyr\")\nlibrary(\"pagoda2\")\nlibrary(\"conos\")\nlibrary(\"conosPanel\")\nprint(\"Loaded libraries: optparse, Matrix, dplyr, pagoda2, conos, conosPanel\")\nprint('==========================================================')\noptions(ggrepel.max.overlaps = Inf)\n\n# # ====================================\n\n# # PARAMETERS for Leiden communities and walktrap\n# runleiden <- TRUE\n# leiden_resolution = 1\n# runwalktrap <- TRUE\n# walktrap_steps = 10\n# # ====================================\n# # PARAMETERS for UMAP\n# umap_distance = 0.05\n# umap_spread = 5\n# # ====================================\n\n# Parse input arguments\nparser = OptionParser()\n# ====================================\nparser <- add_option(parser, c(\"--conos_object\"), help = \"RDS file created by Conos.Cluster.\")\nparser <- add_option(parser, c(\"--output_file_name\"),type='character',default='ConosMarkers', help = \"Basename of the file to be saved.\")\n# ====================================\n# PARAMETERS for Leiden\nparser <- add_option(parser, c(\"--genesofinterest\"),type='character',default='', help = \"A list of gene identifiers. The expression of these genes will be plotted on the embedded map. Gene names need to be separated by a coma and a space (e.g. MS4A1, CD74, LYZ, CD14)\")\nparser <- add_option(parser, c(\"--clustering\"),type='character', default='None', help = \"Option to show clustering information besides gene expression (none, leiden, walktrap, both).\")\n# ====================================\nprint('==========================================================')\nargs <- parse_args(parser)\nprint('Parameters used:')\nprint(args)\nprint('==========================================================')\n# ====================================\n# Setting up the PDF file for the plots\n# pdf(file=paste(args$output_file_name,'.pdf',sep=''))\n\n# Restore the object\n\n#Begin 2021-11-24\n\n# {\n#   \"geneofinterest\": { \"name\": \"Gene Identifier:\", \"description\": \"A gene identifier to plot expression on the embedded map (e.g. MS4A1, CD74)\", \"type\": \"text\"}, \n#   \"clustering\": { \"name\": \"Show Clustering:\", \"description\": \"Option to show clustering information beside gene expression\", \"type\": \"choice\", \"choices\": {\"None\": \"none\", \"Show Leiden\": \"leiden\", \"Show Walktrap\": \"walktrap\", \"Show Both Leiden and Walktrap\": \"both\"}, \"default\": \"none\"},  \n#   \"output_var\": { \"hide\": \"True\" } }}\n\ncustomplot <- function(geneofinterest,clustering){\n    cat(paste(\"\u21b3Creating graphs for gene \", geneofinterest,'...', sep=''))\n    \n    if (clustering == \"none\"){\n    print(con$plotPanel(color.by='gene', gene=paste0(geneofinterest), embedding=embeddings))}\n\n    if (runleiden == TRUE & clustering == \"leiden\"){\n    print(cowplot::plot_grid(con$plotPanel(alpha=0.1, clustering='leiden', embedding=embeddings),\n                             con$plotPanel(color.by='gene', gene=paste0(geneofinterest), embedding=embeddings))\n                 )}\n\n    if (runwalktrap == TRUE & clustering == \"walktrap\"){\n#     pdf(paste0(\"Walktrap_Clusters_with_\",geneofinterest,\"_Expression.pdf\"), width=14.88, height=8.2)\n#     cowplot::plot_grid(con$plotPanel(alpha=0.1, clustering='walktrap', embedding=embeddings),\n#                        con$plotPanel(alpha=0.1, color.by='gene', gene=paste0(geneofinterest), embedding=embeddings))\n#     dev.off()\n    print(cowplot::plot_grid(con$plotPanel(alpha=0.1, clustering='walktrap'),\n    con$plotPanel(color.by='gene', gene=paste0(geneofinterest), embedding=embeddings)))}\n\n    if (runleiden == TRUE & runwalktrap == TRUE & clustering == \"both\"){\n#     pdf(paste0(\"Leiden_and_Walktrap_Clusters_with_\",geneofinterest,\"_Expression.pdf\"), width=14.88, height=8.2)\n#     cowplot::plot_grid(con$plotPanel(alpha=0.1, clustering='leiden', embedding=\"umap\"), \n#                        con$plotPanel(alpha=0.1, clustering='walktrap', embedding=\"umap\"),\n#     con$plotPanel(alpha=0.1, color.by='gene', embedding=\"umap\", gene=paste0(geneofinterest)))\n#     dev.off()\n    print(cowplot::plot_grid(con$plotPanel(alpha=0.1, clustering='leiden', embedding=embeddings), \n                             con$plotPanel(alpha=0.1, clustering='walktrap', embedding=embeddings),\n                             con$plotPanel(color.by='gene', gene=paste0(geneofinterest), embedding=embeddings))\n\n         )}\n    print(\"... done!\")\n    return()\n}\n\n# print(R.Version())\ncat('Reading Conos.Cluster output RDS (this may take about a minute)...')\n\nconos_object <- readRDS(file = args$conos_object)  # reads in a varaible called 'conos_object'\n# con <- conos_object$con\n# con_space <- conos_object$con_space\n# data_source <- conos_object$data_source\nprint('...done!')\ncat('Loading variables into memory...')\ncon <- conos_object$con\npaintcluster <- conos_object$paintcluster\nrunleiden <- conos_object$runleiden\nrunwalktrap <- conos_object$runwalktrap\ndata_source <- conos_object$data_source\n\nif (\"Pagoda2\" %in% class(con$samples[[1]])) {\n embeddings <- NULL\n} else {\n if (!is.null(con$samples[[1]]@reductions$umap)) {\n  embeddings <- \"umap\"\n } else {\n  embeddings <- \"tsne\"\n }\n}\n\nprint('...done!')\nprint('Making polots now...')\n# Run for each gene in the list\nfor (gene in unlist(strsplit(args$genesofinterest, ', '))){\n  \n  if (args$clustering == \"none\"){\n    png(file=paste(args$output_file_name,'_',gene,'.png',sep=''), width = 1600, height = 1600)\n  } else if (runleiden == TRUE & runwalktrap == TRUE & args$clustering == \"both\"){\n    png(file=paste(args$output_file_name,'_',gene,'.png',sep=''), width = 1600, height = 1600)\n  }else{\n    png(file=paste(args$output_file_name,'_',gene,'.png',sep=''), width = 1600, height = 900)\n  }\n  customplot(gene,args$clustering)\n  dev.off()\n}\nprint('...done!')"}, {"role": "assistant", "content": "#Conos.VisualizeGeneExpression\n#Fri Mar 11 18:20:10 UTC 2022\nJVMLevel=\nLSID=urn\\:lsid\\:genepattern.org\\:genepatternmodules\\:00423\\:3\nauthor=Edwin F. Juarez;UCSD - Mesirov Lab\ncategories=single-cell;singlecell\ncommandLine=Rscript --no-save --quiet --slave --no-restore <libdir>run_conos_visualizegeneexpression.R --conos_object <conos_object> --genesofinterest <genesofinterest> --clustering <clustering> --output_file_name <output_file_name>\ncpuType=any\ndescription=This is a minimalistic implementation of visualization options for Conos. This module is intended to be used after <a href\\=\"https\\://cloud.genepattern.org/gp/pages/index.jsf?lsid\\=urn\\:lsid\\:broad.mit.edu\\:cancer.software.genepattern.module.analysis\\:00410\\:0.1\">Conos.Cluster</a> has been ran.\ndocumentationUrl=https://github.com/genepattern/Conos.VisualizeGeneExpression/blob/v5/documentation.md\nfileFormat=pdf\njob.docker.image=genepattern/conos\\:2.1\nlanguage=any\nname=Conos.VisualizeGeneExpression\nos=any\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=RDS file created by Conos.Cluster\np1_fileFormat=rds\np1_flag=--conos_object\np1_name=conos_object\np1_numValues=0..1\np1_optional=\np1_prefix=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\np2_MODE=\np2_TYPE=TEXT\np2_default_value=\np2_description=A list of gene identifiers. The expression of these genes will be plotted on the embedded map. Gene names need to be separated by a coma and a space (e.g. MS4A1, CD74, LYZ, CD14) and match the identifiers used in the original input data (Gene Symbols, Ensembl IDs, etc).\np2_fileFormat=\np2_flag=--genesofinterest\np2_name=genesofinterest\np2_numValues=0..1\np2_optional=\np2_prefix=\np2_prefix_when_specified=\np2_type=java.lang.String\np2_value=\np3_MODE=\np3_TYPE=TEXT\np3_default_value=none\np3_description=Option to show clustering information besides gene expression (none, leiden, walktrap, both)\np3_fileFormat=\np3_flag=--clustering\np3_name=clustering\np3_numValues=0..1\np3_optional=\np3_prefix=\np3_prefix_when_specified=\np3_type=java.lang.String\np3_value=none\\=none;leiden\\=leiden;walktrap\\=walktrap;both\\=both\np4_MODE=\np4_TYPE=TEXT\np4_default_value=ConosMarkers\np4_description=Basename of the file to be saved\np4_fileFormat=\np4_flag=--output_file_name\np4_name=output_file_name\np4_numValues=1..1\np4_optional=\np4_prefix=\np4_prefix_when_specified=\np4_type=java.lang.String\np4_value=\nprivacy=public\nquality=development\nsrc.repo=https\\://github.com/genepattern/Conos.VisualizeGeneExpression\ntaskDoc=\ntaskType=single-cell\nuserid=edjuaro\nversion=Initial version"}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "# copyright 2017-2018 Regents of the University of California and the Broad Institute. All rights reserved.\n\nimport sys\nfrom io import StringIO\nimport os\nimport zipfile\nimport subprocess\nfrom subprocess import PIPE, STDOUT\nimport shutil\n\n# work directly with sys.argv to avoid having to specify all the parameters that do not change but can just pass through\n# so we'l look at the args ourselves and only rewrite as necessary when we see an arg that is not\n# passed natively to the hisat call\n\nindexDirToDelete = None\ndryRun = False\n\ndef rewriteIndex(args, buff, arg, argDict):\n    global indexDirToDelete\n\n    # expect either a zip file or a dir,\n    # if a zip, unzip it to a dir of the same name\n    # The dirname is the prefix as seen by hisat\n    #    -x <index.dir>/<index.file.prefix>\n    zipOrDirPath = next(args)\n    basename = os.path.splitext(os.path.basename(zipOrDirPath))[0]\n\n    if os.path.isfile(zipOrDirPath):\n        if not zipOrDirPath.lower().endswith(\".zip\"):\n            print(\"This should be a zip file, extension is wrong...\" + zipOrDirPath)\n        # this should be created in os.getcwd() the current working directory which is fine\n        os.mkdir(basename)\n        # try to unzip\n        os.path.splitext(zipOrDirPath)\n        zip_ref = zipfile.ZipFile(zipOrDirPath, 'r')\n        zip_ref.extractall(basename)\n        zip_ref.close()\n        zipOrDirPath = basename\n        indexDirToDelete = basename\n    elif os.path.isdir(zipOrDirPath):\n        # for directories we use the convention that the index name prefix is the same as the directory name\n        # basename = basename\n        basename=\"genome\" # to match the ftp://gpftp.broadinstitute.org/module_support_files/hisat2/index/by_genome/\n    else:\n        raise ValueError(\"Index Problem: \" + zipOrDirPath + \" is neither a zip file nor a directory\")\n\n\n    # else its a dir\n    buff.write(u\"-x \")\n    buff.write(unicode(zipOrDirPath))\n    buff.write(u\"/\")\n    buff.write(unicode(basename))\n\n\n\ndef readFileList(fileList):\n    files =[]\n\n    fileReader = open(fileList, 'r')\n    for line in fileReader:\n        line = line.rstrip('\\n')\n        line = line.strip()\n        result = line.split('\\t')\n        if len(result) >= 1:\n            filepath = result[0]\n            assert os.path.exists(filepath), 'File does not exist: ' + filepath\n\n            #if it is a directory then get all the files in that directory\n            if os.path.isdir(filepath):\n                subFiles = [os.path.join(filepath,fName) for fName in next(os.walk(filepath))[2]]\n                subFiles.sort()\n                files += subFiles\n            else:\n                files.append(filepath)\n    return ','.join(files)\n\n\ndef readPairs(args, buff, arg, argDict):\n    # look to see if we got -1 and -2, and if so write them.  If not we\n    # only got -1 so we write it as -U with the next value\n    readpairs_1 = readFileList(next(args))\n\n\n    if (\"-2\" in argDict):\n        readpairs_2 = readFileList(unicode(argDict['-2']))\n\n        buff.write(u\" -1 \")\n        buff.write(unicode(readpairs_1))\n        buff.write(u\" -2 \")\n        buff.write(unicode(readpairs_2))\n    else:\n        buff.write(u\" -U \")\n        buff.write(unicode(readpairs_1))\n\ndef softclipPenalty(args, buff, arg, argDict):\n    next(args, None)\n    min = argDict['-min_softclip_penalty']\n    max = argDict['-max_softclip_penalty']\n    buff.write(u\" --sp \")\n    buff.write(unicode(max))\n    buff.write(u\",\")\n    buff.write(unicode(min))\n\n\ndef nCeilFunc(args, buff, arg, argDict):\n    next(args, None)\n    min = argDict['-min_n_ceil']\n    max = argDict['-max_n_ceil']\n    buff.write(u\" --n-ceil L,\")\n    buff.write(unicode(min ))\n    buff.write(u\",\")\n    buff.write(unicode(max ))\n\ndef scoreMinFunc(args, buff, arg, argDict):\n    next(args)\n    min = argDict['-min.score.align']\n    max = argDict['-max.score.align']\n    buff.write(u\" --score-min L,\")\n    buff.write(unicode(min ))\n    buff.write(u\",\")\n    buff.write(unicode(max ))\n\ndef canonIntronPenFunc(args, buff, arg, argDict):\n    next(args)\n    min = argDict['-min_pen-canintronlen']\n    max = argDict['-max_pen-canintronlen']\n    buff.write(unicode(u\" --pen-canintronlen G,\"))\n   \n    buff.write(unicode(str(min)) )\n    buff.write(u\",\")\n    buff.write(unicode(str(max)))\n\ndef noncanonIntronPenFunc(args, buff, arg, argDict):\n    next(args)\n    min = argDict['-min_pen-noncanintronlen']\n    max = argDict['-max_pen-noncanintronlen']\n    buff.write(unicode(u\" --pen-noncanintronlen G,\"))\n    buff.write(unicode(str(min)))\n    buff.write(u\",\" )\n    buff.write(unicode(str(max)) )\n\ndef outputPrefix(args, buff, arg, argDict):\n    val = next(args)\n    buff.write(u\" -S \")\n    buff.write(unicode(val ))\n    buff.write(u\".sam\")\n\ndef mappedReads(args, buff, arg, argDict):\n    if (\"-2\" in argDict):\n        buff.write(u\" --al-conc-gz \")\n    else:\n        buff.write(u\" --al-gz \")\n    val = next(args)\n    buff.write(unicode(val ))\n\n\ndef unmappedReads(args, buff, arg, argDict):\n    if (\"-2\" in argDict):\n        buff.write(u\" --un-conc-gz \")\n    else:\n        buff.write(u\" --un-gz \")\n    val = next(args)\n    buff.write(unicode(val ))\n\ndef readGapPenFunc(args, buff, arg, argDict):\n    next(args)\n    x = argDict['-read.gap.open.pen']\n    y = argDict['-read.gap.extend.pen']\n    buff.write(u\" --rdg \")\n    buff.write(unicode(x) )\n    buff.write(u\",\")\n    buff.write(unicode(y))\n\n\ndef refGapPenFunc(args, buff, arg, argDict):\n    next(args)\n    x = argDict['-ref.gap.open.pen']\n    y = argDict['-ref.gap.extend.pen']\n    buff.write(u\" --rfg \")\n    buff.write(unicode(x ))\n    buff.write(u\",\")\n    buff.write(unicode(y ))\n\ndef mismatchPenFunc(args, buff, arg, argDict):\n    next(args)\n    minp = argDict['-min.mismatch.penalty']\n    maxp = argDict['-max.mismatch.penalty']\n    buff.write(u\" --mp \")\n    buff.write(unicode(maxp ))\n    buff.write(u\",\")\n    buff.write(unicode(minp) )\n\ndef dryRunFlag(args, buff, arg, argDict):\n    val = next(args, None)\n    if (\"True\" == val):\n        dryRun = True\n\n#######################   these are the catchall handler fuunctions ============\ndef passThrough(args, buff, arg, argDict):\n    val = next(args, None)\n    buff.write(unicode(arg) )\n    buff.write(u\" \")\n    buff.write(unicode(val) )\n    #print(\"passthrough on: \" + str(arg) + \"  with val \" + str(val))\n\n\ndef justAFlagPassThrough(args, buff, arg, argDict):\n    # don't do anything to the argument but in this case its just a flag with no value following it\n    buff.write(unicode(arg) )\n    buff.write(u\" \")\n    #print(\"just a flag on: \"+ arg)\n\n\n\ndef nullOpt(args, buff, arg, argDict):\n    # this is for options that are present in the GP command line to this script\n    # but get combined into a compound argument to hisat itself.  We don't want them to pass\n    # through, they should just be dropped on the assumtion that another handler consumes them\n    # from the arg dict.\n    next(args, None)\n\ndef nullFlag(args, buff, arg, argDict):\n    # this is for flags used as placeholders that should not pass through to the actual hisat2 call.\n    # usually this is for a genepattern dropdown that we really want nothing in one case, but thats not\n    # an allowable value in a GenePattern selector\n    print('')\n\n#######################  END - these two are the catchall handler fuunctions ============\n\n\n\n\ndef setupHandlers():\n    handlers = {\"-index\": rewriteIndex,\n                \"-U\": readPairs,\n                \"-2\": nullOpt,\n                \"-min_softclip_penalty\": softclipPenalty,\n                \"-max_softclip_penalty\": nullOpt,\n                \"-min_n_ceil\": nCeilFunc,\n                \"-max_n_ceil\": nullOpt,\n                \"-min.score.align\": scoreMinFunc,\n                \"-max.score.align\": nullOpt,\n                \"-min_pen-canintronlen\": canonIntronPenFunc,\n                \"-max_pen-canintronlen\": nullOpt,\n                \"-min_pen-noncanintronlen\": noncanonIntronPenFunc,\n                \"-max_pen-noncanintronlen\": nullOpt,\n                \"-S\": outputPrefix,\n                \"--int-quals\": justAFlagPassThrough,\n                \"-f\":  justAFlagPassThrough,\n                \"-p\":  passThrough,\n                \"--fr\": justAFlagPassThrough,\n                \"--rf\": justAFlagPassThrough,\n                \"--ff\": justAFlagPassThrough,\n                \"--phred33\": justAFlagPassThrough,\n                \"--phred64\": justAFlagPassThrough,\n                \"--solexa-quals\": justAFlagPassThrough,\n                \"--ignore-quals\": justAFlagPassThrough,\n                \"--no-mixed\": justAFlagPassThrough,\n                \"--no-discordant\": justAFlagPassThrough,\n                \"--no-spliced-alignment\": justAFlagPassThrough,\n                \"--secondary\": justAFlagPassThrough,\n                 \"-mapped.reads\": mappedReads,\n                \"-unmapped.reads\": unmappedReads,\n                \"-read.gap.open.pen\": readGapPenFunc,\n                \"-read.gap.extend.pen\": nullOpt,\n                \"-ref.gap.open.pen\": refGapPenFunc,\n                \"-ref.gap.extend.pen\": nullOpt,\n                \"-min.mismatch.penalty\": mismatchPenFunc,\n                \"-max.mismatch.penalty\": nullOpt,\n                \"--norc\":justAFlagPassThrough,\n                \"--nofw\":justAFlagPassThrough,\n                \"--norc\": justAFlagPassThrough,\n                \"--WRAPPER_IGNORE\": nullFlag,\n                \"-WRAPPER_IGNORE\": nullFlag,\n                \"-dryRun\": dryRunFlag,\n\n                ## below are ones that do not seem to match to the hisat2 doc but that VIB specified\n                ## these need to be examined more closely\n                #\"--max-seeds\": nullOpt,\n                }\n    return handlers\n\n\n\ndef generate_command():\n\n    handlers = setupHandlers()\n\n    # cache all args by their -? names since some of the cases take multiple GP args\n    # and condense them into a single compound hisat arg\n    argDict = {}\n    allargs = iter(sys.argv)\n    next(allargs)\n    for arg in allargs:\n        if arg.startswith('-'):\n            key = arg\n            handler = handlers.get(arg, passThrough)\n\n            if not ((handler == justAFlagPassThrough) or (handler == nullFlag)):\n                val = next(allargs, None)\n                argDict[key] = val\n                #print(\"1. Arg is ->\" + str(arg) + \"<- val ->\"+ val )\n\n\n    buff = StringIO()\n    buff.write(u\"hisat2 \")\n\n    allargs = iter(sys.argv)\n    next(allargs, None)  # strip off the script's name\n    for arg in allargs:\n        handler = handlers.get(arg, passThrough)\n        #print(\"arg is \" + arg)\n        handler(allargs, buff, arg, argDict)\n        buff.write(u\" \")\n        #print(\"        buff is now \" + buff.getvalue())\n\n    return buff.getvalue()\n\n\n\nif __name__ == '__main__':\n\n    revised_command = generate_command()\n    retval = 0\n\n    if dryRun:\n        print(revised_command)\n    else:\n        # print command line to stdout for debugging\n        print(revised_command)\n        # now call it passing along the same environment we got\n        childProcess = subprocess.Popen(revised_command, shell=True, env=os.environ, stdout=PIPE, stderr=PIPE)\n        stdout, stderr = childProcess.communicate()\n        retval = childProcess.returncode\n        if (retval != 0):\n                # if non-zero return, print stderr to stderr\n                print( stdout ) \n                print  >> sys.stderr, stderr\n        else:\n                # if not a non-zero stdout, print stderr to stdout since Hisat2Indexer logs non-error\n                # stuff to stderr.  Downside is the stderr and stdout are not interlevened\n                print(stdout)\n                print(stderr)\n\n\n\n    if not (indexDirToDelete == None):\n        shutil.rmtree(indexDirToDelete)\n    sys.exit(retval)    "}, {"role": "assistant", "content": "#Mon, 12 Feb 2018 11:19:35 -0800\n#HISAT2.aligner\n#Fri Feb 02 21:20:19 UTC 2018\nJVMLevel=\ntaskDoc=doc.html\ndocumentationUrl=https://genepattern.github.io/HISAT2.aligner/v2/\nLSID=urn\\:lsid\\:broad.mit.edu\\:cancer.software.genepattern.module.analysis\\:00367\\:999999999\nauthor=Ted Liefeld;UCSD\ncategories=rna-seq\ncommandLine=python <libdir>/hisat_wrapper.py  -index <index> -U <reads.pair.1> <reads.pair.2>   -S <output.prefix>   \\n -k <max.primary.alignments>  --max-seeds <max.seeds.extended>  -min_n_ceil <min.n.ceil>        -min.mismatch.penalty <min.mismatch.penalty>  --np <ambiguous.read.penalty> -read.gap.open.pen <read.gap.open.penalty> -ref.gap.open.pen <reference.gap.open.penalty> --pen-cansplice <penalty.for.canonical.splice.sites> --pen-noncansplice <penalty.for.non-canonical.splice.sites> -min_pen-canintronlen <min.penalty.long.introns.with.canonical.splice.sites> -max_pen-canintronlen <max.penalty.long.introns.with.canonical.splice.sites> --min-intronlen  <minimum.intron.length> --max-intronlen <maximum.intron.length>   -X <maximum.fragment.length.for.paired.alignment> <unpaired.alignments.for.paired.reads> <discordant.alignments.for.paired.reads>   <input.format> <quality.value.scale> <integer.quality.value> <mate.orientations> <novel.splicesites.infile> <ignore.read.qualities> <align> -max.mismatch.penalty <max.mismatch.penalty> <soft.clipping> -min_softclip_penalty <min.softclip.penalty> -max_softclip_penalty <max.softclip.penalty> -max_n_ceil <max.n.ceil> -read.gap.extend.pen <read.gap.extend.penalty> -ref.gap.extend.pen  <reference.gap.extend.pen> <spliced.alignments>  -I <minimum.fragment.length.for.paired.alignment> <secondary.alignments> <max.reads.to.align>   -min.score.align <min.score.align> -max.score.align <max.score.align>   <novel.splicesites> <mapped.reads> <unmapped.reads> -dryRun <dry.run> -min_pen-noncanintronlen <min.penalty.long.introns.with.noncanonical.splice.sites> -max_pen-noncanintronlen <max.penalty.long.introns.with.noncanonical.splice.sites> -p <job.cpuCount>\ncpuType=any\ndescription=HISAT2 is a fast and sensitive alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes (as well as to a single reference genome).\nfileFormat=sam\nlanguage=any\njob.docker.image=genepattern/docker-hisat2:v0.12\nsrc.repo=https://github.com/genepattern/HISAT2.aligner/tree/v1.5\nname=HISAT2.aligner\nos=any\np10_MODE=\np10_TYPE=Integer\np10_default_value=1\np10_description=Sets penalty for positions where the read, reference, or both, contain an ambiguous character such as `N`. \np10_fileFormat=\np10_flag=--np \np10_name=ambiguous.read.penalty\np10_numValues=1..1\np10_optional=\np10_prefix=\np10_prefix_when_specified=\np10_type=java.lang.Integer\np10_value=\np11_MODE=\np11_TYPE=Integer\np11_default_value=5\np11_description=Sets the read gap open penalty. A read gap of length N gets a penalty of `` + N * ``. \np11_fileFormat=\np11_flag=\np11_name=read.gap.open.penalty\np11_numValues=1..1\np11_optional=on\np11_prefix=\np11_prefix_when_specified=\np11_type=java.lang.Integer\np11_value=\np12_MODE=\np12_TYPE=Integer\np12_default_value=5\np12_description=Sets the reference gap open penalty. A read gap of length N gets a penalty of `` + N * ``. \np12_fileFormat=\np12_flag=\np12_name=reference.gap.open.penalty\np12_numValues=0..1\np12_optional=on\np12_prefix=\np12_prefix_when_specified=\np12_type=java.lang.Integer\np12_value=\np13_MODE=\np13_TYPE=Integer\np13_default_value=0\np13_description=Sets the penalty for each pair of canonical splice sites (e.g. GT/AG). \\n\np13_fileFormat=\np13_flag=--pen-cansplice \np13_name=penalty.for.canonical.splice.sites\np13_numValues=0..1\np13_optional=on\np13_prefix=\np13_prefix_when_specified=\np13_type=java.lang.Integer\np13_value=\np14_MODE=\np14_TYPE=Integer\np14_default_value=12\np14_description=Sets the penalty for each pair of non-canonical splice sites (e.g. non-GT/AG). \np14_fileFormat=\np14_flag=--pen-noncansplice \np14_name=penalty.for.non-canonical.splice.sites\np14_numValues=0..1\np14_optional=on\np14_prefix=\np14_prefix_when_specified=\np14_type=java.lang.Integer\np14_value=\np15_MODE=\np15_TYPE=Integer\np15_default_value=-8\np15_description=Sets the minimum in a natural log penalty function for long introns with canonical splice sites so that alignments with shorter introns are preferred to those with longer ones.\np15_fileFormat=\np15_flag=-min_pen-canintronlen \np15_name=min.penalty.long.introns.with.canonical.splice.sites\np15_numValues=0..1\np15_optional=on\np15_prefix=\np15_prefix_when_specified=\np15_type=java.lang.Integer\np15_value=\np16_MODE=\np16_TYPE=Integer\np16_default_value=1\np16_description=Sets the maximim in a natural log penalty function for long introns with canonical splice sites so that alignments with shorter introns are preferred to those with longer ones.\np16_fileFormat=\np16_flag=-max_pen-canintronlen \np16_name=max.penalty.long.introns.with.canonical.splice.sites\np16_numValues=0..1\np16_optional=on\np16_prefix=\np16_prefix_when_specified=\np16_type=java.lang.Integer\np16_value=\np17_MODE=\np17_TYPE=Integer\np17_default_value=20\np17_description=Sets minimum intron length. \np17_fileFormat=\np17_flag=--min-intronlen  \np17_name=minimum.intron.length\np17_numValues=1..1\np17_optional=\np17_prefix=\np17_prefix_when_specified=\np17_type=java.lang.Integer\np17_value=\np18_MODE=\np18_TYPE=Integer\np18_default_value=500000\np18_description=Sets maximum intron length.\\n\np18_fileFormat=\np18_flag=--max-intronlen \np18_name=maximum.intron.length\np18_numValues=0..1\np18_optional=on\np18_prefix=\np18_prefix_when_specified=\np18_type=java.lang.Integer\np18_value=\np19_MODE=\np19_TYPE=Integer\np19_default_value=500\np19_description=The maximum fragment length for valid paired-end alignments.This option is valid only with no spliced alignment. E.g. if 100 is specified and a paired-end alignment consists of two 20-bp alignments in the appropriate orientation with a 60-bp gap between them, that alignment is considered valid (as long as the minimum fragment length is also satisfied). A 61-bp gap would not be valid in that case. If trimming options -3 or -5 are also used, the  constraint is applied with respect to the untrimmed mates.\\n\\nThe larger the difference between minimum and maximum fragment lengths, the slower HISAT2 will run. This is because larger differences scan a larger window to determine if a concordant alignment exists. For typical fragment length ranges (200 to 400 nucleotides), HISAT2 is very efficient. \np19_fileFormat=\np19_flag=-X \np19_name=maximum.fragment.length.for.paired.alignment\np19_numValues=0..1\np19_optional=on\np19_prefix=\np19_prefix_when_specified=\np19_type=java.lang.Integer\np19_value=\np1_MODE=IN\np1_TYPE=FILE\np1_choiceDir=https://datasets.genepattern.org/gpftp/module_support_files/hisat2/index/index_directory.json\np1_choiceDirFilter=\np1_default_value=\np1_description=Directory or zip file containing a Hisat2 genome index to be aligned to.\np1_fileFormat=DIRECTORY\np1_flag=\np1_name=index\np1_numValues=1..1\np1_optional=\np1_prefix=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\np20_MODE=\np20_TYPE=TEXT\np20_default_value=--WRAPPER_IGNORE\np20_description=By default, when `hisat2` cannot find a concordant or discordant alignment for a pair, it then tries to find alignments for the individual mates.  This option disables that behavior. \np20_fileFormat=\np20_flag=\np20_name=unpaired.alignments.for.paired.reads\np20_numValues=0..1\np20_optional=on\np20_prefix=\np20_prefix_when_specified=\np20_type=java.lang.String\np20_value=--WRAPPER_IGNORE\\= no;--no-mixed\\=Disabled\np21_MODE=\np21_TYPE=TEXT\np21_default_value=--WRAPPER_IGNORE\np21_description=By default, `hisat2` looks for discordant alignments if it cannot find any concordant alignments.  A discordant alignment is an alignment where both mates align uniquely, but that does not satisfy the paired-end constraints (`--fr`/`--rf`/`--ff`, `-I`, `-X`).  This option disables that behavior.\\n\np21_fileFormat=\np21_flag=\np21_name=discordant.alignments.for.paired.reads\np21_numValues=0..1\np21_optional=on\np21_prefix=\np21_prefix_when_specified=\np21_type=java.lang.String\np21_value=--WRAPPER_IGNORE\\= No;--no-discordant\\=Disabled\np22_MODE=\np22_TYPE=TEXT\np22_default_value=-q\np22_description=The format of the input reads files.  May be fastQ, fastA, raw (one sequence per line) or Illumina qseq format.\np22_fileFormat=\np22_flag=\np22_name=input.format\np22_numValues=1..1\np22_optional=\np22_prefix=\np22_prefix_when_specified=\np22_type=java.lang.String\np22_value=-q\\=fastQ;-f\\=fastA;-r\\=raw (one sequence per line);-qseq\\=Illumina qseq format\np23_MODE=\np23_TYPE=TEXT\np23_default_value=--phred33\np23_description=Whether to use the Solexa, Phred 33, Phred 64 quality value scale\np23_fileFormat=\np23_flag=\np23_name=quality.value.scale\np23_numValues=1..1\np23_optional=\np23_prefix=\np23_prefix_when_specified=\np23_type=java.lang.String\np23_value=--phred33\\=phred33-Quals;--phred64\\=phred64-quals;--solexa-quals\\=solexa-quals\np24_MODE=\np24_TYPE=TEXT\np24_default_value=--WRAPPER_IGNORE\np24_description=Quality values are represented in the read input file as space-separated ASCII integers, e.g., 40 40 30 40..., rather than ASCII characters, e.g., II?I.... Integers are treated as being on the Phred quality scale unless \"Solexa\" is also specified for the <quality value scale>.\np24_fileFormat=\np24_flag=\np24_name=integer.quality.value\np24_numValues=0..1\np24_optional=on\np24_prefix=\np24_prefix_when_specified=\np24_type=java.lang.String\np24_value=--int-quals\\=yes;--WRAPPER_IGNORE\\=no\np25_MODE=\np25_TYPE=TEXT\np25_default_value=--fr\np25_description=The upstream/downstream mate orientations for a valid paired-end alignment against the forward reference strand. \np25_fileFormat=\np25_flag=\np25_name=mate.orientations\np25_numValues=1..1\np25_optional=\np25_prefix=\np25_prefix_when_specified=\np25_type=java.lang.String\np25_value=--fr\\=first mate forward, second mate reverse (--fr);--rf\\=first mate reverse, second mate forward (--rf);--ff\\=both mates forward (--ff)\np26_MODE=IN\np26_TYPE=FILE\np26_default_value=\np26_description=An optional list of known splice sites, which HISAT2 makes use of to align reads with small anchors. (this is the output of Novel Splice Sites - see Supplementary Output)\np26_fileFormat=\np26_flag=--novel-splicesite-infile \np26_name=novel.splicesites.infile\np26_numValues=0..1\np26_optional=on\np26_prefix=--novel-splicesite-infile \np26_prefix_when_specified=--novel-splicesite-infile \np26_type=java.io.File\np26_value=\np27_MODE=\np27_TYPE=TEXT\np27_default_value=--WRAPPER_IGNORE\np27_description=When calculating a mismatch penalty, always consider the quality value at the mismatched position to be the highest possible, regardless of the actual value. I.e. input is treated as though all quality values are high. This is also the default behavior when the input doesn't specify quality values\np27_fileFormat=\np27_flag=\np27_name=ignore.read.qualities\np27_numValues=1..1\np27_optional=\np27_prefix=\np27_prefix_when_specified=\np27_type=java.lang.String\np27_value=--WRAPPER_IGNORE\\=no;--ignore-quals\\=yes\np28_MODE=\np28_TYPE=TEXT\np28_default_value=--WRAPPER_IGNORE\np28_description=Align unpaired reads against the forward reference strand only, the reverse-complement (Crick) reference strand only, or both.\np28_fileFormat=\np28_flag=\np28_name=align\np28_numValues=0..1\np28_optional=\np28_prefix=\np28_prefix_when_specified=\np28_type=java.lang.String\np28_value=--norc\\=only against forward strand;--nofw\\=only reverse;--WRAPPER_IGNORE\\= both\np29_MODE=\np29_TYPE=Integer\np29_default_value=6\np29_description=Sets the maximum (`MX`)  mismatch penalty. A number less than or equal to `MX` and greater than or equal to <min mismatch penalty> (`MN`) is subtracted from the alignment score for each position where a read character aligns to a reference character, the characters do not match, and neither is an `N`. If <ignore read qualities> is specified, the number subtracted quals `MX`. Otherwise, the number subtracted is `MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) )` where Q is the Phred quality value. Default\\: `MX` \\= 6, `MN` \\= 2.\np29_fileFormat=\np29_flag=\np29_name=max.mismatch.penalty\np29_numValues=1..1\np29_optional=\np29_prefix=\np29_prefix_when_specified=\np29_type=java.lang.Integer\np29_value=\np2_MODE=IN\np2_TYPE=FILE\np2_default_value=\np2_description=Unpaired reads file or first mate for paired reads. One or more files containing reads in FASTA or FASTQ format (bz2 and gz compressed files are supported).\np2_fileFormat=fq;fastq;fq.gz;fastq.gz;fq.bz2;fastq.bz2;fa;fasta;fa.gz;fasta.gz;fa.bz2;fasta.bz2\np2_flag=\np2_name=reads.pair.1\np2_numValues=1+\np2_optional=\np2_prefix=\np2_prefix_when_specified=\np2_type=java.io.File\np2_value=\np30_MODE=\np30_TYPE=TEXT\np30_default_value=-WRAPPER_IGNORE\np30_description=Allow or disallow soft clipping.\np30_fileFormat=\np30_flag=\np30_name=soft.clipping\np30_numValues=1..1\np30_optional=\np30_prefix=\np30_prefix_when_specified=\np30_type=java.lang.String\np30_value=-WRAPPER_IGNORE\\=yes;--no-softclip\\=no\np31_MODE=\np31_TYPE=Integer\np31_default_value=1\np31_description=Sets the  minimum (MN) penalty for soft-clipping per base. A number less than or equal to the max softclip penalty (MX) and greater than or equal to MN is subtracted from the alignment score for each position. The number subtracted is MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) ) where Q is the Phred quality value. Default\\: MX \\= 2, MN \\= 1.\np31_fileFormat=\np31_flag=\np31_name=min.softclip.penalty\np31_numValues=0..1\np31_optional=\np31_prefix=\np31_prefix_when_specified=\np31_type=java.lang.Integer\np31_value=\np32_MODE=\np32_TYPE=Integer\np32_default_value=2\np32_description=Sets the maximum (MX) penalty for soft-clipping per base. A number less than or equal to MX and greater than or equal to the min softclip penalty (MN) is subtracted from the alignment score for each position. The number subtracted is MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) ) where Q is the Phred quality value. Default\\: MX \\= 2, MN \\= 1.\np32_fileFormat=\np32_flag=\np32_name=max.softclip.penalty\np32_numValues=0..1\np32_optional=\np32_prefix=\np32_prefix_when_specified=\np32_type=java.lang.Integer\np32_value=\np33_MODE=\np33_TYPE=Floating Point\np33_default_value=.15\np33_description=Sets a maximum in a linear function governing the maximum number of ambiguous characters (usually `N`s and/or `.`s) allowed in a read as a function of read length. \np33_fileFormat=\np33_flag=\np33_name=max.n.ceil\np33_numValues=1..1\np33_optional=\np33_prefix=\np33_prefix_when_specified=\np33_type=java.lang.Float\np33_value=\np34_MODE=\np34_TYPE=Integer\np34_default_value=3\np34_description=Sets the read gap extend penalty. A read gap of length N gets a penalty of `` + N * ``. \np34_fileFormat=\np34_flag=\np34_name=read.gap.extend.penalty\np34_numValues=1..1\np34_optional=\np34_prefix=\np34_prefix_when_specified=\np34_type=java.lang.Integer\np34_value=\np35_MODE=\np35_TYPE=Integer\np35_default_value=3\np35_description=Sets the reference gap extend penalty. A read gap of length N gets a penalty of `` + N * ``. \np35_fileFormat=\np35_flag=\np35_name=reference.gap.extend.pen\np35_numValues=1..1\np35_optional=\np35_prefix=\np35_prefix_when_specified=\np35_type=java.lang.Integer\np35_value=\np36_MODE=\np36_TYPE=TEXT\np36_default_value=--WRAPPER_IGNORE\np36_description=Disables spliced alignments if set to 'no'.\np36_fileFormat=\np36_flag=\np36_name=spliced.alignments\np36_numValues=0..1\np36_optional=\np36_prefix=\np36_prefix_when_specified=\np36_type=java.lang.String\np36_value=--WRAPPER_IGNORE\\= yes;--no-spliced-alignments\\=no\np37_MODE=\np37_TYPE=Floating Point\np37_default_value=0\np37_description=Sets minimum on the function governing the minimum alignment score needed for an alignment to be considered \"valid\" (i.e. good enough to report). This is a function of read length. For instance, specifying 0 sets the minimum-score function f to f(x) \\= 0 + -0.6 * x, where x is the read length and -0.6 is the max score align value. \np37_fileFormat=\np37_flag=-min.score.align \np37_name=min.score.align\np37_numValues=0..1\np37_optional=\np37_prefix=\np37_prefix_when_specified=\np37_type=java.lang.Float\np37_value=\np38_MODE=\np38_TYPE=Floating Point\np38_default_value=-.2\np38_description=Sets maximum on the function governing the minimum alignment score needed for an alignment to be considered \"valid\" (i.e. good enough to report). This is a function of read length. For instance, specifying -0.6 sets the minimum-score function f to f(x) \\= 0.1 + -0.6 * x, where x is the read length and 0.1 is the min score align value. \np38_fileFormat=\np38_flag=-max.score.align \np38_name=max.score.align\np38_numValues=0..1\np38_optional=\np38_prefix=\np38_prefix_when_specified=\np38_type=java.lang.Float\np38_value=\np39_MODE=\np39_TYPE=Integer\np39_default_value=0\np39_description=The minimum fragment length for valid paired-end alignments.This option is valid only with no spliced alignment. E.g. if 60 is specified and a paired-end alignment consists of two 20-bp alignments in the appropriate orientation with a 20-bp gap between them, that alignment is considered valid (as long as the maximum fragment length is also satisfied). A 19-bp gap would not be valid in that case. If trimming options -3 or -5 are also used, the  constraint is applied with respect to the untrimmed mates.\\n\\nThe larger the difference between minimum and maximum fragment lengths, the slower HISAT2 will run. This is because larger differences scan a larger window to determine if a concordant alignment exists. For typical fragment length ranges (200 to 400 nucleotides), HISAT2 is very efficient. \np39_fileFormat=\np39_flag=-I \np39_name=minimum.fragment.length.for.paired.alignment\np39_numValues=0..1\np39_optional=\np39_prefix=\np39_prefix_when_specified=\np39_type=java.lang.Integer\np39_value=\np3_MODE=\np3_TYPE=TEXT\np3_default_value=mapped\np3_description=The prefix to use for the output file name.\np3_fileFormat=\np3_flag=\np3_name=output.prefix\np3_numValues=1..1\np3_optional=\np3_prefix=\np3_prefix_when_specified=\np3_type=java.lang.String\np3_value=\np40_MODE=\np40_TYPE=TEXT\np40_default_value=--WRAPPER_IGNORE\np40_description=Report secondary alignments.\np40_fileFormat=\np40_flag=\np40_name=secondary.alignments\np40_numValues=0..1\np40_optional=\np40_prefix=\np40_prefix_when_specified=\np40_type=java.lang.String\np40_value=--WRAPPER_IGNORE\\= no;--secondary\\=yes\np41_MODE=\np41_TYPE=TEXT\np41_default_value=\np41_description=Optional output file for novel splice sites found.\np41_fileFormat=\np41_flag=--novel-splicesite-outfile \np41_name=novel.splicesites\np41_numValues=0..1\np41_optional=on\np41_prefix=--novel-splicesite-outfile \np41_prefix_when_specified=--novel-splicesite-outfile \np41_type=java.lang.String\np41_value=\np42_MODE=\np42_TYPE=TEXT\np42_default_value=\np42_description=Optional\\: write unpaired reads that align at least once to a file.\np42_fileFormat=\np42_flag=-mapped.reads \np42_name=mapped.reads\np42_numValues=0..1\np42_optional=on\np42_prefix=-mapped.reads \np42_prefix_when_specified=-mapped.reads \np42_type=java.lang.String\np42_value=\np43_MODE=\np43_TYPE=TEXT\np43_default_value=\np43_description=Write paired-end reads that align concordantly at least once to file(s).\np43_fileFormat=\np43_flag=-unmapped.reads \np43_name=unmapped.reads\np43_numValues=0..1\np43_optional=on\np43_prefix=-unmapped.reads \np43_prefix_when_specified=-unmapped.reads \np43_type=java.lang.String\np43_value=\np44_MODE=\np44_TYPE=TEXT\np44_default_value=False\np44_description=When true, the module only prints the hisat command-line that would be used to the program's standard output file (stdout.txt) but does not execute the alignment.  Useful for testing or generating a command line to run HISAT2 outside of GenePattern.\np44_fileFormat=\np44_flag=-dryRun \np44_name=dry.run\np44_numValues=0..1\np44_optional=\np44_prefix=\np44_prefix_when_specified=\np44_type=java.lang.String\np44_value=False\\=False;True\\=True\np45_MODE=\np45_TYPE=Integer\np45_default_value=-8\np45_description=Sets the minimum in a natural log penalty function for long introns with noncanonical splice sites so that alignments with shorter introns are preferred to those with longer ones. \np45_fileFormat=\np45_flag=-min_pen-noncanintronlen \np45_name=min.penalty.long.introns.with.noncanonical.splice.sites\np45_numValues=0..1\np45_optional=\np45_prefix=\np45_prefix_when_specified=\np45_type=java.lang.Integer\np45_value=\np46_MODE=\np46_TYPE=Integer\np46_default_value=1\np46_description=Sets the maximim in a natural log penalty function for long introns with noncanonical splice sites so that alignments with shorter introns are preferred to those with longer ones. \np46_fileFormat=\np46_flag=-max_pen-noncanintronlen \np46_name=max.penalty.long.introns.with.noncanonical.splice.sites\np46_numValues=0..1\np46_optional=\np46_prefix=\np46_prefix_when_specified=\np46_type=java.lang.Integer\np46_value=\np4_MODE=IN\np4_TYPE=FILE\np4_default_value=\np4_description=Second mate for paired reads. Zero or more files in FASTA or FASTQ format (bz2 and gz compressed files are supported).\np4_fileFormat=fq;fastq;fq.gz;fastq.gz;fq.bz2;fastq.bz2;fa;fasta;fa.gz;fasta.gz;fa.bz2;fasta.bz2\np4_flag=-2 \np4_name=reads.pair.2\np4_numValues=0+\np4_optional=on\np4_prefix=-2 \np4_prefix_when_specified=-2 \np4_type=java.io.File\np4_value=\np5_MODE=\np5_TYPE=Integer\np5_default_value=5\np5_description=HISAT2 searches for up to N distinct, primary alignments for each read, where N equals the integer specified with this parameter. Primary alignments mean alignments whose alignment score is equal or higher than any other alignments. It is possible that multiple distinct alignments have the same score. That is, if `2` is specified, HISAT2 will search for at most 2 distinct alignments. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM 'secondary' bit (which equals 256) set in its FLAGS field.\np5_fileFormat=\np5_flag=-k \np5_name=max.primary.alignments\np5_numValues=1..1\np5_optional=\np5_prefix=\np5_prefix_when_specified=\np5_type=java.lang.Integer\np5_value=\np6_MODE=\np6_TYPE=Integer\np6_default_value=5\np6_description=HISAT2, like other aligners, uses seed-and-extend approaches. HISAT2 tries to extend seeds to full-length alignments. In HISAT2, --max-seeds is used to control the maximum number of seeds that will be extended. HISAT2 extends up to these many seeds and skips the rest of the seeds. Large values for <max seeds extended>` may improve alignment sensitivity, but HISAT2 is not designed with large values for<max seeds extended> in mind, and when aligning reads to long, repetitive genomes large <max seeds extended> can be very, very slow.\np6_fileFormat=\np6_flag=--max-seeds \np6_name=max.seeds.extended\np6_numValues=0..1\np6_optional=on\np6_prefix=\np6_prefix_when_specified=\np6_type=java.lang.Integer\np6_value=\np7_MODE=\np7_TYPE=Floating Point\np7_default_value=0\np7_description=Sets the minimum value in a linear function governing the maximum number of ambiguous characters (usually `N`s and/or `.`s) allowed in a read as a function of read length. specifying `-L,0,0.15` sets the N-ceiling function `f` to `f(x) \\= 0 + 0.15 * x`,\\nwhere x is the read length.  See also\\: [setting function options].  Reads\\nexceeding this ceiling are [filtered out].  Default\\: `L,0,0.15`.\\n`N`s and/or `.`s) allowed in a read as a function of read length.   In these cases the user specifies three parameters\\: (a) a function\\ntype `F`, (b) a constant term `B`, and (c) a coefficient `A`. For instance,\\nspecifying `-L,0,0.15` sets the N-ceiling function `f` to `f(x) \\= 0 + 0.15 * x`,\\nwhere x is the read length\np7_fileFormat=\np7_flag=\np7_name=min.n.ceil\np7_numValues=1..1\np7_optional=\np7_prefix=\np7_prefix_when_specified=\np7_type=java.lang.Float\np7_value=\np8_MODE=\np8_TYPE=Integer\np8_default_value=\np8_description=Align the first \\# reads or read pairs from the input (after the `-s`/`--skip` reads or pairs have been skipped), then stop. Mainly useful for testing.\np8_fileFormat=\np8_flag=-u \np8_name=max.reads.to.align\np8_numValues=0..1\np8_optional=on\np8_prefix=-u \np8_prefix_when_specified=-u \np8_type=java.lang.Integer\np8_value=\np9_MODE=\np9_TYPE=Integer\np9_default_value=2\np9_description=Sets the  minimum (`MN`) mismatch penalty. A number less than or equal to <max mismatch penalty> (`MX`) and greater than or equal to `MN` is subtracted from the alignment score for each position where a read character aligns to a reference character, the characters do not match, and neither is an `N`. If <ignore read qualities> is specified, the number subtracted quals `MX`. Otherwise, the number subtracted is `MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) )` where Q is the Phred quality value. Default\\: `MX` \\= 6, `MN` \\= 2.\np9_fileFormat=\np9_flag=\np9_name=min.mismatch.penalty\np9_numValues=1..1\np9_optional=\np9_prefix=\np9_prefix_when_specified=\np9_type=java.lang.Integer\np9_value=\nprivacy=public\nquality=production\ntaskType=rna-seq\nuserid=ted\nversion=Changed index dynamic source from ftp://gpft p to the copy on https://datasets.genepattern.org\npublicationDate=01/20/2023 11\\:19"}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "########################################################################\n# NTPez.R                                    Jan.27, 2009\n#                                     Fixed: 06/18/2012\n#   Nearest Template Prediction (NTP) for >=2 classes\n#   Yujin Hoshida (Broad Institute)\n#\n#    input: (1) Gene expression dataset (.gct)\n#           (2) Marker genes (.txt)\n#                  1st column: Probe ID\n#                  2nd column: Gene name\n#                  3rd column: Class (1,2,...)\n#                  4th column (optional): Weight vector\n#                           (score of differential expression, etc)\n#    output: Prediction result, Marker genes (.xls), heatmap (.png)\n#            Files for GenePattern (.gct, .cls)\n########################################################################\n\nNTPez<-function(\n# file I/O\ninput.exp.filename,\ninput.features.filename,\noutput.name=\"NTP\",\n\n# temp.nn distance & row normalize\ndist.selection=\"cosine\", # \"correlation\" or \"cosine\"\ntemp.nn.wt=\"T\",   # only for 2 cls\n\n# resampling to generate null dist\nnresmpl=1000,\n\n# outputs\nGenePattern.output=\"T\",\n\n# Seed\nrnd.seed=7392854\n)\n{\n\n#  suppressWarnings()\n\n  # Advanced setting\n\n  norm.method=\"row.std\" # \"row.std.ref\",\"ratio.ref\"\n  ref.sample.file=NULL\n  within.sig=\"F\"\n  plot.nominal.p=\"F\"\n  plot.distance=\"F\"\n  dchip.output=\"F\"\n  signature.heatmap=\"T\"\n  FDR.sample.bar=0.05 # NA if not needed\n  plot.FDR=\"T\"\n  col.range=3         # SD in heatmap\n  heatmap.legend=signature.heatmap\n  histgram.null.dist=\"F\" # histgram of null dist for the distance\n  hist.br=30\n\n  # for GenePattern\n\n  nresmpl<-as.numeric(nresmpl)\n  col.range<-as.numeric(col.range)\n  hist.br<-as.numeric(hist.br)  # bin number for resampled dist histgram\n  rnd.seed <- as.numeric(rnd.seed)\n  if (FDR.sample.bar!=\"NA\"){\n    FDR.sample.bar <- as.numeric(FDR.sample.bar)\n    if (is.numeric(FDR.sample.bar)==F){\n      stop(\"### Provide numerical value (0~1) for FDR.sample.bar! ###\")\n    }\n  }\n  if (is.null(ref.sample.file)){\n  }else{\n    if (ref.sample.file==\"NULL\"){\n      ref.sample.file <- NULL\n    }\n  }\n\n  # set random seed\n  set.seed(rnd.seed)\n\n  ### input ###\n\n  # selected features used for prediction\n  features<-read.delim(input.features.filename,header=T,check.names=F)\n\n  ## file format check\n  if (length(features[1,])!=3 & length(features[1,])!=4){\n    stop(\"### Please use features file format! ###\")\n  }\n  if (length(features[1,])<4 & temp.nn.wt==\"T\"){\n    temp.nn.wt <- \"F\"\n  }\n  third.col<-rownames(table(features[,3]))\n  if (is.na(as.numeric(third.col[1]))){\n    stop(\"### The 3rd column of feature file should be numerical! ###\")\n  }\n\n  feat.col.names<-colnames(features)\n  feat.col.names[1:2]<-c(\"ProbeID\",\"GeneName\")\n  colnames(features)<-feat.col.names\n\n  num.features<-length(features[,1])\n  num.cls<-length(table(features[,3]))\n  feature.col.num <- length(features[1,])\n\n  ord<-seq(1:num.features)\n  features<-cbind(ord,features)  # add order column to \"features\"\n\n  # expression data\n  ## file format check\n  if (regexpr(\".gct$\",input.exp.filename)==-1){\n    stop(\"### Gene expression data should be .gct format! ###\")\n  }\n  exp.dataset<-read.delim(input.exp.filename,header=T,skip=2,check.names=F)\n  colnames(exp.dataset)[1:2] <- c(\"ProbeID\",\"GeneName\")\n\n  ## Other dataset's mean & SD for row normalization (optional)\n  if (!is.null(ref.sample.file)){\n    ref.sample <- read.delim(ref.sample.file,header=T)\n    if (dim(ref.sample)[2]!=4 & is.numeric(ref.sample[1,3]) & is.numeric(ref.sample[1,4])){\n      stop(\"### mean & SD file format incorrect! ###\")\n    }\n    colnames(ref.sample)[1:4] <- c(\"ProbeID\",\"SomeName\",\"mean\",\"sd\")\n    merged.dataset <- merge(ref.sample,exp.dataset,sort=F)\n\n    ref.sample <- merged.dataset[,1:4]\n    exp.dataset <- merged.dataset[,c(1,5:dim(merged.dataset)[2])]\n  }\n\n  ProbeID<-exp.dataset[,1]\n  gene.names<-exp.dataset[,2]\n  num.samples<-(length(exp.dataset[1,])-2)\n  exp.dataset<-exp.dataset[-c(1:2)]\n\n  exp.for.sample.names<-read.delim(input.exp.filename,header=F,skip=2)  # read sample names\n  sample.names<-as.vector(as.matrix(exp.for.sample.names[1,3:length(exp.for.sample.names[1,])]))\n\n  # row normalize\n\n  normed.exp.dataset<-exp.dataset\n\n  if (norm.method==\"row.std\"){\n    exp.mean <- apply(exp.dataset,1,mean,na.rm=T)\n    exp.sd <- apply(exp.dataset,1,sd,na.rm=T)\n    normed.exp.dataset<-(exp.dataset-exp.mean)/exp.sd\n  }\n  if (norm.method==\"row.std.ref\"){\n    if (is.null(ref.sample)){\n      stop(\"### Provide reference sample data! ###\")\n    }\n    exp.mean <- as.numeric(as.vector(ref.sample$mean))\n    exp.sd <- as.numeric(as.vector(ref.sample$sd))\n    normed.exp.dataset<-(exp.dataset-exp.mean)/exp.sd\n  }\n  if (norm.method==\"ratio.ref\"){\n    if (is.null(ref.sample)){\n      stop(\"### Provide reference sample data! ###\")\n    }\n    exp.mean <- as.numeric(as.vector(ref.sample$mean))\n    normed.exp.dataset<- exp.dataset/exp.mean\n  }\n\n  normed.exp.dataset<-cbind(ProbeID,normed.exp.dataset)\n\n  # extract features from normed.exp.dataset\n\n  exp.dataset.extract<-merge(features,normed.exp.dataset,sort=F)\n  if (length(exp.dataset.extract[,1])<1){\n    stop(\"### No matched probes! ###\")\n  }\n\n  order.extract<-order(exp.dataset.extract[,2])\n  exp.dataset.extract<-exp.dataset.extract[order.extract,]\n  order.extract.after<-exp.dataset.extract[,2]\n  exp.dataset.extract<-exp.dataset.extract[-2]\n\n  if (temp.nn.wt==\"F\"){\n    features.extract<-exp.dataset.extract[,1:3]\n    if (feature.col.num==4){\n      exp.dataset.extract <- exp.dataset.extract[-4]\n    }\n    features.extract<-cbind(order.extract.after,features.extract) # order:ProbeID:gene name:cls:wt(if any)\n    num.features.extract<-length(features.extract[,1])\n\n    ProbeID.extract<-as.vector(exp.dataset.extract[,1])\n    exp.dataset.extract<-exp.dataset.extract[-c(1:3)]\n    rownames(exp.dataset.extract)<-ProbeID.extract\n  }\n\n#  temp.nn.wt.vector <- rep(1,num.features)\n\n  if (temp.nn.wt==\"T\" & num.cls==2){\n    features.extract<-exp.dataset.extract[,1:4]\n    features.extract<-cbind(order.extract.after,features.extract) # order:ProbeID:gene name:cls:wt(if any)\n\n#    if (is.numeric(features[,4])){\n      temp.nn.wt.vector <- as.numeric(as.vector(features.extract[,5]))\n#    }else{\n    if (is.numeric(temp.nn.wt.vector)==F){\n      stop(\"# Please use numeric values in 4th column!#\")\n    }\n\n    num.features.extract<-length(features.extract[,1])\n\n    ProbeID.extract<-as.vector(exp.dataset.extract[,1])\n    exp.dataset.extract<-exp.dataset.extract[-c(1:4)]\n    rownames(exp.dataset.extract)<-ProbeID.extract\n  }\n\n  # make template\n\n  for (i in 1:num.cls){\n    temp.temp<-as.numeric(as.vector(features.extract[,4]))\n    temp.temp[temp.temp!=i]<-0\n    temp.temp[temp.temp==i]<-1\n    eval(parse(text=paste(\"temp.\",i,\"<-temp.temp\",sep=\"\")))\n#    eval(parse(text=paste(\"temp\\.\",i,\"<-temp\\.temp\",sep=\"\")))  ### for < R-2.4.0\n  }\n\n  # weighted template (only for 2cls)\n\n  if (temp.nn.wt==\"T\" & num.cls==2){\n    temp.1 <- temp.nn.wt.vector\n    temp.2 <- -temp.nn.wt.vector\n  }\n\n  ### compute distance and p-value ###\n\n  predict.label<-vector(length=num.samples,mode=\"numeric\")\n  dist.to.template<-vector(length=num.samples,mode=\"numeric\")\n  dist.to.cls1<-vector(length=num.samples,mode=\"numeric\")\n\n  rnd.feature.matrix<-matrix(0,nrow=num.features.extract,ncol=nresmpl)\n\n  perm.dist.vector<-vector(length=nresmpl*num.cls,mode=\"numeric\")\n  nominal.p<-vector(length=num.samples,mode=\"numeric\")\n  BH.FDR<-vector(length=num.samples,mode=\"numeric\")\n  Bonferroni.p<-vector(length=num.samples,mode=\"numeric\")\n\n  for (i in 1:num.samples){\n\n    print(paste(\"sample # \",i,sep=\"\"))\n\n    current.sample <- as.vector(exp.dataset.extract[,i])\n\n    # compute original distance\n\n    orig.dist.to.all.temp <- vector(length=num.cls,mode=\"numeric\")\n\n    if (temp.nn.wt==\"T\"){   # weight sample data\n      current.sample <- current.sample*abs(temp.nn.wt.vector)\n    }\n\n    if (dist.selection==\"cosine\"){\n      for (o in 1:num.cls){      # compute distance to all templates\n        eval(parse(text=paste(\"current.temp <- temp.\",o,sep=\"\")))\n        orig.dist.to.all.temp[o]<-sum(current.temp*current.sample)/\n                  (sqrt(sum(current.temp^2))*sqrt(sum(current.sample^2)))\n      }\n    }\n    if (dist.selection==\"correlation\"){\n      for (o in 1:num.cls){      # compute distance to all templates\n        eval(parse(text=paste(\"current.temp <- temp.\",o,sep=\"\")))\n        orig.dist.to.all.temp[o] <- cor(current.temp,current.sample,method=\"pearson\",use=\"complete.obs\")\n      }\n    }\n\n    if (num.cls==2){           # find nearest neighbor (2 classes)\n      if ((is.na(orig.dist.to.all.temp[1])!=T) && (is.na(orig.dist.to.all.temp[2])!=T)){\n        if (orig.dist.to.all.temp[1]>=orig.dist.to.all.temp[2]){\n          predict.label[i]<-1\n          dist.to.template[i]<-1-orig.dist.to.all.temp[1]\n          dist.to.cls1[i]<--(orig.dist.to.all.temp[1]+1)\n        }\n        if (orig.dist.to.all.temp[1]<orig.dist.to.all.temp[2]){\n          predict.label[i]<-2\n          dist.to.template[i]<-1-orig.dist.to.all.temp[2]\n          dist.to.cls1[i]<-orig.dist.to.all.temp[2]+1\n        }\n      }\n    }\n\n    if (num.cls>2){\n      for (o in 1:num.cls){       # find nearest neighbor (>2 classes)\n        if (is.na(orig.dist.to.all.temp[o])!=T){\n          if (orig.dist.to.all.temp[o]==max(orig.dist.to.all.temp,na.rm=T)){\n            predict.label[i]<-o\n            dist.to.template[i]<-1-orig.dist.to.all.temp[o]\n            dist.to.cls1[i]<-(1-orig.dist.to.all.temp[o])+o\n          }\n        }\n      }\n    }\n\n    # permutation test\n\n    if (within.sig==\"F\"){     # generate resampled features from all probes\n      for (p in 1:nresmpl){\n        rnd.feature.matrix[,p]<-sample(normed.exp.dataset[,(i+1)],num.features.extract,replace=F)\n      }\n    }\n    if (within.sig==\"T\"){     # generate resampled features from only signature genes\n      for (p in 1:nresmpl){\n        rnd.feature.matrix[,p]<-sample(exp.dataset.extract[,i],num.features.extract,replace=F)\n      }\n    }\n\n    if (temp.nn.wt==\"T\" & num.cls==2){\n      rnd.feature.matrix <- rnd.feature.matrix*abs(temp.nn.wt.vector)\n    }\n\n    # compute distance to all templates\n    if (dist.selection==\"cosine\"){          # cosine\n      for (res in 1:num.cls){\n        eval(parse(text=paste(\"temp.resmpl<-temp.\",res,sep=\"\")))\n\n        prod.sum<-apply(t(t(rnd.feature.matrix)*temp.resmpl),2,sum)\n\n        data.sq.sum<-apply(rnd.feature.matrix^2,2,sum)\n        temp.sq.sum<-sum(temp.resmpl^2)\n\n        perm.dist.vector[(1+(nresmpl*(res-1))):(nresmpl*res)]<-\n               (1-(prod.sum/(sqrt(data.sq.sum)*sqrt(temp.sq.sum))))\n      }\n    }\n\n    if (dist.selection==\"correlation\"){          # correlation\n      for (res in 1:num.cls){\n        eval(parse(text=paste(\"temp.resmpl<-temp.\",res,sep=\"\")))\n        perm.dist.vector[(1+(nresmpl*(res-1))):(nresmpl*res)]<-\n                 (1-as.vector(cor(rnd.feature.matrix,temp.resmpl,method=\"pearson\",use=\"complete.obs\")))\n      }\n    }\n\n    # compute nominal p-value\n\n    combined.stats.rank<-rank(c(dist.to.template[i],perm.dist.vector))\n    nominal.p[i]<-combined.stats.rank[1]/length(combined.stats.rank)\n\n    # histgram of combined null distributions\n\n    if (histgram.null.dist==\"T\" & capabilities(\"png\")==T){\n      png(paste(\"resampled_\",dist.selection,\"_dist_histgram_\",sample.names[i],\".png\",sep=\"\"))\n      hist(c(dist.to.template[i],perm.dist.vector),br=hist.br,main=paste(sample.names[i],\", # resampling: \",nresmpl,sep=\"\"))\n      dev.off()\n    }\n\n  } # main sample loop END\n\n  # MCT correction\n\n  BH.FDR<-nominal.p*num.samples/rank(nominal.p)\n  Bonferroni.p<-nominal.p*num.samples\n\n  BH.FDR[BH.FDR>1]<-1\n  Bonferroni.p[Bonferroni.p>1]<-1\n\n  ### output ###\n\n  # prediction results\n\n  dist.to.cls1.rank <- rank(dist.to.cls1)\n  pred.summary <- cbind(sample.names,predict.label,dist.to.template,dist.to.cls1.rank,\n              nominal.p,BH.FDR,Bonferroni.p)\n\n  write.table(pred.summary,paste(output.name,\"_prediction_result.xls\",sep=\"\"),\n              quote=F,sep=\"\\t\",row.names=F)\n\n  # extracted features\n\n  if (temp.nn.wt==\"T\" & num.cls==2){\n    write.table(features.extract[,2:5],paste(output.name,\"_features.xls\",sep=\"\"),\n              quote=F,sep=\"\\t\",row.names=F)\n  }\n  if (temp.nn.wt==\"F\"){\n    write.table(features.extract[,2:4],paste(output.name,\"_features.xls\",sep=\"\"),\n              quote=F,sep=\"\\t\",row.names=F)\n  }\n\n  # sorted exp dataset for heatmap (row normalized)\n\n  t.dataset<-t(exp.dataset.extract)               # sort samples\n  t.dataset<-cbind(dist.to.cls1,t.dataset)\n  ts.dataset<-t.dataset[order(t.dataset[,1]),]\n  to.dataset.out<-ts.dataset[,2:(num.features.extract+1)]\n\n  sorted.dataset<-t(to.dataset.out)\n  heatmap.dataset<-as.matrix(sorted.dataset)\n#  if (.Platform$OS.type == \"windows\") {\n#    sorted.dataset<-matrix(gsub(\" \",\"\",sorted.dataset),ncol=(num.samples+2))\n#  }\n\n  # sorted exp dataset for spreadsheets (not normalized)\n\n  exp.dataset.gannot<-cbind(ProbeID,exp.dataset)\n  exp.dataset.extract<-merge(features.extract,exp.dataset.gannot,sort=F) # redefine exp.dataset.extract\n\n  order.extract<-order(exp.dataset.extract[,2])   # sort genes\n  exp.dataset.extract<-exp.dataset.extract[order.extract,]\n  if (temp.nn.wt==\"T\" & num.cls==2){\n    exp.dataset.extract<-exp.dataset.extract[-c(1:5)]\n  }\n  if (temp.nn.wt==\"F\"){\n    exp.dataset.extract<-exp.dataset.extract[-c(1:4)]\n  }\n\n  t.dataset<-t(exp.dataset.extract)               # sort samples\n  t.dataset<-cbind(dist.to.cls1,t.dataset)\n  ts.dataset<-t.dataset[order(t.dataset[,1]),]\n  to.dataset.out<-ts.dataset[,2:(num.features.extract+1)]\n\n  sorted.dataset<-t(to.dataset.out)\n  sorted.dataset<-cbind(features.extract[,2:3],sorted.dataset)\n\n  sorted.dataset.header<-c(\"ProbeID\",\"GeneName\",sample.names[order(t.dataset[,1])])\n  sorted.dataset<-t(cbind(sorted.dataset.header,t(sorted.dataset)))\n\n  if (.Platform$OS.type == \"windows\") {\n    sorted.dataset<-matrix(gsub(\" \",\"\",sorted.dataset),ncol=(num.samples+2))\n  }\n\n  # output for GenePattern\n\n  if (GenePattern.output==\"T\"){\n\n    # exp data\n    write.table(\"#1.2\",paste(output.name,\"_sorted.dataset.gct\",sep=\"\")\n                ,quote=F,sep=\"\\t\",row.names=F,col.names=F)\n    write.table(paste(num.features.extract,num.samples,sep=\"\\t\"),paste(output.name,\"_sorted.dataset.gct\",sep=\"\")\n                ,quote=F,sep=\"\\t\",row.names=F,col.names=F,append=T)\n    write.table(sorted.dataset,paste(output.name,\"_sorted.dataset.gct\",sep=\"\"),\n              quote=F,sep=\"\\t\",row.names=F,col.names=F,append=T)\n\n    # cls ffiles (unsorted, sorted)\n    cls.out<-matrix(0,nrow=3,ncol=1)\n\n    ## unsorted cls\n    cls.out[1,]<-paste(num.samples,\" \",num.cls,\" 1\",sep=\"\")  # line 1\n    cls.out[2,]<-paste(\"# \",paste(unique(predict.label),collapse=\" \")) # line 2\n    predict.label.out<-as.numeric(predict.label)-1                      # line 3\n    cls.out[3,]<-paste(predict.label.out,collapse=\" \")\n\n    write.table(cls.out,paste(output.name,\"_predicted_unsorted.cls\",sep=\"\"),\n              quote=F,sep=\"\\t\",row.names=F,col.names=F)\n\n    ## sorted cls\n    sorted.predict.label<-sort(as.numeric(predict.label))\n    cls.out[2,]<-paste(\"# \",paste(unique(sorted.predict.label),collapse=\" \")) # line 2\n    predict.label.out<-sorted.predict.label-1    # line 3\n    cls.out[3,]<-paste(predict.label.out,collapse=\" \")\n\n    write.table(cls.out,paste(output.name,\"_predicted_sorted.cls\",sep=\"\"),\n              quote=F,sep=\"\\t\",row.names=F,col.names=F)\n\n    # sample info\n    sample.info<-cbind(sample.names,predict.label)\n    write.table(sample.info,paste(output.name,\"_sample_info.txt\",sep=\"\"),\n              quote=F,sep=\"\\t\",row.names=F)\n  }\n\n  # output for dChip\n\n  if (dchip.output==\"T\"){\n\n    # exp data\n    write.table(sorted.dataset,paste(output.name,\"_dChip_sorted.dataset.txt\",sep=\"\"),\n              quote=F,sep=\"\\t\",row.names=F,col.names=F)\n\n    # sample info\n    sample.info<-cbind(sample.names,sample.names,predict.label)\n    write.table(sample.info,paste(output.name,\"_dChip_sample_info.txt\",sep=\"\"),\n              quote=F,sep=\"\\t\",row.names=F)\n\n    # gene info\n    dchip.gene.info<-cbind(features.extract[,2:3],NA,features.extract[,3],features.extract[,4],NA)\n    colnames(dchip.gene.info)<-c(\"Probe Set\",\"Identifier\",\"FirstOfLocuslink\",\"FirstOfName\",\"FirstOfFunction\",\"Description\")\n    write.table(dchip.gene.info,paste(output.name,\"_dChip_gene_info.txt\",sep=\"\"),\n              quote=F,sep=\"\\t\",row.names=F)\n  }\n\n  # heatmap\n\n  if (signature.heatmap==\"T\" & capabilities(\"png\")==T){\n\n    subclass.col.source <- c(\"red\",\"blue\",\"yellow\",\"green\",\"purple\",\"orange\",\"lightblue\",\"darkgreen\")\n    predict.col.vector <- unique(sort(predict.label))\n    subclass.col <- subclass.col.source[predict.col.vector]\n\n    heatmap.col <- c(\"#0000FF\", \"#0000FF\", \"#4040FF\", \"#7070FF\", \"#8888FF\", \"#A9A9FF\", \"#D5D5FF\", \"#EEE5EE\", \"#FFAADA\", \"#FF9DB0\", \"#FF7080\", \"#FF5A5A\", \"#FF4040\", \"#FF0D1D\", \"#FF0000\")\n\n    heatmap.dataset[heatmap.dataset>col.range] <- col.range\n    heatmap.dataset[heatmap.dataset< -col.range] <- -col.range # bug fixed 06/18/2012\n\n    ncol.heat <- length(heatmap.dataset[1,])\n    nrow.heat <- length(heatmap.dataset[,1])\n\n    heatmap.dataset <- apply(heatmap.dataset,2,rev)\n\n    num.pred <- as.vector(table(predict.label))\n    num.pred.gene <- as.vector(table(features.extract[,4]))\n\n    increment.sample <- cumsum(num.pred)\n    increment.sample <- c(0,increment.sample)\n\n    increment.gene <- cumsum(num.pred.gene)\n    increment.gene <- c(0,increment.gene)\n\n    png(paste(output.name,\"_heatmap.png\",sep=\"\"))\n      image(1:ncol.heat,1:nrow.heat,t(heatmap.dataset),axes=F,col=heatmap.col,zlim=c(-col.range,col.range),xlim=c(-0.5,(ncol.heat+0.5+round(ncol.heat*0.05))),ylim=c(-0.5,(nrow.heat+0.5+round(nrow.heat*0.08))),xlab=NA,ylab=NA)\n\n      for (c in 1:num.cls){                          # gene bar\n        rect((ncol.heat+1),0.5,(ncol.heat+0.5+round(ncol.heat*0.05)),(nrow.heat+0.5-increment.gene[c]),col=subclass.col[c],xpd=T,border=F)\n      }\n      for (c in 1:length(num.pred)){               # sample bar\n        rect((0.5+increment.sample[c]),(nrow.heat+2),(ncol.heat+0.5),(nrow.heat+0.5+round(nrow.heat*0.08)),col=subclass.col[c],xpd=T,border=F)\n      }\n    dev.off()\n\n    # heatmap legend\n\n    if (heatmap.legend==\"T\"){\n      png(paste(output.name,\"_heatmap_legend.png\",sep=\"\"))\n        par(plt=c(.1,.9,.45,.5))\n        a=matrix(seq(1:15),nc=1)\n        image(a,col=heatmap.col,xlim=c(0,1),axes=F,yaxt=\"n\")\n        box()\n      dev.off()\n    }\n\n    # FDR sample bar\n\n    if (FDR.sample.bar!=\"NA\" & num.cls==2){\n      fdr.bar.vector <- predict.label[order(dist.to.cls1.rank)]\n      fdr.bar.vector[which(BH.FDR[order(dist.to.cls1.rank)]>=FDR.sample.bar)] <- 3\n      png(paste(output.name,\"_FDR_\",FDR.sample.bar,\"_sample_bar.png\",sep=\"\"))\n        par(plt=c(.1,.9,.45,.5))\n        a=matrix(fdr.bar.vector,nc=1)\n        image(a,col=c(\"red\",\"blue\",\"gray\"),axes=F,yaxt=\"n\")\n      dev.off()\n    }\n\n    if (FDR.sample.bar!=\"NA\" & num.cls>2){\n      fdr.bar.vector <- predict.label[order(dist.to.cls1.rank)]\n      fdr.bar.vector[which(BH.FDR[order(dist.to.cls1.rank)]>=FDR.sample.bar)] <- (num.cls+1)\n      uni.fdr.bar.vector <- sort(unique(fdr.bar.vector))\n      if (length(uni.fdr.bar.vector)>1){\n        n.sig.cls <- length(uni.fdr.bar.vector)-1\n        uni.fdr.bar.vector <- uni.fdr.bar.vector[1:n.sig.cls]\n      }else{\n        uni.fdr.bar.vector <- NULL\n      }\n\n      sig.subclass.col <- c(subclass.col.source[1:num.cls],\"gray\")\n      png(paste(output.name,\"_FDR_\",FDR.sample.bar,\"_sample_bar.png\",sep=\"\"))\n        par(plt=c(.1,.9,.45,.5))\n        a=matrix(fdr.bar.vector,nc=1)\n        image(a,col=sig.subclass.col,axes=F,yaxt=\"n\")\n      dev.off()\n    }\n\n  }\n\n  # plot FDR\n\n  if (plot.FDR==\"T\" & capabilities(\"png\")==T){\n    png(paste(output.name,\"_FDR.png\",sep=\"\"))\n      par(plt=c(0.1,0.95,0.4,0.6),las=2)\n      plot(BH.FDR[order(dist.to.cls1)],pch=3,col=\"blue\",lwd=2,ylim=c(0,1),main=\"BH-FDR\")\n      box(lwd=2)\n    dev.off()\n  }\n\n  # plot nominal-p\n\n  if (plot.nominal.p==\"T\" & capabilities(\"png\")==T){\n    png(paste(output.name,\"_nominal.p.png\",sep=\"\"))\n      par(plt=c(0.1,0.95,0.4,0.6),las=2)\n      plot(nominal.p[order(dist.to.cls1)],pch=3,col=\"blue\",lwd=2,ylim=c(0,1),main=\"nominal p-value\")\n      box(lwd=2)\n    dev.off()\n  }\n\n  # plot distance to template\n\n  if (plot.distance==\"T\" & capabilities(\"png\")==T){\n    png(paste(output.name,\"_distance.png\",sep=\"\"))\n      par(plt=c(0.1,0.95,0.4,0.6),las=2)\n      plot(dist.to.template[order(dist.to.cls1)],pch=3,col=\"blue\",lwd=2,ylim=c(0,1),main=paste(\"1 - \",dist.selection,sep=\"\"))\n      box(lwd=2)\n    dev.off()\n  }\n\n}  # END main\n\n# Added for Rscript call.\nopts <- commandArgs(trailingOnly=T)\nNTPez(\n  input.exp.filename <- opts[1],\n  input.features.filename <- opts[2],\n  output.name  <- opts[3],\n  dist.selection  <- opts[4],\n  temp.nn.wt  <- opts[5],\n  nresmpl  <- opts[6],\n  GenePattern.output  <- opts[7],\n  rnd.seed  <- opts[8]\n)"}, {"role": "assistant", "content": "#NearestTemplatePrediction\n#Tue Jan 13 15:01:33 EST 2009\nJVMLevel=\nauthor=Yujin Hoshida (Broad Institute)\ncommandLine=<R3.1_Rscript> <libdir>NTPez.R <input.exp.filename> <input.features.filename> <output.name> <distance.selection> <weight.genes> <num.resamplings> <GenePattern.output> <random.seed>\ncpuType=any\ndescription=Nearest neighbor prediction based on a list of marker genes\nfileFormat=gct;png;txt;xls;cls\nlanguage=R-3.1.3\nname=NearestTemplatePrediction\nos=any\n\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=Gene expression data set (.gct)\np1_fileFormat=gct\np1_name=input.exp.filename\np1_optional=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\n\np2_MODE=IN\np2_TYPE=FILE\np2_default_value=\np2_description=List of marker genes (.txt)\\: Probe ID, Gene name, Class (1,2,...), Weight (optional)\np2_fileFormat=txt\np2_name=input.features.filename\np2_optional=\np2_prefix_when_specified=\np2_type=java.io.File\np2_value=\n\np3_default_value=NTP\np3_description=Name for output files\np3_fileFormat=\np3_name=output.name\np3_optional=\np3_prefix_when_specified=\np3_type=java.lang.String\np3_value=\n\np4_default_value=cosine\np4_description=Distance metric\np4_fileFormat=\np4_name=distance.selection\np4_optional=\np4_prefix_when_specified=\np4_type=java.lang.String\np4_value=cosine\\=cosine;correlation\\=correlation\n\np5_default_value=T\np5_description=Weight genes? (by statistic, fold change, etc. only for 2 classes)\np5_fileFormat=\np5_name=weight.genes\np5_optional=\np5_prefix_when_specified=\np5_type=java.lang.String\np5_value=T\\=yes;F\\=no\n\np6_default_value=1000\np6_description=\\# resampling to generate null distribution for distance metric\np6_fileFormat=\np6_name=num.resamplings\np6_optional=\np6_prefix_when_specified=\np6_type=java.lang.Integer\np6_value=\n\np7_default_value=F\np7_description=Create .gct and .cls files for GenePattern\np7_fileFormat=\np7_name=GenePattern.output\np7_optional=\np7_prefix_when_specified=\np7_type=java.lang.String\np7_value=T\\=yes;F\\=no\n\np8_default_value=7392854\np8_description=Random seed\np8_fileFormat=\np8_name=random.seed\np8_optional=\np8_prefix_when_specified=\np8_type=java.lang.Integer\np8_value=\n\npipelineModel=\nprivacy=public\nquality=preproduction\ntaskDoc=doc.html\nrequiredPatchLSIDs=\nrequiredPatchURLs=\nserializedModel=\ntaskType=Prediction\nuserid=hoshida@broad.mit.edu\nversion=Updated to use R-3.1 and added HTML documentation."}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "nmfconsensus <- function(input.ds, k.init, k.final, num.clusterings, maxniter, error.function, rseed=123456789, stopconvergence = 40, stopfrequency = 10, non.interactive.run = F, doc.string = \"\", ...) {\n\ndirectory = \"\"\ntime.string <- as.character(as.POSIXlt(Sys.time(),\"GMT\"))\nif (non.interactive.run == \"F\"){ \n\tfilename <- paste(directory, doc.string, \".params.txt\", sep=\"\", collapse=\"\")  \n\twrite(paste(\"Run of NMF on \", time.string), file=filename)\n\n\twrite(paste(\"input.ds =\", input.ds, sep=\" \"), file=filename, append=T) \n\twrite(paste(\"k.init = \", k.init, sep=\" \"), file=filename, append=T) \n\twrite(paste(\"k.final =\", k.final, sep=\" \"), file=filename, append=T) \n\twrite(paste(\"num.clusterings =\", num.clusterings, sep=\" \"), file=filename, append=T) \n\twrite(paste(\"maxniter =\", maxniter, sep=\" \"), file=filename, append=T) \n\twrite(paste(\"error.function =\", error.function, sep=\" \"), file=filename, append=T) \n\twrite(paste(\"rseed =\", rseed, sep=\" \"), file=filename, append=T) \n\twrite(paste(\"directory =\", directory, sep=\" \"), file=filename, append=T) \n\twrite(paste(\"stopconv =\", stopconvergence, sep=\" \"), file=filename, append=T) \n\twrite(paste(\"stopfreq =\", stopfrequency, sep=\" \"), file=filename, append=T)\n\twrite(paste(\"non.interctive.run =\", non.interactive.run, sep=\" \"), file=filename, append=T) \n\twrite(paste(\"doc.string =\", doc.string, sep=\" \"), file=filename, append=T) \n}\n\n\nk.init<-as.integer(k.init)\nk.final<-as.integer(k.final)\nnum.clusterings<-as.integer(num.clusterings)\nn.iter<-as.integer(maxniter)\nif (!is.na(rseed)){\n     seed <- as.integer(rseed)\n}\nstopfreq <- as.integer(stopfrequency)\nstopconv <- as.integer(stopconvergence)\n# library(mva)\n# library(MASS)\n# library(GenePattern)\n\nD <- read.dataset(input.ds)\nA <- data.matrix(D)\n\n# Threshold negative values to small quantity \n\neps <- .Machine$double.eps\nA[A < 0] <- eps\n\n\n\ncols <- length(A[1,])\nrows <- length(A[,1])\n\ncol.names <- names(D)\n\nnum.k <- k.final - k.init + 1\n\nrho <- vector(mode = \"numeric\", length = num.k)\nk.vector <- vector(mode = \"numeric\", length = num.k)\n\nk.index <- 1\n\nconnect.matrix.ordered <- array(0, c(num.k, cols, cols))\n\nfor (k in k.init:k.final) { \n\n   if (non.interactive.run == F) {\n         if (.Platform$OS.type == \"windows\") {\n             filename <- paste(directory, doc.string, \".\", \"graphs.k\", k, sep=\"\", collapse=\"\")\n             windows(width = 9, height = 11)\n         } else if (.Platform$OS.type == \"unix\") {\n             filename <- paste(directory, doc.string, \".\", \"graphs.k\", k, \".pdf\", sep=\"\", collapse=\"\")\n             pdf(file=filename, width = 9, height = 11)\n         }\n   } else {\n         if (.Platform$OS.type == \"unix\") {\n             filename <- paste(directory, doc.string, \".\", \"graphs.k\", k, \".pdf\", sep=\"\", collapse=\"\")\n             pdf(file=filename, width = 9, height = 11)\n         } else if (.Platform$OS.type == \"windows\") {\n             filename <- paste(directory, doc.string, \".\", \"graphs.k\", k, \".pdf\", sep=\"\", collapse=\"\")\n             pdf(file=filename, width = 9, height = 11)\n         }\n   }\n\n   nf <- layout(matrix(c(1,2,3,4,5,6,7,8), 4, 2, byrow=T), c(1, 1, 1, 1), c(1, 1), TRUE)\n   assign <- matrix(0, nrow = num.clusterings, ncol = cols)\n\n   for (i in 1:num.clusterings) {\n\t  \n\tif (non.interactive.run == \"F\"){\n        print(paste(\"Computing clustering number=\", i, \" for k=\", k, sep=\"\", collapse=\" \"))\n\t}\n\n        if (error.function == \"divergence\"){\n\t    NMF.out <- NMF.div(V = A, k = k, maxniter = n.iter, seed = seed + i, stopconv = stopconv, stopfreq = stopfreq)\n\t} else if (error.function == \"euclidean\"){\n\t    NMF.out <- NMF(V = A, k = k, maxniter = n.iter, seed = seed + i, stopconv = stopconv, stopfreq = stopfreq)\n\t} else {\n            stop(paste(\"Un-supported error function=\", error.function, sep=\"\"))\n        }\n\tif (non.interactive.run == \"F\"){\n        print(paste(NMF.out$t, \" NMF iterations performed\", sep=\"\", collapse=\" \"))\n\t}\n\n        for (j in 1:cols) { # Find membership\n            class <- order(NMF.out$H[,j], decreasing=T)\n            assign[i, j] <- class[1]\n        }\n\n\tif (i == 3) {  # '2''20 example for first clustering iteration\n            H.saved <- NMF.out$H\n            sub.string <- paste(doc.string, \" k=\", k, sep=\"\")\n            plot(1:NMF.out$t, NMF.out$error.v[1:NMF.out$t], pch = 20, cex = 1.5, col = 1, xlab=\"time\", ylab=\"NMF error\", sub=sub.string, main=paste(\"Example of NMF convergence plot k=\", k, sep=\"\"))\n\n\n            if (rows < 1000) {\n               W <- NMF.out$W\n            } else {\n               W <- NMF.out$W[sample(x = 1:rows, size = 1000),]\n            }\n            sub.string <- paste(doc.string, \" k=\", k, sep=\"\")\n            matrix.abs.plot(W, sub = sub.string, log = F, main = \"Example W matrix (orig. ordering)\", ylab = \"genes\", xlab =\"metasamples\")\n            matrix.abs.plot(H.saved, sub = sub.string, log = F, main = \"Example H matrix (orig. ordering)\", ylab = \"metagenes\", xlab =\"samples\")\n            metagene.plot(H = H.saved, main = \"Example metagenes (orig. ordering)\", sub = sub.string, xlab = \"samples\", ylab = \"metagenes\")\n\n        }\n\n        rm(NMF.out)\n\n     }  ## end  for (i in 1:num.clusterings)\n\n   \n     # compute consensus matrix\n     connect.matrix <- matrix(0, nrow = cols, ncol = cols)\n\n     for (i in 1:num.clusterings) {\n       for (j in 1:cols) {\n          for (p in 1:cols) {\n             if (j != p) {\n                  if (assign[i, j] == assign[i, p]) {\n                    connect.matrix[j, p] <- connect.matrix[j, p] + 1\n                  } \n              } else {\n                    connect.matrix[j, p] <- connect.matrix[j, p] + 1\n              }\n           }\n       }\n     }\n\n     connect.matrix <- connect.matrix / num.clusterings\n\n     dist.matrix <- 1 - connect.matrix\n     dist.matrix <- as.dist(dist.matrix)\n     HC <- hclust(dist.matrix, method=\"average\")\n\n     dist.coph <- cophenetic(HC)\n     k.vector[k.index] <- k\n     rho[k.index] <- cor(dist.matrix, dist.coph)\n     rho[k.index] <- signif(rho[k.index], digits = 4)\n   \n#     connect.matrix.ordered <- matrix(0, nrow=cols, ncol = cols)\n\n     for (i in 1:cols) {\n        for (j in 1:cols) {\n           connect.matrix.ordered[k.index, i, j] <- connect.matrix[HC$order[i], HC$order[j]]\n         }\n     }\n\n     # compute consensus clustering membership\n\n     membership <- cutree(HC, k = k)\n\n     max.k <- max(membership)\n     items.names.ordered <- col.names[HC$order]\n     membership.ordered <- membership[HC$order]\n     results <- data.frame(cbind(membership.ordered, items.names.ordered))\n\n     if (k > k.init){\n          all.membership <- cbind(all.membership, membership);\n     } else {\n          all.membership <- cbind(membership);\n     }\n\n     sub.string <- paste(doc.string, \" k=\", k, sep=\"\")\n     matrix.abs.plot(connect.matrix.ordered[k.index,,], sub=sub.string, log = F, main = \"Ordered Consensus Matrix\", ylab = \"samples\", xlab =\"samples\")\n     plot(HC, xlab=\"samples\", cex = 0.75, labels = col.names, sub = sub.string, col = \"blue\", main = paste(\"Ordered Linkage Tree. Coph=\", rho[k.index]))\n\n     resultsGct <- data.frame(membership.ordered)\n     row.names(resultsGct) <- items.names.ordered\n     filename <- paste(directory, doc.string, \".\", \"consensus.k.\",k, \".gct\", sep=\"\", collapse=\"\")\n     write.gct(resultsGct, filename)\n\n     H.sorted <- H.saved[,HC$order]\n     sub.string <- paste(doc.string, \" k=\", k, sep=\"\")\n     matrix.abs.plot(H.sorted, sub = sub.string, log = F, main = \"Example H matrix (ordered)\", ylab = \"metagenes\", xlab =\"samples\")\n     metagene.plot(H = H.sorted, sub = sub.string, main = \"Example metagenes (ordered)\", xlab = \"samples\", ylab = \"metagenes\")\n\n     if (non.interactive.run == F) {  \n           if (.Platform$OS.type == \"windows\") {\n               savePlot(filename = filename, type =\"jpeg\", device = dev.cur())\n           } else if (.Platform$OS.type == \"unix\") {\n               dev.off()\n           }\n      } else {\n           dev.off()\n      }\n\n   if (non.interactive.run == F) {\n         if (.Platform$OS.type == \"windows\") {\n             filename <- paste(directory, doc.string, \".\", \"consensus.plot.k\", k, sep=\"\", collapse=\"\")\n             windows(width = 8.5, height = 11)\n         } else if (.Platform$OS.type == \"unix\") {\n             filename <- paste(directory, doc.string, \".\", \"consensus.plot.k\", k, \".pdf\", sep=\"\", collapse=\"\")\n             pdf(file=filename, width = 8.5, height = 11)\n         }\n   } else {\n         if (.Platform$OS.type == \"unix\") {\n            filename <- paste(directory, doc.string, \".\", \"consensus.plot.k\", k, \".pdf\", sep=\"\", collapse=\"\")\n             pdf(file=filename, width = 8.5, height = 11)\n         } else if (.Platform$OS.type == \"windows\") {\n            filename <- paste(directory, doc.string, \".\", \"consensus.plot.k\", k, \".pdf\", sep=\"\", collapse=\"\")\n            pdf(file=filename, width = 8.5, height = 11)\n         }\n   }\n\n     nf <- layout(matrix(c(1), 1, 1, byrow=T), c(1, 1), c(1, 1), TRUE)\n\n     conlabel <- paste(\"Consensus k =\", k, sep=\" \", collapse=\"\")\n\n     sub.string <- paste(\"Consensus matrix k=\", k, \"; dataset= \", input.ds, sep=\"\")\n     ConsPlot(connect.matrix.ordered[k.index,,], col.labels = membership.ordered, col.names = items.names.ordered, main = \" \", sub=sub.string, xlab=\" \", ylab=\" \")\n\n      if (non.interactive.run == F) {  \n           if (.Platform$OS.type == \"windows\") {\n               savePlot(filename = filename, type =\"jpeg\", device = dev.cur())\n           } else if (.Platform$OS.type == \"unix\") {\n               dev.off()\n           }\n      } else {\n           dev.off()\n      }\n  \n     k.index <- k.index + 1\n\n} # end of loop over k\n\n\n# Save consensus matrices in one file\n\n   if (non.interactive.run == F) {\n         if (.Platform$OS.type == \"windows\") {\n             filename <- paste(directory, doc.string, \".\", \"consensus.all.k.plot\", sep=\"\")\n             windows(width = 8.5, height = 11)\n         } else if (.Platform$OS.type == \"unix\") {\n             filename <- paste(directory, doc.string, \".\", \"consensus.all.k.plot.pdf\", sep=\"\")\n             pdf(file=filename, width = 8.5, height = 11)\n         }\n   } else {\n         if (.Platform$OS.type == \"unix\") {\n            filename <- paste(directory, doc.string, \".\", \"consensus.all.k.plot.pdf\", sep=\"\")\n            pdf(file=filename, width = 8.5, height = 11)\n         } else if (.Platform$OS.type == \"windows\") {\n            filename <- paste(directory, doc.string, \".\", \"consensus.all.k.plot.pdf\", sep=\"\")\n            pdf(file=filename, width = 8.5, height = 11)\n         }\n   }\n\n   nf <- layout(matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16), 4, 4, byrow=T), c(1, 1, 1, 1), c(1, 1, 1, 1), TRUE)\n\n  for (k in 1:num.k) { \n     matrix.abs.plot(connect.matrix.ordered[k,,], log = F, main = paste(\"k=\", k.vector[k]), \n                          sub = paste(\"Cophenetic coef.=\", rho[k]), ylab = \"samples\", xlab =\"samples\")\n  }\n   \n  y.range <- c(1 - 2*(1 - min(rho)), 1)\n  plot(k.vector, rho, main =\"Cophenetic Coefficient\", xlim=c(k.init, k.final), ylim=y.range, \n                          xlab = \"k\", ylab=\"Cophenetic correlation\", type = \"n\")\n  lines(k.vector, rho, type = \"l\", col = \"black\")\n  points(k.vector, rho, pch=22, type = \"p\", cex = 1.25, bg = \"black\", col = \"black\")\n\n  if (non.interactive.run == F) {  \n        if (.Platform$OS.type == \"windows\") {\n            savePlot(filename = filename, type =\"jpeg\", device = dev.cur())\n        } else if (.Platform$OS.type == \"unix\") {\n            dev.off()\n        }\n   } else {\n        dev.off()\n   }\n\n   if (non.interactive.run == F) {\n         if (.Platform$OS.type == \"windows\") {\n             filename <- paste(directory, doc.string, \".\", \"cophenetic.plot\", sep=\"\")\n             windows(width = 8.5, height = 11)\n         } else if (.Platform$OS.type == \"unix\") {\n             filename <- paste(directory, doc.string, \".\", \"cophenetic.plot.pdf\", sep=\"\")\n             pdf(file=filename, width = 8.5, height = 11)\n         }\n   } else {\n         if (.Platform$OS.type == \"unix\") {\n            filename <- paste(directory, doc.string, \".\", \"cophenetic.plot.pdf\", sep=\"\")\n             pdf(file=filename, width = 8.5, height = 11)\n         } else if (.Platform$OS.type == \"windows\") {\n            filename <- paste(directory, doc.string, \".\", \"cophenetic.plot.pdf\", sep=\"\")\n             pdf(file=filename, width = 8.5, height = 11)\n         }\n   }\n\n\n# Write the membership matrix\n\nresultsmembership <- data.frame(all.membership)\nrow.names(resultsmembership) <- col.names\nfilename <- paste(directory, doc.string, \".\", \"membership\", \".gct\", sep=\"\", collapse=\"\")\nwrite.gct(resultsmembership , filename)\n\ny.range <- c(1 - 2*(1 - min(rho)), 1)\nplot(k.vector, rho, main =\"Cophenetic Coefficient\", xlim=c(k.init, k.final), ylim=y.range, xlab = \"k\", ylab=\"Cophenetic correlation\", type = \"n\")\nlines(k.vector, rho, type = \"l\", col = \"black\")\npoints(k.vector, rho, pch=22, type = \"p\", cex = 1.25, bg = \"black\", col = \"black\")\n\n      if (non.interactive.run == F) {  \n           if (.Platform$OS.type == \"windows\") {\n               savePlot(filename = filename, type =\"jpeg\", device = dev.cur())\n           } else if (.Platform$OS.type == \"unix\") {\n               dev.off()\n           }\n      } else {\n           dev.off()\n      }\n\nxx <- cbind(k.vector, rho)\nwrite(xx, file= paste(directory, doc.string, \".\", \"cophenetic.txt\", sep=\"\"))\n}\n\n\nread.dataset <- function(file) {\n\tresult <- regexpr(paste(\".gct\",\"$\",sep=\"\"), tolower(file))\n\tif(result[[1]] != -1)\n\t\treturn(read.gct(file))\n\tresult <- regexpr(paste(\".res\",\"$\",sep=\"\"), tolower(file))\n\tif(result[[1]] != -1)\n\t\treturn(read.res(file))\n\tstop(\"Input is not a res or gct file.\")\t\n}\n\nmatrix.abs.plot <- function(V, axes = F, log = F, norm = T, transpose = T, matrix.order = T, max.v = 1, min.v = 0, main = \" \", sub = \" \", xlab = \" \", ylab = \"  \") {\n      rows <- length(V[,1])\n      cols <- length(V[1,])\n      if (log == T) {\n         V <- log(V)\n      }\n      B <- matrix(0, nrow=rows, ncol=cols)\n\tfor (i in 1:rows) {\n           for (j in 1:cols) {\n                if (matrix.order == T) {\n                   k <- rows - i + 1\n                } else {\n                   k <- i\n                }\n                if (norm == T) {\n                  if ((max.v == 1) && (min.v == 0)) {\n                     max.val <- max(V)\n                     min.val <- min(V)\n                  } else {\n\t\t     \t   max.val = max.v\n                     min.val = min.v\n                  }\n               }\n\t     B[k, j] <-  max.val - V[i, j] + min.val\n           }\n      }\n\tif (transpose == T) {\n\t  B <- t(B)\n        }\n\tif (norm == T) {\n            image(z = B, zlim = c(min.val, max.val), axes = axes, col = rainbow(100, s = 1.0, v = 0.75, start = 0.0, end = 0.75, gamma = 1.5), main = main, sub = sub, xlab = xlab, ylab = ylab) \n      } else {\n            image(z = B, axes = axes, col = rainbow(100, s = 1, v = 0.6, start = 0.1, end = 0.9, gamma = 1), main = main, sub = sub, xlab = xlab, ylab = ylab) \n      }\n      return(list(B, max.val, min.val))\n}\n\nmetagene.plot <- function(H, main = \" \", sub = \" \", xlab = \"samples \", ylab = \"amplitude\") {\n\tk <- length(H[,1])\n\tS <- length(H[1,])\n\tindex <- 1:S\n\tmaxval <- max(H)\n        minval <- min(H)\n\tplot(index, H[1,], xlim=c(1, S), ylim=c(minval, maxval), main = main, sub = sub, ylab = ylab, xlab = xlab, type=\"n\")\n\tfor (i in 1:k) {\n\t    lines(index, H[i,], type=\"l\", col = i, lwd=2)\n        }\n}\n\nNMF <- function(V, k, maxniter = 2000, seed = 123456, stopconv = 40, stopfreq = 10) {\n        N <- length(V[,1])\n        M <- length(V[1,])\n        set.seed(seed)\n        W <- matrix(runif(N*k), nrow = N, ncol = k)  # Initialize W and H with random numbers\n        H <- matrix(runif(k*M), nrow = k, ncol = M)\n\n\n        VP <- matrix(nrow = N, ncol = M)\n\n\n        error.v <- vector(mode = \"numeric\", length = maxniter)\n        new.membership <- vector(mode = \"numeric\", length = M)\n        old.membership <- vector(mode = \"numeric\", length = M)\n        eps <- .Machine$double.eps\n        for (t in 1:maxniter) {\n\n              VP = W %*% H\n\n              H <- H * (crossprod(W, V)/crossprod(W, VP)) + eps\n\t\t  VP = W %*% H\n              H.t <- t(H)\n              W <- W * (V %*% H.t)/(VP %*% H.t) + eps\n              error.v[t] <- sqrt(sum((V - VP)^2))/(N * M)\n               if (t %% stopfreq == 0) {\n                    for (j in 1:M) {\n                        class <- order(H[,j], decreasing=T)\n                        new.membership[j] <- class[1]\n                     }\n                     if (sum(new.membership == old.membership) == M) {\n                        no.change.count <- no.change.count + 1\n                     } else {\n                        no.change.count <- 0\n                     }\n                     if (no.change.count == stopconv) break\n                     old.membership <- new.membership\n               }\n        }\n        return(list(W = W, H = H, t = t, error.v = error.v))\n}\n\nNMF.div <- function(V, k, maxniter = 2000, seed = 123456, stopconv = 40, stopfreq = 10) {\n\n        N <- length(V[,1])\n        M <- length(V[1,])\n        set.seed(seed)\n        W <- matrix(runif(N*k), nrow = N, ncol = k)  # Initialize W and H with random numbers\n        H <- matrix(runif(k*M), nrow = k, ncol = M)\n        VP <- matrix(nrow = N, ncol = M)\n        error.v <- vector(mode = \"numeric\", length = maxniter)\n        new.membership <- vector(mode = \"numeric\", length = M)\n        old.membership <- vector(mode = \"numeric\", length = M)\n        no.change.count <- 0\n        eps <- .Machine$double.eps\n        for (t in 1:maxniter) {\n                VP = W %*% H\n                W.t <- t(W)\n                H <- H * (W.t %*% (V/VP)) + eps\n                norm <- apply(W, MARGIN=2, FUN=sum)\n                for (i in 1:k) {\n                    H[i,] <- H[i,]/norm[i]\n                }\n                VP = W %*% H\n                H.t <- t(H)\n                W <- W * ((V/VP) %*% H.t) + eps\n                norm <- apply(H, MARGIN=1, FUN=sum)\n                for (i in 1:k) {\n                    W[,i] <- W[,i]/norm[i]\n                }\n               error.v[t] <- sum(V * log((V + eps)/(VP + eps)) - V + VP)/(M * N)\n               if (t %% stopfreq == 0) {\n\n                    for (j in 1:M) {\n                        class <- order(H[,j], decreasing=T)\n                        new.membership[j] <- class[1]\n                     }\n                     if (sum(new.membership == old.membership) == M) {\n                        no.change.count <- no.change.count + 1\n                     } else {\n                        no.change.count <- 0\n                     }\n                     if (no.change.count == stopconv) break\n                     old.membership <- new.membership\n               }\n        }\n        return(list(W = W, H = H, t = t, error.v = error.v))\n}\n\nConsPlot <- function(V, col.labels, col.names, main = \" \", sub = \" \", xlab=\" \", ylab=\" \") {\n\n# Plots a heatmap plot of a consensus matrix\n\n     cols <- length(V[1,])\n     B <- matrix(0, nrow=cols, ncol=cols)\n     max.val <- max(V)\n     min.val <- min(V)\n     for (i in 1:cols) {\n         for (j in 1:cols) {\n             k <- cols - i + 1\n\t     B[k, j] <-  max.val - V[i, j] + min.val\n          }\n     }\n\n     col.names2 <- rev(col.names)\n     col.labels2 <- rev(col.labels)\n     D <- matrix(0, nrow=(cols + 1), ncol=(cols + 1))\n\n     col.tag <- vector(length=cols, mode=\"numeric\")\n     current.tag <- 0\n     col.tag[1] <- current.tag\n     for (i in 2:cols) {\n        if (col.labels[i] != col.labels[i - 1]) {\n             current.tag <- 1 - current.tag\n        }\n        col.tag[i] <- current.tag\n     }\n     col.tag2 <- rev(col.tag)\n     D[(cols + 1), 2:(cols + 1)] <- ifelse(col.tag %% 2 == 0, 1.02, 1.01)\n     D[1:cols, 1] <- ifelse(col.tag2 %% 2 == 0, 1.02, 1.01)\n     D[(cols + 1), 1] <- 1.03\n     D[1:cols, 2:(cols + 1)] <- B[1:cols, 1:cols]\n\n     col.map <- c(rainbow(100, s = 1.0, v = 0.75, start = 0.0, end = 0.75, gamma = 1.5), \"#BBBBBB\", \"#333333\", \"#FFFFFF\")\n     image(1:(cols + 1), 1:(cols + 1), t(D), col = col.map, axes=FALSE, main=main, sub=sub, xlab= xlab, ylab=ylab)\n     for (i in 1:cols) {\n         col.names[i]  <- paste(\"      \", substr(col.names[i], 1, 12), sep=\"\")\n         col.names2[i] <- paste(substr(col.names2[i], 1, 12), \"     \", sep=\"\")\n     }\n\n     axis(2, at=1:cols, labels=col.names2, adj= 0.5, tick=FALSE, las = 1, cex.axis=0.50, font.axis=1, line=-1)\n     axis(2, at=1:cols, labels=col.labels2, adj= 0.5, tick=FALSE, las = 1, cex.axis=0.65, font.axis=1, line=-1)\n\n     axis(3, at=2:(cols + 1), labels=col.names, adj= 1, tick=FALSE, las = 3, cex.axis=0.50, font.axis=1, line=-1)\n     axis(3, at=2:(cols + 1), labels=as.character(col.labels), adj = 1, tick=FALSE, las = 1, cex.axis=0.65, font.axis=1, line=-1)\n\n     return()\n}\n\nread.res <- function(filename = \"NULL\") { \n#\n# Reads a gene expression dataset in RES format and converts it into an R data frame\n#\n   header.cont <- readLines(filename, n = 1)\n   temp <- unlist(strsplit(header.cont, \"\\t\"))\n   colst <- length(temp)\n   header.labels <- temp[seq(3, colst, 2)]\n   ds <- read.delim(filename, header=F, row.names = 2, sep=\"\\t\", quote=\"\", skip=3, blank.lines.skip=T, comment.char=\"\", as.is=T)\n   colst <- length(ds[1,])\n   cols <- (colst - 1)/2\n   rows <- length(ds[,1])\n   A <- matrix(nrow=rows - 1, ncol=cols)\n   A <- ds[1:rows, seq(2, colst, 2)]\n   table1 <- data.frame(A)\n   names(table1) <- header.labels\n   return(table1)\n}\n\nread.gct <- function(filename = \"NULL\") { \n#\n# Reads a gene expression dataset in GCT format and converts it into an R data frame\n#\n   ds <- read.delim(filename, header=T, sep=\"\\t\", quote=\"\", skip=2, row.names=1, blank.lines.skip=T, comment.char=\"\", as.is=T)\n   ds <- ds[-1]\n   return(ds)\n}\n\nwrite.gct <- function (gct, filename) \n{\n    f <- file(filename, \"w\")\n    cat(\"#1.2\", \"\\n\", file = f, append = TRUE, sep = \"\")\n    cat(dim(gct)[1], \"\\t\", dim(gct)[2], \"\\n\", file = f, append = TRUE, sep = \"\")\n\n    cat(\"Name\", \"\\t\", file = f, append = TRUE, sep = \"\")\n    cat(\"Description\", file = f, append = TRUE, sep = \"\")\n\n    names <- names(gct)\n    for (j in 1:length(names)) {\n        cat(\"\\t\", names[j], file = f, append = TRUE, sep = \"\")\n    }\n    cat(\"\\n\", file = f, append = TRUE, sep = \"\")\n    oldWarn <- options(warn = -1)\n\n    m <- matrix(nrow = dim(gct)[1], ncol = dim(gct)[2] +  2)\n    m[, 1] <- row.names(gct)\n    m[, 2] <- row.names(gct)\n    index <- 3\n    for (i in 1:dim(gct)[2]) {\n        m[, index] <- gct[, i]\n        index <- index + 1\n    }\n    write.table(m, file = f, append = TRUE, quote = FALSE, sep = \"\\t\", eol = \"\\n\", col.names = FALSE, row.names = FALSE)\n    close(f)\n    options(warn = 0)\n    return(gct)\n}"}, {"role": "assistant", "content": "#NMFConsensus\n#Tue Mar 07 11:03:01 PST 2023\nJVMLevel=2.5.0\nLSID=urn\\:lsid\\:broad.mit.edu\\:cancer.software.genepattern.module.analysis\\:00057\\:5\nauthor=Jean-Phillipe Brunet and Pablo Tamayo, The Broad Institute\ncommandLine=<R2.5> <libdir>nmfconsensus.R nmfconsensus <dataset.filename> <k.initial> <k.final> <num.clusterings> <max.num.iterations> <error.function> <random.seed> <stop.convergence> <stop.frequency> T <output.file.prefix> \ncpuType=any\ndescription=Non-negative Matrix Factorization (NMF) Consensus Clustering\nfileFormat=membership.gct;cophenetic.txt;cophenetic.plot.pdf;consensus.k.2.gct;consensus.k.3.gct;consensus.k.4.gct;consensus.k.5.gct\nlanguage=R 2.5\nname=NMFConsensus\nos=any\np10_default_value=10\np10_description=Frequency (NMF iterations) of \"no change\" checks\np10_domain=\np10_fileFormat=\np10_name=stop.frequency\np10_optional=\np10_prefix_when_specified=\np10_type=java.lang.Integer\np10_value=\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=Input dataset (gct or res)\np1_domain=\np1_fileFormat=\np1_name=dataset.filename\np1_optional=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\np2_default_value=2\np2_description=Initial value of K\np2_domain=\np2_fileFormat=\np2_name=k.initial\np2_optional=\np2_prefix_when_specified=\np2_type=java.lang.Integer\np2_value=\np3_default_value=5\np3_description=Final value of K\np3_domain=\np3_fileFormat=\np3_name=k.final\np3_optional=\np3_prefix_when_specified=\np3_type=java.lang.Integer\np3_value=\np4_default_value=20\np4_description=Number of clusterings per value of K\np4_domain=\np4_fileFormat=\np4_name=num.clusterings\np4_optional=\np4_prefix_when_specified=\np4_type=java.lang.Integer\np4_value=\np5_default_value=2000\np5_description=Maximum number of NMF iterations per clustering\np5_domain=\np5_fileFormat=\np5_name=max.num.iterations\np5_optional=\np5_prefix_when_specified=\np5_type=java.lang.Integer\np5_value=\np6_default_value=divergence\np6_description=Error function\np6_domain=\np6_fileFormat=\np6_name=error.function\np6_optional=\np6_prefix_when_specified=\np6_type=java.lang.String\np6_value=divergence;euclidean\np7_default_value=123456789\np7_description=Seed for random number generator\np7_domain=\np7_fileFormat=\np7_name=random.seed\np7_optional=\np7_prefix_when_specified=\np7_type=java.lang.Integer\np7_value=\np8_default_value=<dataset.filename_basename>\np8_description=Prefix to append to all output files\np8_domain=\np8_fileFormat=\np8_name=output.file.prefix\np8_optional=\np8_prefix_when_specified=\np8_type=java.lang.String\np8_value=\np9_default_value=40\np9_description=How many \"no change\" checks are needed to stop NMF iterations before max iterations is reached(convergence)\np9_domain=\np9_fileFormat=\np9_name=stop.convergence\np9_optional=\np9_prefix_when_specified=\np9_type=java.lang.Integer\np9_value=\npipelineModel=\nprivacy=public\npublicationDate=08/17/2012 12\\:37 \nquality=production\nrequiredPatchLSIDs=urn\\:lsid\\:broad.mit.edu\\:cancer.software.genepattern.server.patch\\:00009\\:1\nrequiredPatchURLs=http\\://www.broad.mit.edu/webservices/gpModuleRepository/download/prod/patch/?file\\=/R_2_5_Check/broad.mit.edu\\:cancer.software.genepattern.server.patch/00009/1/R2_5.zip\nserializedModel=\ntaskType=Clustering\nuserid=ted\nversion=Added output files to manifest. Doc edits."}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "## The Regents of the University of California and The Broad Institute\n## SOFTWARE COPYRIGHT NOTICE AGREEMENT\n## This software and its documentation are copyright (2018) by the\n## Regents of the University of California abd the \n## Broad Institute/Massachusetts Institute of Technology. All rights are\n## reserved.\n##\n## This software is supplied without any warranty or guaranteed support\n## whatsoever. Neither the Broad Institute nor MIT can be responsible for its\n## use, misuse, or functionality.\n\n# Load any packages used to in our code to interface with GenePattern.\n# Note the use of suppressMessages and suppressWarnings here.  The package\n# loading process is often noisy on stderr, which will (by default) cause\n# GenePattern to flag the job as failing even when nothing went wrong. \nsuppressMessages(suppressWarnings(library(dplyr)))\nsuppressMessages(suppressWarnings(library(getopt)))\nsuppressMessages(suppressWarnings(library(optparse)))\nsuppressMessages(suppressWarnings(library(limma)))\nsuppressMessages(suppressWarnings(library(GenomicRanges)))\nsuppressMessages(suppressWarnings(library(TxDb.Hsapiens.UCSC.hg38.knownGene)))\nsuppressMessages(suppressWarnings(library(org.Hs.eg.db)))\nsuppressMessages(suppressWarnings(library(Homo.sapiens)))\nsuppressMessages(suppressWarnings(library(OutSplice)))\n\n\n# Print the sessionInfo so that there is a listing of loaded packages, \n# the current version of R, and other environmental information in our\n# stdout file.  This can be useful for reproducibility, troubleshooting\n# and comparing between runs.\nargs = commandArgs(trailingOnly=TRUE)\nprint(\"=============\")\nprint(args)\nsessionInfo()\n\nis.emptyString=function(a){return (trimws(a)==\"\")}\n\n# Get the command line arguments.  We'll process these with optparse.\n# https://cran.r-project.org/web/packages/optparse/index.html\narguments <- commandArgs(trailingOnly=TRUE)\n\n# Declare an option list for optparse to use in parsing the command line.\noption_list <- list(\n  # Note: it's not necessary for the names to match here, it's just a convention\n  # to keep things consistent.\n  make_option(\"--data.file\", dest=\"data.file\"),\n  make_option(\"--number\", dest=\"number\"),\n  make_option(\"--junctions\", dest=\"junctions\"),\n  make_option(\"--tail\", dest=\"tail\", default=NULL),\n  make_option(\"--p.value\", dest=\"p.value\", type=\"double\"),\n  make_option(\"--out.file.prefix\", dest=\"out.file.prefix\", default=\"OutputFile\"),\n  make_option(\"--gene\", dest=\"gene\", default='FALSE')  ,\n  make_option(\"--symbol\", dest=\"symbol\", default=NULL),\n  make_option(\"--tumor.color\", dest=\"tumor.color\", default=\"red\"),\n  make_option(\"--normal.color\", dest=\"normal.color\", default=\"blue\")\n)\n\n# Parse the command line arguments with the option list, printing the result\n# to give a record as with sessionInfo.\nopt <- parse_args(OptionParser(option_list=option_list), positional_arguments=FALSE, args=arguments)\nopts <- opt\ndata_file = opts$data.file\n\noutdir = getwd()\n\nif (!(endsWith(outdir, '/'))){\n   outdir = paste(outdir, '/', sep=\"\")\n}\n\npdf <- paste0( opts$out.file.prefix, \"\", '.pdf')\npdf_output <- paste0('./', pdf)\nprint(data_file)\nif (!is.null(opts$tail)){\n\tif (opts$tail == \"NULL\"){\n\t    tail = NULL\n\t} else {\n\t    tail=opts$tail\n\t}\n} else {\n\ttail = NULL\n}\nprint(paste(\"tail is \", tail))\nplotJunctionData(data_file, NUMBER=opts$number, junctions=opts$junctions, tail=tail, p_value = opts$p.value, GENE=opts$gene, SYMBOL=opts$symbol, makepdf=TRUE, pdffile = pdf_output, tumcol='red', normcol='blue')"}, {"role": "assistant", "content": "# OutSplice.plotJunctions  urn:lsid:genepattern.org:module.analysis:00433:999999999\n#Thu Mar 02 19:18:26 UTC 2023\nJVMLevel=\nLSID=urn\\:lsid\\:genepattern.org\\:module.analysis\\:00433\\:999999999\nauthor=Joseph Bendik;UCSD\ncategories=alternative splicing\ncommandLine=Rscript /build/source/outsplice_plotjunctions_wrapper.R <data.file>  <junctions>       <out.file.prefix>  <gene> <symbol> <tumor.color> <normal.color>  <p.value>   <tail>    <number>\ncpuType=any\ndescription=Using the result file from OutSplice, OutSplice.plotJunctions creates bar and waterfall plots of junction expression in both the tumor and normal samples.\n\ndocumentationUrl=https://genepattern.github.io/OutSplice.plotJunctions/v1/\nfileFormat=\njob.cpuCount=\njob.docker.image=genepattern/outsplice.plotjunctions\\:0.5\njob.memory=\njob.walltime=\nlanguage=any\nname=OutSplice.plotJunctions\nos=any\np10_MODE=\np10_TYPE=TEXT\np10_default_value=red\np10_description=Color for tumors on graph. Default is red \\n\np10_fileFormat=\np10_flag=--tumor.color \np10_name=tumor.color\np10_numValues=1..1\np10_optional=\np10_prefix=--tumor.color \np10_prefix_when_specified=--tumor.color \np10_type=java.lang.String\np10_value=\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=R Data file containing output from the SplicingOutliers or TCGA_SplicingOutliers Functions generated by OutSpplice.\np1_fileFormat=RData;rdata;.rda;.RDa\np1_flag=--data.file \np1_name=data.file\np1_numValues=0..1\np1_optional=\np1_prefix=--data.file \np1_prefix_when_specified=--data.file \np1_type=java.io.File\np1_value=\np2_MODE=\np2_TYPE=TEXT\np2_default_value=1\np2_description=The number of junctions to plot. This can be top number of junctions (over or under expressed), or can be specific junctions in a list.  Default is 1 \np2_fileFormat=\np2_flag=--number \np2_name=number\np2_numValues=0..1\np2_optional=\np2_prefix=--number \np2_prefix_when_specified=--number \np2_type=java.lang.String\np2_value=\np3_MODE=\np3_TYPE=TEXT\np3_default_value=\np3_description=The specific junction you want to graph (or comma delimited list of junctions). \np3_fileFormat=\np3_flag=--junctions \np3_name=junctions\np3_numValues=0..1\np3_optional=on\np3_prefix=--junctions \np3_prefix_when_specified=--junctions \np3_type=java.lang.String\np3_value=\np4_MODE=\np4_TYPE=TEXT\np4_default_value= \np4_description=Specify tail\\='RIGHT' for junctions overexpressed in tumors,  tail\\='LEFT' for junctions underexpressed in tumors. If neither is specified, plot the first N number of junctions specified in the number parameter, regardless of significance or expression level. Default is neither.\np4_fileFormat=\np4_flag=--tail  \np4_name=tail\np4_numValues=0..1\np4_optional=on\np4_prefix=--tail  \np4_prefix_when_specified=--tail  \np4_type=java.lang.String\np4_value=NULL\\= ;RIGHT\\=RIGHT;LEFT\\=LEFT\np5_MODE=\np5_TYPE=TEXT\np5_default_value=<data.file_basename>_plot\np5_description=Prefix that will be used for all output files.\np5_fileFormat=\np5_flag=--out.file.prefix  \np5_name=out.file.prefix\np5_numValues=1..1\np5_optional=\np5_prefix=--out.file.prefix  \np5_prefix_when_specified=--out.file.prefix  \np5_type=java.lang.String\np5_value=\np6_MODE=\np6_TYPE=Floating Point\np6_default_value=.05\np6_description=p-value threshold to use when plotting the top over or under-expressed junctions with \"tail\". Default is 0.05 [OPTIONAL]\np6_fileFormat=\np6_flag=--p.value  \np6_name=p.value\np6_numValues=0..1\np6_optional=on\np6_prefix=--p.value  \np6_prefix_when_specified=--p.value  \np6_type=java.lang.Float\np6_value=\np7_MODE=\np7_TYPE=TEXT\np7_default_value=FALSE\np7_description=Pick junctions based on a specific gene. TRUE means you will pick all the junctions mapping to a certain gene.  FALSE means you do not pick based on the gene. Default is False. \np7_fileFormat=\np7_flag=--gene \np7_name=gene\np7_numValues=0..1\np7_optional=on\np7_prefix=--gene \np7_prefix_when_specified=--gene \np7_type=java.lang.String\np7_value=TRUE\\=TRUE;FALSE\\=FALSE\np8_MODE=\np8_TYPE=TEXT\np8_default_value=\np8_description=HGNC SYMBOL of gene you want to graph.\np8_fileFormat=\np8_flag=--symbol  \np8_name=symbol\np8_numValues=0..1\np8_optional=on\np8_prefix=--symbol  \np8_prefix_when_specified=--symbol  \np8_type=java.lang.String\np8_value=\np9_MODE=\np9_TYPE=TEXT\np9_default_value=blue\np9_description=Color for normals on graph. Default is blue\np9_fileFormat=\np9_flag=--normal.color  \np9_name=normal.color\np9_numValues=0..1\np9_optional=\np9_prefix=--normal.color  \np9_prefix_when_specified=--normal.color  \np9_type=java.lang.String\np9_value=\nprivacy=public\npublicationDate=03/02/2023 07\\:21 \nquality=development\nsrc.repo=https\\://github.com/genepattern/OutSplice.plotJunctions\ntaskDoc=\ntaskType=beta\nuserid=ted\nversion=Initial Revision."}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "# Prepare.Transcriptome.for.Velocity\n# Source: https://combine-lab.github.io/alevin-tutorial/2020/alevin-velocity/\n\nsuppressPackageStartupMessages({\n  library(\"getopt\")\n  library(\"optparse\")\n  library(\"R.utils\")\n  library(\"dplyr\")\n  library(\"BSgenome\")\n  library(\"eisaR\")\n  library(\"GenomicFeatures\")\n  library(\"Biostrings\")\n})\n\narguments <- commandArgs(trailingOnly = TRUE)\n\noption_list <- list(\n  make_option(\"--gtf\", dest = \"gtf\"),\n  make_option(\"--genome\", dest = \"genome.fa\"),\n  make_option(\"--length\", dest = \"length\"),\n  make_option(\"--trim\", dest = \"trim\"),\n  make_option(\"--type\", dest = \"type\"),\n  make_option(\"--join\", dest = \"join\")\n)\n\nopt <- parse_args(OptionParser(option_list = option_list),\n  positional_arguments = TRUE,\n  args = arguments\n)$options\n\ngtf = opt$gtf\ngenome.fa = opt$genome.fa\ntype = opt$type ## \"separate\", or \"collapse\"\nread_length = as.integer(opt$length) ## Insert Length, used to set flank length around introns\nflank_trim_length = as.integer(opt$trim) # New tutorial uses 5, not clear why.\nflank_length = as.integer(read_length - flank_trim_length)\njoin_introns = as.logical(opt$join)\n\n# genome.fa.out <- gsub(basename(genome.fa), pattern=\".gz$\", replacement=\"\")\n# genome.fa.out <- gsub(genome.fa.out, pattern=\".fa$\", replacement=\"\")\n# genome.fa.out <- paste0(genome.fa.out,\".expanded\")\n\nsequences.out <- gsub(basename(gtf), pattern = \".gz$\", replacement = \"\")\nsequences.out <- gsub(sequences.out, pattern = \".gtf$\", replacement = \"\")\nsequences.out <- paste0(sequences.out, \".velocity\")\n\ngrl <- eisaR::getFeatureRanges(\n  gtf = gtf,\n  featureType = c(\"spliced\", \"intron\"),\n  intronType = type,\n  flankLength = flank_length,\n  joinOverlappingIntrons = join_introns, # New tutorial sets = TRUE, not clear why\n  verbose = FALSE\n)\n\ngenome <- Biostrings::readDNAStringSet(\n  genome.fa\n) # The \"Error in (function (x)  : attempt to apply non-function\" message is expected.\n\ngtf_df <- rtracklayer::import(gtf)\ngtf_df <- as.data.frame(gtf_df)\ngene_meta <- distinct(gtf_df[, c(\"gene_id\", \"gene_name\")])\n\nnames(genome) <- sapply(strsplit(names(genome), \" \"), .subset, 1)\nseqs <- GenomicFeatures::extractTranscriptSeqs(\n  x = genome,\n  transcripts = grl\n)\n\nBiostrings::writeXStringSet(\n  seqs,\n  filepath = paste0(sequences.out, \".\", as.character(flank_length), \"bp_flank.fa.gz\"), compress = TRUE\n)\n\neisaR::exportToGtf(\n  grl,\n  filepath = paste0(sequences.out, \".gtf\")\n)\ngzip(paste0(sequences.out, \".gtf\"), destname = paste0(sequences.out, \".\", as.character(flank_length), \"bp_flank.gtf.gz\"), overwrite = TRUE, remove = TRUE)\n\nsplicing_meta <- metadata(grl)$corrgene\nmetadata_table <- merge(x = splicing_meta, y = gene_meta, by.x = \"spliced\", by.y = \"gene_id\", all.x = TRUE)\nmetadata_table <- metadata_table[match(splicing_meta$spliced, metadata_table$spliced), ]\n\nwrite.table(metadata_table,\n  file = paste0(sequences.out, \".\", as.character(flank_length), \"bp_flank.features.tsv\"),\n  row.names = FALSE, col.names = TRUE, quote = FALSE, sep = \"\\t\"\n)\n\ndf <- eisaR::getTx2Gene(\n  grl,\n  filepath = paste0(sequences.out, \".\", as.character(flank_length), \"bp_flank.tgMap.tsv\")\n)\n\nmt_df <- unique(gtf_df[(gtf_df$seqnames == \"chrM\" | gtf_df$seqnames == \"MT\"), c(\"gene_id\"), drop = FALSE])\nmt_df_2 <- as.data.frame(paste(mt_df$gene_id, \"I\", sep = \"-\"))\ncolnames(mt_df_2) <- colnames(mt_df)\nmt_df <- rbind(mt_df, mt_df_2)\nwrite.table(mt_df, paste0(sequences.out, \".\", as.character(flank_length), \"bp_flank.mtGenes.txt\"), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = \"\\t\")\n\nrrna_df <- unique(gtf_df[gtf_df$gene_type == \"rRNA\", c(\"gene_id\"), drop = FALSE])\nrrna_df_2 <- as.data.frame(paste(rrna_df$gene_id, \"I\", sep = \"-\"))\ncolnames(rrna_df_2) <- colnames(rrna_df)\nrrna_df <- rbind(rrna_df, rrna_df_2)\nwrite.table(rrna_df, paste0(sequences.out, \".\", as.character(flank_length), \"bp_flank.rrnaGenes.txt\"), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = \"\\t\")\n\n\ninvisible(file.remove(gtf))"}, {"role": "assistant", "content": "#PreprocessVelocityTranscriptome\n#Thu Feb 17 22:22:26 UTC 2022\nJVMLevel=\nLSID=urn\\:lsid\\:genepattern.org\\:module.analysis\\:00424\\:1\nauthor=Anthony S. Castanza;UCSD-MesirovLab\ncategories=preprocess & utilities;single-cell;singlecell\ncommandLine=Rscript /module/txome.for.velocity.R --gtf <GTF> --genome <Genome.FASTA> --length <Insert.Size> --trim <Intron.Flank.Trim> --type <Intron.Extraction> --join <Join.Overlapping.Introns>\ncpuType=any\ndescription=Extract transcript and intron sequences from the genome sequence using the eisaR package in order to quantify both intronic (unprocessed) and exonic (processed) RNA abundances in each cell with alevin.<br>A necessary preprocessing step to enable RNA velocity analysis.\ndocumentationUrl=https\\://genepattern.github.io/PreprocessVelocityTranscriptome/v1/\nfileFormat=fa;gtf;tsv\njob.cpuCount=\njob.docker.image=genepattern/prepvelocitytxome\\:v1\njob.memory=6Gb\njob.walltime=\nlanguage=any\nname=PreprocessVelocityTranscriptome\nos=any\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=A GTF file containing the genomic ranges to extract features from for quantification.\np1_fileFormat=.gtf.gz;gtf;gtf.gz\np1_flag=--gtf\np1_name=GTF\np1_numValues=1..1\np1_optional=\np1_prefix=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\np2_MODE=IN\np2_TYPE=FILE\np2_default_value=\np2_description=A FASTA file of the genomic sequence corresponding to the organism's GTF file.\np2_fileFormat=.fa.gz;fa;fa.gz;FASTA;fasta;fasta.gz\np2_flag=--genome\np2_name=Genome.FASTA\np2_numValues=1..1\np2_optional=\np2_prefix=\np2_prefix_when_specified=\np2_type=java.io.File\np2_value=\np3_MODE=\np3_TYPE=Integer\np3_default_value=\np3_description=Insert size/RNA read length.<br>For standard 10x Chromium Single Cell 3' v3/v3.1 chemistry the insert size is <b>\"91\"</b>, for 10x Chromium Single Cell 3' v2 the insert size is <b>\"98\"</b> for dual indexed 10x Chromium kits containing an i5 index, the insert size is <b>\"90\"</b>. This value is used to determine valid alignment positions across exon-intron junctions.\np3_fileFormat=\np3_flag=--length\np3_name=Insert.Size\np3_numValues=1..1\np3_optional=\np3_prefix=\np3_prefix_when_specified=\np3_range=1+\np3_type=java.lang.Integer\np3_value=\np4_MODE=\np4_TYPE=Integer\np4_default_value=5\np4_description=Adjusts the Insert.Size value so that reads that align to an exon-intron junction must have at least Intron.Flank.Trim base pair alignment to the intron in order to be quantified as an intronic alignment. Typically 1-5 basepairs.\np4_fileFormat=\np4_flag=--trim\np4_name=Intron.Flank.Trim\np4_numValues=1..1\np4_optional=\np4_prefix=\np4_prefix_when_specified=\np4_range=1+\np4_type=java.lang.Integer\np4_value=\np5_MODE=\np5_TYPE=TEXT\np5_default_value=separate\np5_description=Consider transcripts separately (\"separate\") when extracting intronic regions, or collapsed to gene level (\"collapse\").\np5_fileFormat=\np5_flag=--type\np5_name=Intron.Extraction\np5_numValues=1..1\np5_optional=\np5_prefix=\np5_prefix_when_specified=\np5_type=java.lang.String\np5_value=separate\\=separate;collapse\\=collapse\np6_MODE=\np6_TYPE=TEXT\np6_default_value=TRUE\np6_description=Some transcripts/genes may have intronic sequences that overlap. These overlapping sequences can be combined into a single record for quantification or be kept separate.\np6_fileFormat=\np6_flag=--join\np6_name=Join.Overlapping.Introns\np6_numValues=1..1\np6_optional=\np6_prefix=\np6_prefix_when_specified=\np6_type=java.lang.String\np6_value=TRUE\\=True;FALSE\\=False\nprivacy=public\npublicationDate=02/08/2022 14\\:39 \nquality=preproduction\nsrc.repo=https\\://github.com/genepattern/PreprocessVelocityTranscriptome/tree/v1\ntaskDoc=\ntaskType=preprocess & utilities\nuserid=acastanza\nversion=initial release"}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "## The Regents of the University of California and The Broad Institute\n## SOFTWARE COPYRIGHT NOTICE AGREEMENT\n## This software and its documentation are copyright (2018) by the\n## Regents of the University of California abd the \n## Broad Institute/Massachusetts Institute of Technology. All rights are\n## reserved.\n##\n## This software is supplied without any warranty or guaranteed support\n## whatsoever. Neither the Broad Institute nor MIT can be responsible for its\n## use, misuse, or functionality.\n\n# Load any packages used to in our code to interface with GenePattern.\n# Note the use of suppressMessages and suppressWarnings here.  The package\n# loading process is often noisy on stderr, which will (by default) cause\n# GenePattern to flag the job as failing even when nothing went wrong. \nsuppressMessages(suppressWarnings(library(getopt)))\nsuppressMessages(suppressWarnings(library(optparse)))\n#suppressMessages(suppressWarnings(library(dplyr)))\nsuppressMessages(suppressWarnings(library(Seurat)))\n\n# Print the sessionInfo so that there is a listing of loaded packages, \n# the current version of R, and other environmental information in our\n# stdout file.  This can be useful for reproducibility, troubleshooting\n# and comparing between runs.\nsessionInfo()\n\nis.emptyString=function(a){return (trimws(a)==\"\")}\n\n# Get the command line arguments.  We'll process these with optparse.\n# https://cran.r-project.org/web/packages/optparse/index.html\narguments <- commandArgs(trailingOnly=TRUE)\n\n# Declare an option list for optparse to use in parsing the command line.\noption_list <- list(\n  # Note: it's not necessary for the names to match here, it's just a convention\n  # to keep things consistent.\n  make_option(\"--input.file\", dest=\"input.file\"),\n  make_option(\"--output.file\", dest=\"output.file\"),\n  make_option(\"--max_dim\", dest=\"max_dim\", type=\"integer\"),\n  make_option(\"--resolution\", dest=\"resolution\", type=\"double\"),\n  make_option(\"--reduction\", dest=\"reduction\"),\n  make_option(\"--seed\", dest=\"seed\", type=\"integer\"),\n\n)\n\n# Parse the command line arguments with the option list, printing the result\n# to give a record as with sessionInfo.\nopt <- parse_args(OptionParser(option_list=option_list), positional_arguments=TRUE, args=arguments)\nprint(opt)\nopts <- opt$options\n\npbmc=NULL\n\nif (file.exists(opts$input.file)){\n\tpbmc = readRDS(opts$input.file)\n}\n\npbmc <- FindNeighbors(pbmc, dims = 1:opts$max_dim)\npbmc <- FindClusters(pbmc, resolution = opts$resolution)\npbmc <- RunUMAP(pbmc, dims = 1:opts$max_dim, seed.use=opts$seed)\nDimPlot(pbmc, reduction = opts$reduction)\nsaveRDS(pbmc, file = opts$output.file)"}, {"role": "assistant", "content": "#Tue, 17 Dec 2019 13:14:51 -0800\nJVMLevel=\nLSID=urn\\:lsid\\:broad.mit.edu\\:cancer.software.genepattern.module.analysis\\:00408\\:999999999\nauthor=Satija Lab New York Genome Canter, Wrapped as a module by Ted Liefeld, UCSD School of Medicine.\ncategories=SingleCell\ncommandLine=/opt/R3.6/bin/Rscript --no-save --quiet --slave --no-restore /seurat/run-seurat-clustering.R --input.file\\=<input.seurat.rds.file> --output.file\\=<output.filename>.rds --max_dim\\=<maximum_dimension> --resolution\\=<resolution> --reduction\\=<reduction> --seed\\=<seed>\n\ncpuType=any\ndescription=performs clustering on Seurat RDS objects\nfileFormat=pdf,rds\nlanguage=any\nminGenePatternVersion=3.9.13\nname=SeuratClustering\nos=any\njob.docker.image=genepattern/seurat-clustering:3.2\n\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=RDS file containing a seurat object\np1_fileFormat=rds\np1_flag=\np1_name=input.seurat.rds.file\np1_numValues=1\np1_optional=\np1_prefix=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\n\np2_MODE=\np2_TYPE=TEXT\np2_default_value=<input.seurat.rds.file_basename>.clustered\np2_description=Name for output rds file\np2_fileFormat=\np2_flag=\np2_name=output.filename\np2_numValues=1..1\np2_optional=\np2_prefix=\np2_prefix_when_specified=\np2_type=java.lang.String\np2_value=\n\np3_MODE=IN\np3_TYPE=\np3_default_value=10\np3_description=Max num dimensions to cluster\np3_fileFormat=\np3_flag=\np3_name=maximum_dimension\np3_numValues=1\np3_optional=on\np3_prefix=\np3_prefix_when_specified=\np3_type=java.lang.String\np3_value=\n\n#  <gene.sets.database> <link.to.msigdb> <url.in.description>\np4_MODE=IN\np4_TYPE=\np4_default_value=0.5\np4_description=resolution\np4_fileFormat=\np4_numValues=1\np4_flag=\np4_name=resolution\np4_optional=\np4_prefix=\np4_prefix_when_specified=\np4_type=java.lang.String\np4_value=\n\np5_MODE=\np5_TYPE=TEXT\np5_default_value=umap\np5_description=The reduction to use (umap/tsne)\np5_fileFormat=\np5_flag=\np5_name=reduction\np5_numValues=1..1\np5_optional=\np5_prefix=\np5_prefix_when_specified=\np5_type=java.lang.String\np5_value=umap;tsne\n\np6_MODE=IN\np6_TYPE=\np6_default_value=17\np6_description=Random number seed.\np6_fileFormat=\np6_flag=\np6_name=seed\np6_numValues=1\np6_optional=on\np6_prefix=\np6_prefix_when_specified=\np6_type=java.lang.String\np6_value=\n\n\nprivacy=public\npublicationDate=12/17/2019 13\\:14 \nquality=${quality.level}\nrequiredPatchLSIDs=\nrequiredPatchURLs=\ntaskDoc=doc.html\ntaskType=SingleCell\nversion=Initial Revision"}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "# Integrate Data Script\n# Written by Jonathan Zamora, UCSD-MesirovLab\n# For use in GenePattern\n\n\nsuppressMessages(suppressWarnings(library(\"log4r\")))\nlogfile <- \"integrate_data_log.txt\"\nconsole_appender <- console_appender(layout = default_log_layout())\nfile_appender <- file_appender(logfile, append = TRUE, layout = default_log_layout())\nlogger <- log4r::logger(threshold = \"INFO\", appenders = list(console_appender, file_appender))\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = \"Loading libraries: Seurat, ggplot2, optparse, log4r\")\nsuppressMessages(suppressWarnings(library(\"Seurat\")))\nsuppressMessages(suppressWarnings(library(\"optparse\")))\nsuppressMessages(suppressWarnings(library(\"ggplot2\")))\ninfo(logger, message = \"Loaded libraries: Seurat, ggplot2, optparse, log4r\")\ninfo(logger, message = \"==========================================================\")\n\n# # ====================================\n# # PARAMETERS for INPUT, PCA, and Violin Plot\n# use_batch_names = TRUE (Default)\n# # ====================================\n# # PARAMETERS for PCA\n# ncomps = 50 (Default)\n# # ====================================\n# # PARAMETERS for Violin Plot\n# nCount_RNA: TRUE (Default)\n# nFeature_RNA: TRUE (Default)\n# # ====================================\n# # PARAMETERS for OUTPUT\n# output_file_name: \"integrate_data_results\" (Default)\n# # ====================================\n\n# Parameter Descriptions can be found at: https://github.com/genepattern/Seurat.IntegrateData/blob/develop/doc.md\n# ====================================\n# Parse Input Arguments\nparser = OptionParser()\n# ====================================\nparser <- add_option(parser, c(\"--input_files\"), help=\"List of files to load. Separate file names with '\\ ' \")\nparser <- add_option(parser, c(\"--use_batch_names\"), type=\"logical\", default=TRUE, help=\"Maps each input file to Batch Numbers (default = TRUE)\")\n# ====================================\n# PARAMETERS for PCA\nparser <- add_option(parser, c(\"--ncomps\"), type=\"integer\", default=50, help = \"How many PCA components to use (default = 50)\")\n# ====================================\n# PARAMETERS for Violin Plot\nparser <- add_option(parser, c(\"--nCount_RNA\"), type=\"logical\", default=TRUE, help=\"Display nCount_RNA feature on Violin Plot (default = TRUE)\")\nparser <- add_option(parser, c(\"--nFeature_RNA\"), type=\"logical\", default=TRUE, help=\"Display nFeature_RNA feature on Violin Plot (default = TRUE)\")\n# ====================================\n# PARAMETERS for Output File\nparser <- add_option(parser, c(\"--output_file_name\"), default=\"batch_correction_results\", help=\"Output File Name for Data Integration Analysis (default = 'integrate_data_results')\")\n# ====================================\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = \"Parameters used:\")\nargs <- parse_args(parser)\ninfo(logger, message = paste(\"help:\", args$help))\ninfo(logger, message = paste(\"input_files:\", args$input_files))\ninfo(logger, message = paste(\"use_batch_names:\", args$use_batch_names))\ninfo(logger, message = paste(\"ncomps:\", args$ncomps))\ninfo(logger, message = paste(\"nCount_RNA:\", args$nCount_RNA))\ninfo(logger, message = paste(\"nFeature_RNA:\", args$nFeature_RNA))\ninfo(logger, message = paste(\"output_file_name:\", args$output_file_name))\ninfo(logger, message = \"==========================================================\")\n\n\ncon <- file(args$input_files, open = \"r\") # Open \"read\" connection to input files\nlines = readLines(con) # Read lines of input files from open \"read\" connection\n\n# Initialize lists for data, data labels, and batch names\ndata <- list()\ndata_labels <- list()\nbatch_names <- list()\ncounter = 1 # Initialize Batch Counter\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = paste(\"Reading Files contained within:\", args$input_files))\n\n# Run this code by default\nfor(i in 1:length(lines)){\n  \n  if (grepl(\"\\\\.txt$\", lines[[i]]) || grepl(\"\\\\.tsv$\", lines[[i]]))\n  {\n    data[[i]] <- read.delim(file = lines[[i]], row.names=1) # creates data frame for each input file\n    data_labels[[i]] <- tail(strsplit(lines[[i]], \"/\")[[1]], 1) # stores corresponding data labels\n    \n    if (args$use_batch_names == TRUE ) {\n      batch_names[[i]] <- paste(\"Batch\", counter) # store batch names in list\n    }\n    \n    else if (args$use_batch_names == FALSE) {\n      batch_names[[i]] <- tail(strsplit(lines[[i]], \"/\")[[1]], 1) # stores data labels for each batch name\n    }\n    counter = counter + 1 # increment batch counter\n  } else if (grepl(\"\\\\.rds$\", lines[[i]])) {\n    data[[i]] <- readRDS(file = lines[[i]]) # creates data frame for each input file\n    data_labels[[i]] <- tail(strsplit(lines[[i]], \"/\")[[1]], 1) # stores corresponding data labels\n    \n    if (args$use_batch_names == TRUE ) {\n      batch_names[[i]] <- paste(\"Batch\", counter) # store batch names in list\n    }\n    \n    else if (args$use_batch_names == FALSE) {\n      batch_names[[i]] <- tail(strsplit(lines[[i]], \"/\")[[1]], 1) # stores data labels for each batch name\n    }\n    counter = counter + 1 # increment batch counter\n  } else {\n    info(logger, message = paste(\"ERROR: The current file\", lines[[i]], \"is not in a valid format. Please use .txt, .tsv, or .rds file inputs only\"))\n    info(logger, message = paste(\"If you have .tar.gz or .zip files, consult Seurat.QC [https://cloud.genepattern.org/gp/pages/index.jsf?lsid=urn:lsid:genepattern.org:module.analysis:00416:2] to convert those files to .txt or .rds format\"))\n    info(logger, message = paste(\"END OF PROGRAM\"))\n    quit(save=\"no\")\n  }\n}\n\nclose(con) # Close \"read\" connection for input files; No longer needed\n\ninfo(logger, message = paste(\"Finished Reading Files contained within:\", args$input_files))\ninfo(logger, message = \"==========================================================\")\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = paste(\"Creating Seurat Objects for files within:\", args$input_files))\n\nseurat_objects <- list() # Initialize Seurat Object list\n\nfor(i in 1:length(data))\n{\n  if (is(data[[i]], \"Seurat\") == TRUE && args$use_batch_names == TRUE) {\n    seurat_objects[[i]] <- data[[i]]\n    Project(seurat_objects[[i]]) <- batch_names[[i]]\n    # Associates all levels in Seurat Object with Current Batch\n    levels(seurat_objects[[i]]@active.ident) <- rep(batch_names[[i]], length(levels(seurat_objects[[i]])))\n  }\n  \n  else if (is(data[[i]], \"Seurat\") == TRUE && args$use_batch_names == FALSE) {\n    seurat_objects[[i]] <- data[[i]]\n    Project(seurat_objects[[i]]) <- data_labels[[i]]\n    levels(seurat_objects[[i]]@active.ident) <- rep(data_labels[[i]], length(levels(seurat_objects[[i]])))\n  }\n  \n  else {\n    if (args$use_batch_names == TRUE) {\n      seurat_objects[[i]] <- CreateSeuratObject(counts = data[[i]], project = batch_names[[i]])\n      \n      # Associates all levels in Seurat Object with Current Batch\n      levels(seurat_objects[[i]]@active.ident) <- rep(batch_names[[i]], length(levels(seurat_objects[[i]])))\n      \n    } else {\n      seurat_objects[[i]] <- CreateSeuratObject(counts = data[[i]], project = data_labels[[i]])\n      levels(seurat_objects[[i]]@active.ident) <- rep(data_labels[[i]], length(levels(seurat_objects[[i]])))\n    }\n  }\n}\n\nbatch_names <- append(batch_names, paste(\"Batch\", (length(batch_names) + 1))) # Add batch number for merged seurat objects\nmerged_seurat <- merge(x=seurat_objects[[1]], y=seurat_objects[2:length(seurat_objects)], project = batch_names[[length(batch_names)]]) # merge (but dont correct) seurat objects\nseurat_objects <- append(seurat_objects, merged_seurat) # append merged seurat object to end of seurat object list\n\ninfo(logger, message = paste(\"Created Seurat Objects for files contained within:\", args$input_files))\ninfo(logger, message = \"==========================================================\")\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = paste(\"Normalizing Data and Finding Variable Features on Seurat Objects\"))\n\nfor(i in 1:length(seurat_objects)){\n  seurat_objects[[i]] <- NormalizeData(seurat_objects[[i]], verbose = FALSE)\n  seurat_objects[[i]] <- FindVariableFeatures(seurat_objects[[i]], selection.method = \"vst\", nfeatures = 500, verbose = FALSE)\n}\n\ninfo(logger, message = paste(\"Finished Normalizing Data and Finding Variable Features on Seurat Objects\"))\ninfo(logger, message = \"==========================================================\")\n\n\nreference_list <- seurat_objects[1:length(seurat_objects)-1]\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = paste(\"Finding Integration Anchors and Integrating Data on Seurat Objects\"))\ndata_anchors <- FindIntegrationAnchors(object.list = reference_list, dims=1:args$ncomps)\ndata_integrated <- IntegrateData(anchorset = data_anchors)\ninfo(logger, message = paste(\"Finished Finding Integration Anchors and Integrating Data on Seurat Objects\"))\ninfo(logger, message = \"==========================================================\")\n\n\nDefaultAssay(data_integrated) <- \"integrated\" # Set name of default assay as \"integrated\"\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = paste(\"Scaling Data\"))\ndata_integrated <- ScaleData(data_integrated, verbose = FALSE) # Scale and Center Features in dataset(s)\ninfo(logger, message = \"Finished Scaling Data\")\ninfo(logger, message = \"==========================================================\")\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = paste(\"Running PCA on Seurat Objects\"))\ndata_integrated <- RunPCA(data_integrated, npcs = args$ncomps, verbose = FALSE, seed.use = 42) # Dimensionality Reduction\ninfo(logger, message = paste(\"Finished running PCA on Seurat Objects\"))\ninfo(logger, message = \"==========================================================\")\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = \"Running UMAP on Seurat Objects\")\ndata_integrated <- RunUMAP(data_integrated, reduction.use = \"pca\", dims = 1:args$ncomps, seed.use = 42) # Another Dimensional Reduction Technique\ninfo(logger, message = \"Finished running UMAP on Seurat Objects\")\ninfo(logger, message = \"==========================================================\")\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = \"Creating Dictionary for Seurat Batch Objects\")\npdf(file = paste(args$output_file_name, \".pdf\", sep = \"\"), width = 8.5, height = 11)\n\n# Set up data.frame for Batch Names and their corresponding File Names\ndf <- data.frame(do.call(rbind, batch_names[1:length(batch_names)-1]))\ncolnames(df) <- \"Batch_Names\"\ndf$\"File_Names\" <- data_labels\n\n\n# These two steps are executed in order to correct an error with how the data is originally stored in the data.frame\nfirst.step <- lapply(df, unlist)\nsecond.step <- as.data.frame(first.step, stringsAsFactors = F)\n\ndescription = \"NOTE:\\nThe below table displays a mapping of each input file to a corresponding batch number.\\nThis mapping is completed in order to simplify the display of the plots on Pg. 2 and Pg. 3.\"\nplot.new() # Needed in order to use text() function to display description above table\ngridExtra::grid.table(second.step) # Display the Batch Mapping Table\ntext(x=0, y=1, description, font=2, pos = 4, cex = 0.9) # Display the description above the Batch Mapping Table\n\ninfo(logger, message = \"Finished Creating Dictionary for Seurat Batch Objects\")\ninfo(logger, message = \"==========================================================\")\n\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = \"Plotting UMAP Plots:\")\n\nseurat_objects[[length(seurat_objects)]] <- ScaleData(seurat_objects[[length(seurat_objects)]], verbose = FALSE)\nseurat_objects[[length(seurat_objects)]] <- RunPCA(seurat_objects[[length(seurat_objects)]], npcs = args$ncomps, verbose = FALSE, seed.use = 42)\nseurat_objects[[length(seurat_objects)]] <- RunUMAP(seurat_objects[[length(seurat_objects)]], reduction.use = \"pca\", dims = 1:args$ncomps, seed.use = 42)\n\np1 <- DimPlot(seurat_objects[[length(seurat_objects)]], reduction = \"umap\") + theme(legend.position = \"bottom\", plot.title = element_text(hjust = 0.5)) + ggtitle(\"Non-Batch-Corrected Data\")\np1\n\np2 <- DimPlot(data_integrated, reduction = \"umap\") + theme(legend.position = \"bottom\", plot.title = element_text(hjust = 0.5)) + ggtitle(\"Batch-Corrected Data\")\np2\ninfo(logger, message = \"Finished Plotting UMAP Plots\")\ninfo(logger, message = \"==========================================================\")\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = \"Creating Violin Plot(s) for Seurat Object Features\")\n\nif(args$nCount_RNA == TRUE && args$nFeature_RNA == TRUE){\n  VlnPlot(data_integrated, c(\"nCount_RNA\", \"nFeature_RNA\"))\n} else if (args$nCount_RNA == TRUE && args$nFeature_RNA == FALSE){\n  VlnPlot(data_integrated, c(\"nCount_RNA\"))\n} else if (args$nCount_RNA == FALSE && args$nFeature_RNA == TRUE){\n  VlnPlot(data_integrated, c(\"nFeature_RNA\"))\n}\n\nsuppressMessages(suppressWarnings(dev.off()))\n\ninfo(logger, message = \"Created Violin Plot(s) for Seurat Object Features\")\ninfo(logger, message = \"==========================================================\")\n\n\ninfo(logger, message = \"==========================================================\")\ninfo(logger, message = \"Saving Integrated Seurat Data as RDS\")\nsaveRDS(data_integrated, file = paste(args$output_file_name, \".rds\", sep = \"\"))\ninfo(logger, message = \"Done!\")\ninfo(logger, message = \"==========================================================\")"}, {"role": "assistant", "content": "#Seurat.IntegrateData\n#Thu Mar 17 20:08:12 UTC 2022\nJVMLevel=\nLSID=urn\\:lsid\\:8080.gpserver.ip-172-31-26-71.ip-172-31-26-71.ec2.internal\\:genepatternmodules\\:941\\:1.3\nauthor=Jonathan Zamora and Edwin Juarez;UCSD-MesirovLab\ncategories=dimension reduction;preprocess & utilities\ncommandLine=Rscript --no-save --quiet --slave --no-restore <libdir>integrate_data.R --input_files  <input_files>  --use_batch_names <use_batch_names> --ncomps <ncomps> --nCount_RNA <nCount_RNA> --nFeature_RNA <nFeature_RNA> --output_file_name <output_file_name>\ncpuType=any\ndescription=Batch Correction for Seurat Objects\ndocumentationUrl=\nfileFormat=pdf;rds;txt\njob.docker.image=genepattern/seurat-suite\\:4.0.3\nlanguage=any\nname=Seurat.IntegrateData\nos=any\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=Gene expression matrices (columns are cell IDs and rows are genes) stored in a `.txt` or one Seurat Object (`.rds`) file per batch. \\n<br><br>\\nIf your files are in 10x Genomics (Cell Ranger) format or stored in a `.tar`, or `.gz` file, please use the <a href\\=\"https\\://cloud.genepattern.org/gp/pages/index.jsf?lsid\\=urn\\:lsid\\:genepattern.org\\:module.analysis\\:00416\\:2\">Seurat.QC</a> module to pre-process your data and then use the `.txt` or `.rds` output from Seurat.QC in this module.\\n<br><br>\\nFor sample data see \\n<a href\\=\"https\\://datasets.genepattern.org/data/module_support_files/Conos/small_500x500_HNSCC_noribo.txt\">test data file 1</a> and <a href\\=\"https\\://datasets.genepattern.org/data/module_support_files/Conos/small_500x500_MEL_noribo.txt\">test data file 2</a>.\np1_fileFormat=txt\np1_flag=--input_files\np1_name=input_files\np1_numValues=1+\np1_optional=\np1_prefix=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\np2_MODE=\np2_TYPE=TEXT\np2_default_value=TRUE\np2_description=(default \\= TRUE) Map each input file to Batch Numbers beginning with Batch 1 and going up to Batch n where n represents the number of input files.\\n<br><br>\\nWhen set to FALSE, the batch names will be set to the file names.\np2_fileFormat=\np2_flag=--use_batch_names\np2_name=use_batch_names\np2_numValues=1..1\np2_optional=\np2_prefix=\np2_prefix_when_specified=\np2_type=java.lang.String\np2_value=TRUE\\=TRUE;FALSE\\=FALSE\np3_MODE=\np3_TYPE=Integer\np3_default_value=50\np3_description=(default \\= 50) The number of principal components to be used in the Principal Component Analysis (PCA) for batch correction.\np3_fileFormat=\np3_flag=--ncomps\np3_name=ncomps\np3_numValues=1..1\np3_optional=\np3_prefix=\np3_prefix_when_specified=\np3_type=java.lang.Integer\np3_value=\np4_MODE=\np4_TYPE=TEXT\np4_default_value=TRUE\np4_description=(default \\= TRUE) Whether or not the batch correction script will produce a violin plot of the number of molecules detected within a cell for our single-cell datasets.\np4_fileFormat=\np4_flag=--nCount_RNA\np4_name=nCount_RNA\np4_numValues=1..1\np4_optional=\np4_prefix=\np4_prefix_when_specified=\np4_type=java.lang.String\np4_value=TRUE\\=TRUE;FALSE\\=FALSE\np5_MODE=\np5_TYPE=TEXT\np5_default_value=TRUE\np5_description=(default \\= TRUE) Whether or not the batch correction script will produce a violin plot of the number of genes detected within each cell of our single-cell datasets.\np5_fileFormat=\np5_flag=--nFeature_RNA\np5_name=nFeature_RNA\np5_numValues=1..1\np5_optional=\np5_prefix=\np5_prefix_when_specified=\np5_type=java.lang.String\np5_value=TRUE\\=TRUE;FALSE\\=FALSE\np6_MODE=\np6_TYPE=TEXT\np6_default_value=batch_correction_results\np6_description=(default \\= 'batch_correction_results') Base name for the .pdf and .rds output files.\np6_fileFormat=\np6_flag=--output_file_name\np6_name=output_file_name\np6_numValues=1..1\np6_optional=\np6_prefix=\np6_prefix_when_specified=\np6_type=java.lang.String\np6_value=\nprivacy=public\npublicationDate=03/22/2021 18\\:03 \nquality=production\nsrc.repo=https\\://github.com/genepattern/Seurat.BatchCorrection/tree/v3\ntaskDoc=doc.html\ntaskType=dimension reduction\nuserid=edjuaro\nversion=Upgrading to Seurat V4 and fixing a bug in the command line and file name"}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "\n# Load the getopt library\nlibrary(optparse)\nlibrary('ggplot2')\nlibrary('dplyr')\nlibrary('stringr')\nlibrary('spatialGE')\nlibrary('magrittr')\nlibrary(jsonlite)\n\nmake_option_safe <- function(...) {\n  res <- tryCatch(\n    make_option(...),\n    error = function(e) {\n      print(paste(\"Failed to create option:\", deparse(substitute(...))))\n      print(e)\n      NULL\n    }\n  )\n  if (is.null(res)) {\n    stop(\"Failed to create an option\")\n  }\n  res\n}\n\n# Define the specification for each command line argument\n# Define the specification for each command line argument\noption_list = list(\n  make_option_safe(c(\"-a\", \"--input_data_archive\"), type=\"character\",  help=\"input data archive\"),\n  make_option_safe(c(\"-b\", \"--input_clinical_data\"), type=\"character\",  help=\"input clinical data\"),\n  make_option_safe(c(\"-c\", \"--verbose\"), type=\"logical\", default=FALSE, help=\"verbose\"),\n  make_option_safe(c(\"-d\", \"--transform_data\"), type=\"character\", default=\"None\", help=\"transform data\"),\n  make_option_safe(c(\"-e\", \"--output_filename\"), type=\"character\",  help=\"output filename\"),\n  make_option_safe(c(\"-f\", \"--pseudobulk\"), type=\"logical\", default=TRUE, help=\"pseudobulk\"),\n  make_option_safe(c(\"-g\", \"--pseudobulk_max_var_genes\"), type=\"integer\", default=5000, help=\"pseudobulk max var genes\"),\n  make_option_safe(c(\"-F\", \"--pseudobulk_plot_meta\"), type=\"character\", default='patient_id', help=\"pseudobulk plot meta\"),\n  make_option_safe(c(\"-i\", \"--pseudobulk_heatmap_num_displayed_genes\"), type=\"integer\", default=30, help=\"pseudobulk heatmap num displayed genes\"),\n  make_option_safe(c(\"-j\", \"--distribution_plot_meta\"), type=\"character\", default='total_counts', help=\"distribution plot meta\"),\n  make_option_safe(c(\"-k\", \"--spot_min_reads\"), type=\"integer\", default=0, help=\"spot min reads\"),\n  make_option_safe(c(\"-l\", \"--spot_min_genes\"), type=\"integer\", default=0, help=\"spot min genes\"),\n  make_option_safe(c(\"-m\", \"--spot_max_reads\"), type=\"integer\", default=NULL, help=\"spot max reads\"),\n  make_option_safe(c(\"-n\", \"--spot_max_genes\"), type=\"integer\", default=NULL, help=\"spot max genes\"),\n  make_option_safe(c(\"-o\", \"--transform_scale_f\"), type=\"integer\", default=NA, help=\"transform scale f\"),\n  make_option_safe(c(\"-p\", \"--transform_num_regression_genes\"), type=\"integer\", default=NA, help=\"transform num regression genes\"),\n  make_option_safe(c(\"-q\", \"--transform_min_spots_or_cells\"), type=\"integer\", default=NA, help=\"transform min spots or cells\"),\n  make_option_safe(c(\"-r\", \"--spot_min_percent\"), type=\"integer\", default=0, help=\"spot min percent\"),\n  make_option_safe(c(\"-s\", \"--spot_max_percent\"), type=\"integer\", default=NULL, help=\"spot max percent\"),\n  make_option_safe(c(\"-t\", \"--gene_min_reads\"), type=\"integer\", default=0, help=\"gene min reads\"),\n  make_option_safe(c(\"-u\", \"--gene_max_reads\"), type=\"integer\", default=NULL, help=\"gene max reads\"),\n  make_option_safe(c(\"-v\", \"--gene_min_spots\"), type=\"integer\", default=0, help=\"gene min spots\"),\n  make_option_safe(c(\"-w\", \"--gene_max_spots\"), type=\"integer\", default=NULL, help=\"gene max spots\"),\n  make_option_safe(c(\"-x\", \"--gene_min_percent\"), type=\"integer\", default=0, help=\"gene min percent\"),\n  make_option_safe(c(\"-y\", \"--gene_max_percent\"), type=\"integer\", default=NULL, help=\"gene max percent\"),\n  make_option_safe(c(\"-z\", \"--filter_samples\"), type=\"character\", default=NULL, help=\"filter samples\"),\n  make_option_safe(c(\"-A\", \"--rm_tissue\"), type=\"character\", default=NULL, help=\"rm tissue\"),\n  make_option_safe(c(\"-B\", \"--rm_spots\"), type=\"character\", default=NULL, help=\"rm spots\"),\n  make_option_safe(c(\"-C\", \"--rm_genes\"), type=\"character\", default=NULL, help=\"rm genes\"),\n  make_option_safe(c(\"-D\", \"--rm_genes_regex\"), type=\"character\", default=NULL, help=\"rm genes regex\"),\n  make_option_safe(c(\"-E\", \"--spot_percentage_regex\"), type=\"character\", default=\"^MT-\", help=\"spot percentage regex\"),\n  make_option_safe(c(\"-G\", \"--filter_data\"), type=\"logical\", default=TRUE, help=\"filter data\")\n)\n\n# Parse the command line arguments\nopt_parser = OptionParser(option_list=option_list)\nopt = parse_args(opt_parser)\n\n# Assign the command line arguments to variables\n# Replace all the periods in the variable names with underscores\ninput_data_archive <- if(is.null(opt[[\"input_data_archive\"]])) NA else opt[[\"input_data_archive\"]]\ninput_clinical_data <- if(is.null(opt[[\"input_clinical_data\"]])) NA else opt[[\"input_clinical_data\"]]\nverbose <- if(is.null(opt[[\"verbose\"]])) NA else as.logical(opt[[\"verbose\"]])\ntransform_data <- if(is.null(opt[[\"transform_data\"]]) || opt[[\"transform_data\"]] == \"None\") FALSE else TRUE\ntransform_data_method <- if(is.null(opt[[\"transform_data\"]]) || opt[[\"transform_data\"]] == \"None\") \"sct\" else opt[[\"transform_data\"]]\nfilter_data <- if(is.null(opt[[\"filter_data\"]])) TRUE else opt[[\"filter_data\"]]\noutput_filename <- if(is.null(opt[[\"output_filename\"]])) NA else opt[[\"output_filename\"]]\npseudobulk <- if(is.null(opt[[\"pseudobulk\"]])) TRUE else as.logical(opt[[\"pseudobulk\"]])\npseudobulk_max_var_genes <- if(is.null(opt[[\"pseudobulk_max_var_genes\"]])) 5000 else as.integer(opt[[\"pseudobulk_max_var_genes\"]])\npseudobulk_plot_meta <- if(is.null(opt[[\"pseudobulk_plot_meta\"]])) 'patient_id' else opt[[\"pseudobulk_plot_meta\"]]\npseudobulk_heatmap_num_displayed_genes <- if(is.null(opt[[\"pseudobulk_heatmap_num_displayed_genes\"]])) 30 else as.integer(opt[[\"pseudobulk_heatmap_num_displayed_genes\"]])\ndistribution_plot_meta <- if(is.null(opt[[\"distribution_plot_meta\"]])) 'total_counts' else opt[[\"distribution_plot_meta\"]]\nspot_min_reads <- if(is.null(opt[[\"spot_min_reads\"]])) 0 else as.integer(opt[[\"spot_min_reads\"]])\nspot_min_genes <- if(is.null(opt[[\"spot_min_genes\"]])) 0 else as.integer(opt[[\"spot_min_genes\"]])\nspot_max_reads <- if(is.null(opt[[\"spot_max_reads\"]])) NULL else as.integer(opt[[\"spot_max_reads\"]])\nspot_max_genes <- if(is.null(opt[[\"spot_max_genes\"]])) NULL else as.integer(opt[[\"spot_max_genes\"]])\ntransform_scale_f <- if(is.null(opt[[\"transform_scale_f\"]])) 10000 else as.integer(opt[[\"transform_scale_f\"]])\ntransform_num_regression_genes <- if(is.null(opt[[\"transform_num_regression_genes\"]])) 3000 else as.integer(opt[[\"transform_num_regression_genes\"]])\ntransform_min_spots_or_cells <- if(is.null(opt[[\"transform_min_spots_or_cells\"]])) 5 else as.integer(opt[[\"transform_min_spots_or_cells\"]])\nspot_min_percent <- if(is.null(opt[[\"spot_min_percent\"]])) 0 else as.integer(opt[[\"spot_min_percent\"]])\nspot_max_percent <- if(is.null(opt[[\"spot_max_percent\"]])) NULL else as.integer(opt[[\"spot_max_percent\"]])\ngene_min_reads <- if(is.null(opt[[\"gene_min_reads\"]])) 0 else as.integer(opt[[\"gene_min_reads\"]])\ngene_max_reads <- if(is.null(opt[[\"gene_max_reads\"]])) NULL else as.integer(opt[[\"gene_max_reads\"]])\ngene_min_spots <- if(is.null(opt[[\"gene_min_spots\"]])) 0 else as.integer(opt[[\"gene_min_spots\"]])\ngene_max_spots <- if(is.null(opt[[\"gene_max_spots\"]])) NULL else as.integer(opt[[\"gene_max_spots\"]])\ngene_min_percent <- if(is.null(opt[[\"gene_min_percent\"]])) 0 else as.integer(opt[[\"gene_min_percent\"]])\ngene_max_percent <- if(is.null(opt[[\"gene_max_percent\"]])) NULL else as.integer(opt[[\"gene_max_percent\"]])\nfilter_samples <- if(is.null(opt[[\"filter_samples\"]])) NULL else opt[[\"filter_samples\"]]\nrm_tissue <- if(is.null(opt[[\"rm_tissue\"]])) NULL else opt[[\"rm_tissue\"]]\nrm_spots <- if(is.null(opt[[\"rm_spots\"]])) NULL else opt[[\"rm_spots\"]]\nrm_genes <- if(is.null(opt[[\"rm_genes\"]])) NULL else opt[[\"rm_genes\"]]\nrm_genes_regex <- if(is.null(opt[[\"rm_genes_regex\"]])) NULL else opt[[\"rm_genes_regex\"]]\nspot_percentage_regex <- if(is.null(opt[[\"spot_percentage_regex\"]])) \"^MT-\" else opt[[\"spot_percentage_regex\"]]\n\nprint(\"XXX\")\n#GP-9782 strip off the .tar if present in the filename\nprint(paste(\"before stripping tar off --- \", output_filename))\noutput_filename <- gsub(\"\\\\.tar$\", \"\", output_filename)\nprint(paste(\"AFTER stripping tar off --- \", output_filename))\n\n# start by making the data into an STList object\n# for that we need to gunzip input.data.archive\n# and then read the data into an STList object\n\n# Create a temporary directory\ntemp_dir <- tempdir()\n\n# Create the path to the new file location in the temporary directory\nnew_file_location <- file.path(temp_dir, basename(input_data_archive))\n\n# Copy the file to the new location\nfile.copy(input_data_archive, new_file_location)\n\n# Use the system() function to execute the gunzip command with the new file location\nsystem(paste(\"tar xvf \", new_file_location,  \"-C\", temp_dir))\n\n# first pass, assume visium data.  Later need to generalize this bit\nvisium_folders <- list.dirs(temp_dir, full.names=T, recursive=F)\n\n# if there is a single folder, its probably the top of an archive so\n# we need to go down one level\nif (length(visium_folders) <= 1){\n    visium_folders <- list.dirs(visium_folders, full.names=T, recursive=F)\n}\n\nif(length(input_clinical_data) <= 0){\n    stop('No clinical file found in the data archive')\n}\n\ntnbc <- STlist(rnacounts=visium_folders, samples=input_clinical_data)\n\nsummarize_STlist(tnbc)\n\npng(paste(output_filename, \"_distribution_plot_unfiltered.png\", sep=\"\"))\ntryCatch({\n  cp <- distribution_plots(tnbc, plot_type='violin', plot_meta=distribution_plot_meta)\n}, error = function(e) {\n  print(paste(\"Error in distribution_plots:\", e$message))\n})\ncp[['total_counts']]\ndev.off()\n\nif (filter_data){\n    tryCatch({\n\n         tnbc <- filter_data(tnbc, spot_minreads=spot_min_reads, spot_mingenes=spot_min_genes, spot_maxreads=spot_max_reads, spot_maxgenes=spot_max_genes, gene_minreads=gene_min_reads, gene_maxreads=gene_max_reads, gene_minspots=gene_min_spots, gene_maxspots=gene_max_spots, gene_minpct=gene_min_percent, gene_maxpct=gene_max_percent, spot_minpct=spot_min_percent, spot_maxpct=spot_max_percent, samples=filter_samples, rm_tissue=rm_tissue, rm_spots=rm_spots, rm_genes=rm_genes, rm_genes_expr=rm_genes_regex, spot_pct_expr=spot_percentage_regex)\n\n         summarize_STlist(tnbc)\n    }, error = function(e) {\n      print(paste(\"Error in filter_data:\", e$message))\n    })\n    print(summarize_STlist(tnbc))\n    png(paste(output_filename, \"_distribution_plot_postfiltering.png\",sep=\"\"))\n    tryCatch({\n          cp <- distribution_plots(tnbc, plot_type='violin', plot_meta=distribution_plot_meta)\n          print(cp[['total_counts']])\n    }, error = function(e) {\n          print(paste(\"Error in post filter distribution_plots:\", e$message))\n    })\n    dev.off()\n}\n\nif (pseudobulk) {\n    tnbc <- pseudobulk_samples(tnbc, max_var_genes=pseudobulk_max_var_genes)\n    png(paste(output_filename, \"_pseudobulk_pca.png\", sep=\"\"))\n    print(\"B TRANSFORM DATA\")\n    pbpca <- pseudobulk_pca_plot(tnbc, plot_meta=pseudobulk_plot_meta)\n    print(pbpca)\n    dev.off()\n    png(paste(output_filename, \"_pseudobulk_heatmap.png\",sep=\"\"))\n    pbhm <- pseudobulk_heatmap(tnbc, plot_meta=pseudobulk_plot_meta, hm_display_genes=pseudobulk_heatmap_num_displayed_genes)\n    print(pbhm)\n    dev.off()\n}\n\nif (transform_data) {\n    tnbc <- transform_data(tnbc, method=tolower(transform_data_method), scale_f=transform_scale_f, sct_n_regr_genes=transform_num_regression_genes, sct_min_cells=transform_min_spots_or_cells )\n}\n\nprint(paste(\"POST Saving the data to\", output_filename))\nsaveRDS(tnbc, paste(output_filename, \".rds\", sep=\"\"))\n\n# Write the samples.json file\nsumm_df = summarize_STlist(tnbc)\njsonlite::write_json(summ_df, path='samples.json')\n\n# Write genes.json file\ngenes <- c()\nfor (n in names(tnbc@tr_counts)) {\n    genes <- append(genes, rownames(tnbc@tr_counts[[n]]))\n}\ngenes <- unique(genes)\njsonlite::write_json(genes, path='genes.json')\n\n\n# At the end of the script, delete the temporary directory and its contents\nunlink(temp_dir, recursive = TRUE)"}, {"role": "assistant", "content": "#spatialGE.STPreprocessing\n#Tue June 25 2024\nJVMLevel=\nLSID=urn:lsid:genepattern.org:module.analysis:00461:999999999\nauthor=Edwin Huang, Ted Liefeld, Thorin Tabor, Michael Reich;UCSD - Mesirov Lab\ncategories=spatial transcriptomics\n#commandLine when run with source in Docker container:\ncommandLine=Rscript /spatialGE/spatialge_preprocessing_wrapper.R <input.data.archive> <input.clinical.data> <verbose> <transform.data> <output.filename> <pseudobulk> <pseudobulk.max.var.genes> <pseudobulk.plot.meta> <pseudobulk.heatmap.num.displayed.genes> <distribution.plot.meta> <spot.min.reads> <spot.min.genes> <spot.max.reads> <spot.max.genes> <transform.scale.f> <transform.num.regression.genes> <transform.min.spots.or.cells> <spot.min.percent> <spot.max.percent> <gene.min.reads> <gene.max.reads> <gene.min.spots> <gene.max.spots> <gene.min.percent> <gene.max.percent> <filter.samples> <rm.tissue> <rm.spots> <rm.genes> <rm.genes.regex> <spot.percentage.genes.regex> <filter.data>\n\njob.docker.image=genepattern/spatialgp.preprocessing:0.9\nsrc.repo=https://github.com/genepattern/spatialGE.Preprocessing\ncpuType=any\ndescription=The package spatialGE provides a collection of tools for the visualization of gene expression from spatially-resolved transcriptomic experiments. The data input methods have been designed so that any data can be analyzed as long as it contains gene expression counts per region of interest (ROI), spot, or cell, and the spatial coordinates of those ROIs, spots, or cells, as it is generated in platforms such as GeoMx, Visium, and CosMx-SMI. The spatialge.Preprocessing module performs initial data ingestion, filtering, transform and pseudo-bulk operations to prepare data for further processing. Order of operations are: ingestion, filter, pseudobulk, transform.\ndocumentationUrl=https://genepattern.github.io/spatialGE.Preprocessing/v1/\nfileFormat=rds\nlanguage=R\nname=spatialGE.Preprocessing\nos=any\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=Input data archive in gz format. Should match directory structure as defined by spatialGE as described <a href=\"https://fridleylab.github.io/spatialGE/reference/STlist.html\">here</a>.\np1_fileFormat=gz\np1_flag=\np1_name=input.data.archive\np1_numValues=0..1\np1_optional=\np1_prefix=\np1_prefix_when_specified=-a \np1_type=java.io.File\np1_value=\n\np2_MODE=\np2_TYPE=TEXT\np2_default_value=False\np2_description=Output additional files including summarized STList, distribution_plots before and after filtering, and pseudobulk PCA plot and heatmap.\np2_fileFormat=\np2_flag=\np2_name=verbose\np2_numValues=0..1\np2_optional=\np2_prefix=\np2_prefix_when_specified=-c \np2_type=java.lang.String\np2_value=False\\=False;True\\=True\n\np3_MODE=\np3_TYPE=TEXT\np3_default_value=Log\np3_description=None, log or sct. If log, log-normalization is performed. If sct, then the <a href=\"https://rdrr.io/pkg/sctransform/man/vst.html\">SCTransform</a> method is applied. SCT is a variance stabilizing transformation to UMI count data using a regularized Negative Binomial regression model.\np3_fileFormat=\np3_flag=\np3_name=transform.data\np3_numValues=0..1\np3_optional=\np3_prefix=\np3_prefix_when_specified=-d \np3_type=java.lang.String\np3_value=None\\=None;Log\\=Log;SCT\\=SCT\n\np4_MODE=\np4_TYPE=TEXT\np4_default_value=<input.data.archive_basename>\np4_description=The basename to use for output file (no need to add \".txt\" at the end)\np4_fileFormat=\np4_flag=\np4_name=output.filename\np4_numValues=0..1\np4_optional=\np4_prefix=\np4_prefix_when_specified=-e \np4_type=java.lang.String\np4_value=\n\np5_MODE=\np5_TYPE=TEXT\np5_default_value=False\np5_description=Perform pseudobulk to creates (pseudo) bulk RNAseq data sets by combining all counts from each sample. Then log transform the pseudo bulk and perform PCA. Note that the spatial coordinate information is not considered here, which is intended only as an exploratory analysis analysis.\np5_fileFormat=\np5_flag=\np5_name=pseudobulk\np5_numValues=0..1\np5_optional=\np5_prefix=\np5_prefix_when_specified=-f \np5_type=java.lang.String\np5_value=False\\=False;True\\=True\n\np6_MODE=\np6_TYPE=TEXT\np6_default_value=5000\np6_description=The number of most variable genes (standard deviation) to use in pseudobulk analysis.\np6_fileFormat=\np6_flag=\np6_name=pseudobulk.max.var.genes\np6_numValues=0..1\np6_optional=on\np6_prefix=\np6_prefix_when_specified=-g \np6_type=java.lang.Integer\np6_value=\n\np7_MODE=\np7_TYPE=TEXT\np7_default_value=patient_id\np7_description=A string indicating the name of the variable in the sample metadata to color points in the PCA plot.\np7_fileFormat=\np7_flag=\np7_name=pseudobulk.plot.meta\np7_numValues=0..1\np7_optional=\np7_prefix=\np7_prefix_when_specified=-F \np7_type=java.lang.String\np7_value=\n\np8_MODE=\np8_TYPE=TEXT\np8_default_value=30\np8_description=The number of genes to display in the pseudobulk heatmap, selected based on decreasing order of standard deviation across samples.\np8_fileFormat= \np8_flag=-o\np8_name=pseudobulk.heatmap.num.displayed.genes\np8_numValues=0..1\np8_optional=\np8_prefix=\np8_prefix_when_specified=-i \np8_type=java.lang.Integer\np8_value=\n\np9_MODE=\np9_TYPE=TEXT\np9_default_value=total_counts\np9_description=Vector of variables in x@spatial_meta to plot distributions. If 'total_counts', the function plots the counts per spot/cell. If 'total_genes', the function plots the number of genes per spot/cell are plotted.\np9_fileFormat=\np9_flag=\np9_name=distribution.plot.meta\np9_numValues=0..1\np9_optional=\np9_prefix=\np9_prefix_when_specified=-j \np9_type=java.lang.Integer\np9_value=\n\np10_MODE=\np10_TYPE=TEXT\np10_default_value=5000\np10_description=The minimum number of total reads for a spot to be retained\np10_fileFormat=\np10_flag=\np10_name=spot.min.reads\np10_numValues=0..1\np10_optional=on\np10_prefix=\np10_prefix_when_specified=-k \np10_type=java.lang.Integer\np10_value=\n\np11_MODE=\np11_TYPE=TEXT\np11_default_value=1000\np11_description=the minimum number of non-zero counts for a spot to be retained\np11_fileFormat=\np11_flag=\np11_name=spot.min.genes\np11_numValues=0..1\np11_optional=on\np11_prefix=\np11_prefix_when_specified=-l \np11_type=java.lang.Integer\np11_value=\n\np12_MODE=\np12_TYPE=TEXT\np12_default_value=150000\np12_description=The maximum number of total reads for a spot to be retained\np12_fileFormat=\np12_flag=\np12_name=spot.max.reads\np12_numValues=0..1\np12_optional=on\np12_prefix=\np12_prefix_when_specified=-m \np12_type=java.lang.Integer\np12_value=\n\np13_MODE=\np13_TYPE=TEXT\np13_default_value=\np13_description=The maximum number of non-zero counts for a spot to be retained.\np13_fileFormat=\np13_flag=\np13_name=spot.max.genes\np13_numValues=0..1\np13_optional=on\np13_prefix=\np13_prefix_when_specified=-n \np13_type=java.lang.Integer\np13_value=\n\np14_MODE=\np14_TYPE=TEXT\np14_default_value=10000\np14_description=The scale factor used in logarithmic transformation.\np14_fileFormat=\np14_flag=\np14_name=transform.scale.f\np14_numValues=0..1\np14_optional=on\np14_prefix=\np14_prefix_when_specified=-o \np14_type=java.lang.Integer\np14_value=\n\np15_MODE=\np15_TYPE=TEXT\np15_default_value=3000\np15_description=The number of genes to be used in the regression model during SCTransform. The function sctransform::vst makes a random gene selection based on this number.\np15_fileFormat=\np15_flag=\np15_name=transform.num.regression.genes\np15_numValues=0..1\np15_optional=on\np15_prefix=\np15_prefix_when_specified=-p \np15_type=java.lang.Integer\np15_value=\n\np16_MODE=\np16_TYPE=TEXT\np16_default_value=5\np16_description=The minimum number of spots/cells to be used in the regression model fit by sctransform::vst.\np16_fileFormat=\np16_flag=\np16_name=transform.min.spots.or.cells\np16_numValues=0..1\np16_optional=on\np16_prefix=\np16_prefix_when_specified=-q \np16_type=java.lang.Integer\np16_value=\n\np17_MODE=\np17_TYPE=TEXT\np17_default_value=0\np17_description=The minimum percentage of counts for features defined by spot_pct_expr for a spot to be retained.\np17_fileFormat=\np17_flag=\np17_name=spot.min.percent\np17_numValues=0..1\np17_optional=on\np17_prefix=\np17_prefix_when_specified=-r \np17_type=java.lang.Integer\np17_value=\n\np18_MODE=\np18_TYPE=TEXT\np18_default_value=\np18_description=The maximum percentage of counts for features defined by spot_pct_expr for a spot to be retained.\np18_fileFormat=\np18_flag=\np18_name=spot.max.percent\np18_numValues=0..1\np18_optional=on\np18_prefix=\np18_prefix_when_specified=-s \np18_type=java.lang.Integer\np18_value=\n\np19_MODE=\np19_TYPE=TEXT\np19_default_value=0\np19_description=The minimum number of total reads for a gene to be retained.\np19_fileFormat=\np19_flag=\np19_name=gene.min.reads\np19_numValues=0..1\np19_optional=on\np19_prefix=\np19_prefix_when_specified=-t \np19_type=java.lang.Integer\np19_value=\n\np20_MODE=\np20_TYPE=TEXT\np20_default_value=\np20_description=The maximum number of total reads for a gene to be retained.\np20_fileFormat=\np20_flag=\np20_name=gene.max.reads\np20_numValues=0..1\np20_optional=on\np20_prefix=\np20_prefix_when_specified=-u \np20_type=java.lang.Integer\np20_value=\n\np21_MODE=\np21_TYPE=TEXT\np21_default_value=0\np21_description=The minimum number of spots with non-zero counts for a gene to be retained.\np21_fileFormat=\np21_flag=\np21_name=gene.min.spots\np21_numValues=0..1\np21_optional=on\np21_prefix=\np21_prefix_when_specified=-v \np21_type=java.lang.Integer\np21_value=\n\np22_MODE=\np22_TYPE=TEXT\np22_default_value=\np22_description=The maximum number of spots with non-zero counts for a gene to be retained.\np22_fileFormat=\np22_flag=\np22_name=gene.max.spots\np22_numValues=0..1\np22_optional=on\np22_prefix=\np22_prefix_when_specified=-w \np22_type=java.lang.Integer\np22_value=\n\np23_MODE=\np23_TYPE=TEXT\np23_default_value=0\np23_description=The minimum percentage of spots with non-zero counts for a gene to be retained.\np23_fileFormat=\np23_flag=\np23_name=gene.min.percent\np23_numValues=0..1\np23_optional=on\np23_prefix=\np23_prefix_when_specified=-x \np23_type=java.lang.Integer\np23_value=\n\np24_MODE=\np24_TYPE=TEXT\np24_default_value=\np24_description=The maximum percentage of spots with non-zero counts for a gene to be retained.\np24_fileFormat=\np24_flag=\np24_name=gene.max.percent\np24_numValues=0..1\np24_optional=on\np24_prefix=\np24_prefix_when_specified=-y \np24_type=java.lang.Integer\np24_value=\n\np25_MODE=\np25_TYPE=TEXT\np25_default_value=\np25_description=Samples (as in names(x@counts)) to perform filtering.\np25_fileFormat=\np25_flag=\np25_name=filter.samples\np25_numValues=0..1\np25_optional=on\np25_prefix=\np25_prefix_when_specified=-z \np25_type=java.lang.String\np25_value=\n\np26_MODE=\np26_TYPE=TEXT\np26_default_value=\np26_description=Sample (as in names(x@counts)) to remove from STlist. Removes samples in x@counts, x@tr_counts, x@spatial_meta, x@gene_meta, and x@sample_meta.\np26_fileFormat=\np26_flag=\np26_name=rm.tissue\np26_numValues=0..1\np26_optional=on\np26_prefix=\np26_prefix_when_specified=-A \np26_type=java.lang.String\np26_value=\n\np27_MODE=\np27_TYPE=TEXT\np27_default_value=\np27_description=Vector of spot/cell IDs to remove. Removes spots/cells in x@counts, x@tr_counts, and x@spatial_meta.\np27_fileFormat=\np27_flag=\np27_name=rm.spots\np27_numValues=0..1\np27_optional=on\np27_prefix=\np27_prefix_when_specified=-B \np27_type=java.lang.String\np27_value=\n\np28_MODE=\np28_TYPE=TEXT\np28_default_value=\np28_description=Vector of gene names to remove from STlist. Removes genes in x@counts, x@tr_counts, and x@gene_meta\np28_fileFormat=\np28_flag=\np28_name=rm.genes\np28_numValues=0..1\np28_optional=on\np28_prefix=\np28_prefix_when_specified=-C \np28_type=java.lang.String\np28_value=\n\np29_MODE=\np29_TYPE=TEXT\np29_default_value=\np29_description=A regular expression that matches genes to remove. Removes genes in x@counts, x@tr_counts, and x@gene_meta.\np29_fileFormat=\np29_flag=\np29_name=rm.genes.regex\np29_numValues=0..1\np29_optional=on\np29_prefix=\np29_prefix_when_specified=-D \np29_type=java.lang.String\np29_value=\n\np30_MODE=\np30_TYPE=TEXT\np30_default_value=\np30_description=a expression to use with spot_minpct and spot_maxpct. By default '^MT-'.\np30_fileFormat=\np30_flag=\np30_name=spot.percentage.genes.regex\np30_numValues=0..1\np30_optional=on\np30_prefix=\np30_prefix_when_specified=-E \np30_type=java.lang.Integer\np30_value=\n\np31_MODE=IN\np31_TYPE=FILE\np31_default_value=\np31_description=Metadata associated with each sample in a csv file. The sample names are in the first column, and they must match the names of the folders containing the data.\np31_fileFormat=tsv;csv;txt\np31_flag=\np31_name=input.clinical.data\np31_numValues=0..1\np31_optional=\np31_prefix=\np31_prefix_when_specified=-b \np31_type=java.io.File\np31_value=\n\np32_MODE=\np32_TYPE=TEXT\np32_default_value=True\np32_description=Filter data, T/F\np32_fileFormat=\np32_flag=\np32_name=filter.data\np32_numValues=0..1\np32_optional=\np32_prefix=\np32_prefix_when_specified=-G \np32_type=java.lang.String\np32_value=True;False\n\nprivacy=public\nquality=production\ntaskDoc=\ntaskType=spatial transcriptomics\nuserid=bhill@broadinstitute.org\nversion=Strip .tar from output filenames if its part of the input filename. Stop putting .rds on the rds file twice.\n\njob.memory=8Gb"}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "library('optparse')\nlibrary('spatialGE')\nlibrary('ggplot2')\nlibrary('dplyr')\n\n# Parse the command line options\nparser = OptionParser()\nparser <- add_option(parser, c(\"-f\", \"--file\"), type = 'character', help = \"input.file\")\nparser <- add_option(parser, c(\"-g\", \"--genesets\"),  type = 'character', help = \"gene.sets.database\")\nparser <- add_option(parser, c(\"-p\", \"--permutations\"),  type = \"integer\", help = \"permutations\")\nparser <- add_option(parser, c(\"-r\", \"--seed\"),  type = \"integer\", help = \"random.seed\")\nparser <- add_option(parser, c(\"-s\", \"--spots\"),  type = \"integer\", help = \"minimum.spots\")\nparser <- add_option(parser, c(\"-m\", \"--genes\"),  type = \"integer\", help = \"minimum.genes\")\nparser <- add_option(parser, c(\"-d\", \"--deviations\"),  type = \"double\", help = \"standard.deviations\")\nparser <- add_option(parser, c(\"-w\", \"--pvalues\"),  type = \"double\", help = \"filter.p.values\")\nparser <- add_option(parser, c(\"-i\", \"--proportion\"),  type = \"double\", help = \"filter.gene.proportion\")\nargs <- parse_args(parser)\n\n# Load the RDS file\ndata <- readRDS(args$file)\n\n# Load the gene sets\nraw_file = readLines(args$genesets)\ngene_sets <- lapply(raw_file, function(i) {\n    pw_tmp = unlist(strsplit(i, split='\\\\t'))\n    pw_name_tmp = pw_tmp[1]\n    pw_genes_tmp = pw_tmp[-c(1:2)]\n    return(list(pw_name=pw_name_tmp,\n                pw_genes=pw_genes_tmp))\n})\npws_names = c()\nfor(i in 1:length(gene_sets)) {\n    pws_names = append(pws_names, gene_sets[[i]][['pw_name']])\n    gene_sets[[i]] = gene_sets[[i]][['pw_genes']]\n}\nnames(gene_sets) = pws_names\n\n# Call STenrich\nstenrich_out <- STenrich(data,\n    gene_sets=gene_sets,\n    reps=args$permutations,\n    seed=args$seed,\n    min_units=args$spots,\n    min_genes=args$genes,\n    num_sds=args$deviations)\n#    cores=1)  # Multiple cores may not work on macOS\n\n# Write dataframes to disk\nfor (i in seq_along(stenrich_out)) {\n    write.csv(stenrich_out[[i]], file = paste0(names(stenrich_out)[i], \".csv\"), row.names = F)\n}\n\n# Generate the plot and write to disk\nres <- bind_rows(stenrich_out) %>%\n  mutate(prop_gene_set=size_test/size_gene_set) %>%\n  filter(prop_gene_set >= args$proportion & adj_p_value < args$pvalues)\n#   mutate(slide=str_extract(sample_name, \"Lung5_Rep1|Lung6\")) %>%\n#   select(slide, gene_set) %>%\n#   mutate(gene_set=str_replace(gene_set, 'HALLMARK_', ''))\nggplot(res) +\n  geom_bar(aes(x=gene_set)) +\n  xlab(NULL) +\n  theme(axis.text.x=element_text(angle=70, vjust=1, hjust=1))\n  # facet_wrap(~slide)\nggsave(\n  \"genes_in_fov.png\",\n  plot = last_plot(),\n  device = \"png\",\n  height = 2000,\n  units = \"px\",\n  dpi = 300,\n  limitsize = TRUE\n)\n\nsaveRDS(stenrich_out, file='enrich_stlist.rds')"}, {"role": "assistant", "content": "#spatialGE.STenrich\n#Thu Jun 27 20:52:13 UTC 2018\nJVMLevel=\nLSID=urn:lsid:genepattern.org:module.analysis:00461:999999999\nauthor=Thorin Tabor;UCSD - Mesirov Lab\ncategories=spatial transcriptomics\ncommandLine=Rscript /spatialGE/wrapper.R -f <input.file> -g <gene.sets.database> -p <permutations> -r <random.seed> -s <minimum.spots> -m <minimum.genes> -d <standard.deviations> -w <filter.p.values> -i <filter.gene.proportion>\njob.docker.image=genepattern/spatialge-stenrich:0.4\nsrc.repo=https://github.com/genepattern/spatialGE.STenrich\ncpuType=any\ndescription=Detect genes showing spatial expression patterns (e.g., hotspots). Tests if spots/cells with high average expression of a gene set shows evidence of spatial aggregation.\ndocumentationUrl=https://genepattern.github.io/spatialGE.STenrich/v1/\nfileFormat=\nlanguage=R\nname=spatialGE.STenrich\nos=any\n\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=Normalized spatial transcriptomics data coming from the spatialGE.Preprocessing module.\np1_fileFormat=rds\np1_flag=-f\np1_name=input.file\np1_numValues=0..1\np1_optional=\np1_prefix=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\n\np2_MODE=IN\np2_TYPE=FILE\np2_choiceDir=https\\://www.gsea-msigdb.org/gsea/msigdb/gp_modules_gmt.json\np2_default_value=\np2_description=Select a gene set database to test for spatial enrichment. Upload a gene set if your gene set is not listed as a choice from MSigDB.\np2_fileFormat=gmt;gmx;grp\np2_flag=\np2_name=gene.sets.database\np2_numValues=0..1\np2_optional=\np2_prefix=\np2_prefix_when_specified=\np2_type=java.io.File\np2_value=\n\np3_MODE=\np3_TYPE=Integer\np3_default_value=100\np3_description=The number of permutations to estimate the null distribution (no-spatial pattern). The more permutations, the longer STenrich takes to complete, but p-values may be more accurate.\np3_fileFormat=\np3_flag=-p\np3_name=permutations\np3_numValues=0..1\np3_optional=\np3_prefix=\np3_prefix_when_specified=\np3_type=java.lang.Integer\np3_value=\n\np4_MODE=\np4_TYPE=Integer\np4_default_value=12345\np4_description=A seed number to replicate results. It is advisable to run STenrich with different seed values to check for consistency. Different seed values could yield slightly different p-values.\np4_fileFormat=\np4_flag=-r\np4_name=random.seed\np4_numValues=0..1\np4_optional=\np4_prefix=\np4_prefix_when_specified=\np4_type=java.lang.Integer\np4_value=\n\np5_MODE=\np5_TYPE=Integer\np5_default_value=5\np5_description=The minimum number of high expression ROIs/spots/cells required for a gene set to be tested. If a sample has less than this number of high expression ROIs/spots/cells, the gene set is not tested in that sample.\np5_fileFormat=\np5_flag=-s\np5_name=minimum.spots\np5_numValues=0..1\np5_optional=\np5_prefix=\np5_prefix_when_specified=\np5_type=java.lang.Integer\np5_value=\n\np6_MODE=\np6_TYPE=Integer\np6_default_value=5\np6_description=The minimum number of genes of a set required to be present in a sample, for that gene set to be tested in that sample. If a sample has less genes of a set than this number, the gene set is ignored in that sample.\np6_fileFormat=\np6_flag=-m\np6_name=minimum.genes\np6_numValues=0..1\np6_optional=\np6_prefix=\np6_prefix_when_specified=\np6_type=java.lang.Integer\np6_value=\n\np7_MODE=\np7_TYPE=Float\np7_default_value=1.0\np7_description=The number of standard deviations to define the high expression threshold. If an ROI/spot/cell has average gene set expression larger than the entire sample average plus this many standard deviations, it will be considered a high-expression ROI/spot/cell.\np7_fileFormat=\np7_flag=-d\np7_name=standard.deviations\np7_numValues=0..1\np7_optional=\np7_prefix=\np7_prefix_when_specified=\np7_type=java.lang.Float\np7_value=\n\np8_MODE=\np8_TYPE=Float\np8_default_value=0.05\np8_description=Plot only gene sets whose multiple test adjusted p-value is less than this threshold.\np8_fileFormat=\np8_flag=-d\np8_name=filter.p.values\np8_numValues=0..1\np8_optional=\np8_prefix=\np8_prefix_when_specified=\np8_type=java.lang.Float\np8_value=\n\np9_MODE=\np9_TYPE=Float\np9_default_value=0.3\np9_description=Plot only gene sets where the proportional number genes in the set present in the field of view equals or exceeds this threshold.\np9_fileFormat=\np9_flag=-d\np9_name=filter.gene.proportion\np9_numValues=0..1\np9_optional=\np9_prefix=\np9_prefix_when_specified=\np9_type=java.lang.Float\np9_value=\n\nprivacy=public\nquality=development\ntaskDoc=\ntaskType=spatial transcriptomics\nuserid=tabor\nversion=Write stlist rds to disk"}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "suppressMessages(suppressWarnings(library(\"getopt\")))\nsuppressMessages(suppressWarnings(library(\"optparse\")))\nsuppressMessages(suppressWarnings(library(\"ROCR\")))\n\narguments = commandArgs(trailingOnly = TRUE)\n\noption_list <- list(make_option(\"--ssmatrix\", dest = \"ssmatrix\"), make_option(\"--clsfile\", \n dest = \"clsfile\"), make_option(\"--reverse\", dest = \"reverse\"), make_option(\"--plotnsets\", \n dest = \"plotnsets\"))\n\nopt <- parse_args(OptionParser(option_list = option_list), positional_arguments = TRUE, \n args = arguments)$options\n\nssmatrix = opt$ssmatrix\nclsfile = opt$clsfile\nreverse = as.logical(opt$reverse)\nplotnsets = as.numeric(opt$plotnsets)\n\nset.seed(147)\n\nssauc <- function(ssmatrix, clsfile, reverse, nperm = 1000, permutation.type = 0, \n fraction = 1, replace = F, adjust.FDR.q.val = F) {\n\n filenames <- basename(ssmatrix)\n\n dataset <- read.table(ssmatrix, header = F, stringsAsFactors = FALSE, sep = \"\\t\", \n  fill = TRUE, quote = \"\", na = NA)\n cls.cont <- readLines(clsfile)\n\n dataset <- dataset[-c(1), ]\n colnames(dataset) <- dataset[c(1), ]\n dataset <- dataset[-c(1), ]\n rownames(dataset) <- dataset[, c(1)]\n dataset_descriptions <- as.data.frame(dataset[, c(1, 2)], stringsAsFactors = FALSE)\n dataset <- dataset[, -c(1, 2)]\n\n num.lines <- length(cls.cont)\n cls.cont[[3]] <- gsub(\"\\\\t\", \" \", cls.cont[[3]])  #Converts any tabs to spaces\n class.list <- unlist(strsplit(cls.cont[[3]], \" \"))  #Splits CLS on spaces\n\n cls.cont[[2]] <- gsub(\"\\\\t\", \" \", cls.cont[[2]])  #Converts any tabs to spaces\n class.ids <- unlist(strsplit(cls.cont[[2]], \" \"))  #Splits CLS on spaces\n class.ids <- class.ids[2:length(class.ids)]\n class.ids <- class.ids[class.ids != \"\"]\n\n s <- length(class.list)\n t <- table(class.list)[c(unique(class.list))]\n l <- length(t)\n\n sigfigs <- nchar(strsplit(as.character(1/nperm), \"\\\\.\")[[1]][2])\n\n phen <- vector(length = l, mode = \"character\")\n phen.label <- vector(length = l, mode = \"numeric\")\n class.v <- vector(length = s, mode = \"numeric\")\n for (i in 1:l) {\n  phen[i] <- noquote(names(t)[i])\n  phen.label[i] <- i - 1\n }\n for (i in 1:s) {\n  for (j in 1:l) {\n   if (class.list[i] == phen[j]) {\n    class.v[i] <- phen.label[j]\n   }\n  }\n }\n\n if (reverse == FALSE) {\n  class.labels <- class.v\n } else if (reverse == TRUE) {\n  class.labels <- 1 - class.v\n  phen.label <- rev(phen.label)\n  t <- rev(t)\n  class.ids <- rev(class.ids)\n }\n\n\n names(t) <- class.ids\n\n col.index <- order(class.labels, decreasing = F)\n class.labels <- class.labels[col.index]\n\n class.labels = 1 - class.labels\n\n dataset <- dataset[, c(col.index)]\n dataset_transposed <- as.data.frame(t(dataset), stringsAsFactors = FALSE)\n dataset_calculations <- as.data.frame(cbind(dataset_descriptions, AUC = as.numeric(\"\"), \n  stringsAsFactors = FALSE))\n dataset_calculations <- as.data.frame(cbind(dataset_calculations, `Matthews Correlation (MCC)` = as.numeric(\"\"), \n  stringsAsFactors = FALSE))\n dataset_calculations <- as.data.frame(cbind(dataset_calculations, `cutoff value (Youden Index)` = as.numeric(\"\"), \n  stringsAsFactors = FALSE))\n dataset_calculations <- as.data.frame(cbind(dataset_calculations, Sensitivity = as.numeric(\"\"), \n  stringsAsFactors = FALSE))\n dataset_calculations <- as.data.frame(cbind(dataset_calculations, Specificity = as.numeric(\"\"), \n  stringsAsFactors = FALSE))\n dataset_calculations <- as.data.frame(cbind(dataset_calculations, PPV = as.numeric(\"\"), \n  stringsAsFactors = FALSE))\n dataset_calculations <- as.data.frame(cbind(dataset_calculations, NPV = as.numeric(\"\"), \n  stringsAsFactors = FALSE))\n\n for (i in 1:length(colnames(dataset_transposed))) {\n  pred <- prediction(as.numeric(dataset_transposed[, i]), as.integer(class.labels))\n  perf <- performance(pred, \"tpr\", \"fpr\")\n  auc_perf <- performance(pred, measure = \"auc\")\n  auc_perf <- auc_perf@y.values[[1]]\n  dataset_calculations[i, c(\"AUC\")] <- auc_perf\n  perf2 <- performance(pred, \"mat\")\n  dataset_calculations[i, c(\"Matthews Correlation (MCC)\")] <- as.numeric(perf2@y.values[[1]][which.max(abs(perf2@y.values[[1]]))])\n  if (!is.na(dataset_calculations[i, c(\"Matthews Correlation (MCC)\")])) {\n   if (dataset_calculations[i, c(\"Matthews Correlation (MCC)\")] >= 0) {\n    sensis <- performance(pred, measure = \"sens\")@y.values[[1]]\n    specis <- performance(pred, measure = \"spec\")@y.values[[1]]\n   } else {\n    sensis <- -performance(pred, measure = \"sens\")@y.values[[1]]\n    specis <- -performance(pred, measure = \"spec\")@y.values[[1]]\n   }\n  } else {\n   sensis <- performance(pred, measure = \"sens\")@y.values[[1]]\n   specis <- performance(pred, measure = \"spec\")@y.values[[1]]\n  }\n  summing <- sensis + specis\n  youden_ind <- which.max(summing)\n  cutoffs <- performance(pred, measure = \"sens\")@x.values[[1]]\n  dataset_calculations[i, c(\"cutoff value (Youden Index)\")] <- cutoffs[youden_ind]\n  dataset_calculations[i, c(\"Sensitivity\")] <- performance(pred, measure = \"sens\")@y.values[[1]][youden_ind]\n  dataset_calculations[i, c(\"Specificity\")] <- performance(pred, measure = \"spec\")@y.values[[1]][youden_ind]\n  dataset_calculations[i, c(\"PPV\")] <- performance(pred, measure = \"ppv\")@y.values[[1]][youden_ind]\n  dataset_calculations[i, c(\"NPV\")] <- performance(pred, measure = \"npv\")@y.values[[1]][youden_ind]\n }\n dataset_order <- order(as.numeric(dataset_calculations[, c(\"Matthews Correlation (MCC)\")]), \n  decreasing = TRUE)\n dataset_calculations <- dataset_calculations[dataset_order, ]\n\n rownames(dataset_calculations) <- 1:nrow(dataset_calculations)\n\n\n\n # Permutations\n\n if ((t[[1]] >= 7) & (t[[2]] >= 7)) {\n\n  N <- length(dataset[, 1])\n  Ns <- length(dataset[1, ])\n\n  subset.mask <- matrix(0, nrow = Ns, ncol = nperm)\n  reshuffled.class.labels1 <- matrix(0, nrow = Ns, ncol = nperm)\n  reshuffled.class.labels2 <- matrix(0, nrow = Ns, ncol = nperm)\n  class.labels1 <- matrix(0, nrow = Ns, ncol = nperm)\n  class.labels2 <- matrix(0, nrow = Ns, ncol = nperm)\n\n  auc.phi.matrix <- matrix(0, nrow = N, ncol = nperm)\n  mcc.phi.matrix <- matrix(0, nrow = N, ncol = nperm)\n\n  M1 <- matrix(0, nrow = N, ncol = nperm)\n  M2 <- matrix(0, nrow = N, ncol = nperm)\n  S1 <- matrix(0, nrow = N, ncol = nperm)\n  S2 <- matrix(0, nrow = N, ncol = nperm)\n\n  gc()\n\n  C <- split(class.labels, class.labels)\n  class1.size <- length(C[[1]])\n  class2.size <- length(C[[2]])\n  class1.index <- seq(1, class1.size, 1)\n  class2.index <- seq(class1.size + 1, class1.size + class2.size, 1)\n\n  for (r in 1:nperm) {\n   class1.subset <- sample(class1.index, size = ceiling(class1.size * fraction), \n    replace = replace)\n   class2.subset <- sample(class2.index, size = ceiling(class2.size * fraction), \n    replace = replace)\n   class1.subset.size <- length(class1.subset)\n   class2.subset.size <- length(class2.subset)\n   subset.class1 <- rep(0, class1.size)\n   for (i in 1:class1.size) {\n    if (is.element(class1.index[i], class1.subset)) {\n      subset.class1[i] <- 1\n    }\n   }\n   subset.class2 <- rep(0, class2.size)\n   for (i in 1:class2.size) {\n    if (is.element(class2.index[i], class2.subset)) {\n      subset.class2[i] <- 1\n    }\n   }\n   subset.mask[, r] <- as.numeric(c(subset.class1, subset.class2))\n   fraction.class1 <- class1.size/Ns\n   fraction.class2 <- class2.size/Ns\n\n   if (permutation.type == 0) {\n    # random (unbalanced) permutation\n    full.subset <- c(class1.subset, class2.subset)\n    label1.subset <- sample(full.subset, size = Ns * fraction.class1)\n    reshuffled.class.labels1[, r] <- rep(0, Ns)\n    reshuffled.class.labels2[, r] <- rep(0, Ns)\n    class.labels1[, r] <- rep(0, Ns)\n    class.labels2[, r] <- rep(0, Ns)\n    for (i in 1:Ns) {\n      m1 <- sum(!is.na(match(label1.subset, i)))\n      m2 <- sum(!is.na(match(full.subset, i)))\n      reshuffled.class.labels1[i, r] <- m1\n      reshuffled.class.labels2[i, r] <- m2 - m1\n      if (i <= class1.size) {\n     class.labels1[i, r] <- m2\n     class.labels2[i, r] <- 0\n      } else {\n     class.labels1[i, r] <- 0\n     class.labels2[i, r] <- m2\n      }\n    }\n   } else if (permutation.type == 1) {\n    # proportional (balanced) permutation\n\n    class1.label1.subset <- sample(class1.subset, size = ceiling(class1.subset.size * \n      fraction.class1))\n    class2.label1.subset <- sample(class2.subset, size = floor(class2.subset.size * \n      fraction.class1))\n    reshuffled.class.labels1[, r] <- rep(0, Ns)\n    reshuffled.class.labels2[, r] <- rep(0, Ns)\n    class.labels1[, r] <- rep(0, Ns)\n    class.labels2[, r] <- rep(0, Ns)\n    for (i in 1:Ns) {\n      if (i <= class1.size) {\n     m1 <- sum(!is.na(match(class1.label1.subset, i)))\n     m2 <- sum(!is.na(match(class1.subset, i)))\n     reshuffled.class.labels1[i, r] <- m1\n     reshuffled.class.labels2[i, r] <- m2 - m1\n     class.labels1[i, r] <- m2\n     class.labels2[i, r] <- 0\n      } else {\n     m1 <- sum(!is.na(match(class2.label1.subset, i)))\n     m2 <- sum(!is.na(match(class2.subset, i)))\n     reshuffled.class.labels1[i, r] <- m1\n     reshuffled.class.labels2[i, r] <- m2 - m1\n     class.labels1[i, r] <- 0\n     class.labels2[i, r] <- m2\n      }\n    }\n   }\n  }\n  # message('Computing permutations 1-100 of ', nperm, '...')\n\n  for (d in 1:nperm) {\n   if ((d == 101) || (d == 201) || (d == 301) || (d == 401) || (d == 501) || \n    (d == 601) || (d == 701) || (d == 801) || (d == 901)) {\n    # message('Computing permutations ', d, '-', d + 99, ' of ', nperm, '...')\n   }\n\n   reshuffled.class.labels1 = (1 - reshuffled.class.labels1)\n\n   for (i in 1:length(colnames(dataset_transposed))) {\n    pred <- prediction(as.numeric(dataset_transposed[, i]), as.integer(reshuffled.class.labels1[, \n      d]))\n    auc_perf <- performance(pred, measure = \"auc\")\n    auc.phi.matrix[i, d] <- as.numeric(auc_perf@y.values[[1]])\n    mcc_perf <- performance(pred, \"mat\")\n    if (all(is.finite(mcc_perf@y.values[[1]]))) {\n      mcc.phi.matrix[i, d] <- as.numeric(mcc_perf@y.values[[1]][which.max(abs(mcc_perf@y.values[[1]]))])\n    } else {\n      mcc.phi.matrix[i, d] <- paste0(unique(mcc_perf@y.values[[1]]), \n     collapse = \";\")\n    }\n   }\n   auc.phi.matrix <- auc.phi.matrix[dataset_order, ]\n   mcc.phi.matrix <- mcc.phi.matrix[dataset_order, ]\n\n  }\n\n  auc.p.vals <- matrix(0, nrow = N, ncol = 2)\n  mcc.p.vals <- matrix(0, nrow = N, ncol = 2)\n\n  # message('Computing pValues from AUC null distribution...')\n\n  for (i in 1:N) {\n   pos.phi <- NULL\n   neg.phi <- NULL\n   for (j in 1:nperm) {\n    if (auc.phi.matrix[i, j] >= 0.5) {\n      pos.phi <- c(pos.phi, auc.phi.matrix[i, j])\n    } else {\n      neg.phi <- c(neg.phi, auc.phi.matrix[i, j])\n    }\n   }\n   ES.value <- dataset_calculations[i, c(\"AUC\")]\n   if (ES.value >= 0.5) {\n    auc.p.vals[i, 1] <- format(round(signif(sum(pos.phi >= ES.value)/length(pos.phi)), \n      digits = sigfigs), nsmall = sigfigs)\n   } else {\n    auc.p.vals[i, 1] <- format(round(signif(sum(neg.phi <= ES.value)/length(neg.phi)), \n      digits = sigfigs), nsmall = sigfigs)\n   }\n  }\n\n  # message('Computing pValues from MCC null distribution...')\n\n  for (i in 1:N) {\n   pos.phi <- NULL\n   neg.phi <- NULL\n   for (j in 1:nperm) {\n    if (mcc.phi.matrix[i, j] >= 0) {\n      pos.phi <- c(pos.phi, mcc.phi.matrix[i, j])\n    } else {\n      neg.phi <- c(neg.phi, mcc.phi.matrix[i, j])\n    }\n   }\n   ES.value <- dataset_calculations[i, c(\"Matthews Correlation (MCC)\")]\n   if (!is.na(ES.value)) {\n    if (ES.value >= 0) {\n      mcc.p.vals[i, 1] <- format(round(signif(sum(pos.phi >= ES.value)/length(pos.phi)), \n     digits = sigfigs), nsmall = sigfigs)\n    } else {\n      mcc.p.vals[i, 1] <- format(round(signif(sum(neg.phi <= ES.value)/length(neg.phi)), \n     digits = sigfigs), nsmall = sigfigs)\n    }\n   } else {\n    mcc.p.vals[i, 1] <- NA\n   }\n  }\n\n\n  dataset_calculations <- cbind(dataset_calculations, `AUC NOM pValue` = format(auc.p.vals[, \n   1], nsmall = sigfigs))\n  dataset_calculations <- cbind(dataset_calculations, `MCC NOM pValue` = format(mcc.p.vals[, \n   1], nsmall = sigfigs))\n\n  # message('Computing FDR q-values from MCC distributions...')\n  Ng <- dim(dataset_calculations)[1]\n\n  NES <- vector(length = Ng, mode = \"numeric\")\n  phi.norm.mean <- vector(length = Ng, mode = \"numeric\")\n  obs.phi.norm.mean <- vector(length = Ng, mode = \"numeric\")\n  phi.norm.median <- vector(length = Ng, mode = \"numeric\")\n  obs.phi.norm.median <- vector(length = Ng, mode = \"numeric\")\n  phi.norm.mean <- vector(length = Ng, mode = \"numeric\")\n  # obs.phi.mean <- vector(length = Ng, mode = 'numeric')\n  FDR.mean <- vector(length = Ng, mode = \"numeric\")\n  FDR.median <- vector(length = Ng, mode = \"numeric\")\n  # phi.norm.median.d <- vector(length = Ng, mode = 'numeric')\n  # obs.phi.norm.median.d <- vector(length = Ng, mode = 'numeric')\n\n  # Obs.ES.index <- dataset_calculations[, c('AUC')] Orig.index <- seq(1, Ng)\n  # Orig.index <- Orig.index[Obs.ES.index] Orig.index <- order(Orig.index,\n  # decreasing = F) Obs.ES.norm.sorted <- Obs.ES.norm[Obs.ES.index]\n  # Obs.ES.norm.sorted <- dataset_calculations[, c('AUC')] #AUC gs.names.sorted <-\n  # gs.names[Obs.ES.index]\n\n  for (k in 1:Ng) {\n   # NES[k] <- Obs.ES.norm.sorted[k]\n   NES[k] <- as.numeric(dataset_calculations[, c(\"Matthews Correlation (MCC)\")][k])\n   ES.value <- NES[k]\n   count.col <- vector(length = nperm, mode = \"numeric\")\n   obs.count.col <- vector(length = nperm, mode = \"numeric\")\n   for (i in 1:nperm) {\n    # phi.vec <- phi.norm[, i]\n    phi.vec <- mcc.phi.matrix[, i]\n    # obs.phi.vec <- obs.phi.norm[, i]\n    obs.phi.vec <- as.numeric(dataset_calculations[, c(\"Matthews Correlation (MCC)\")])\n    if (!is.na(ES.value)) {\n      if (ES.value >= 0) {\n     count.col.norm <- sum(phi.vec >= 0)\n     obs.count.col.norm <- sum(obs.phi.vec >= 0)\n     count.col[i] <- ifelse(count.col.norm > 0, sum(phi.vec >= ES.value)/count.col.norm, \n       0)\n     obs.count.col[i] <- ifelse(obs.count.col.norm > 0, sum(obs.phi.vec >= \n       ES.value)/obs.count.col.norm, 0)\n      } else {\n     count.col.norm <- sum(phi.vec < 0)\n     obs.count.col.norm <- sum(obs.phi.vec < 0)\n     count.col[i] <- ifelse(count.col.norm > 0, sum(phi.vec <= ES.value)/count.col.norm, \n       0)\n     obs.count.col[i] <- ifelse(obs.count.col.norm > 0, sum(obs.phi.vec <= \n       ES.value)/obs.count.col.norm, 0)\n      }\n    } else {\n     count.col.norm <- NA\n     obs.count.col.norm <- NA\n     count.col[i] <- NA\n     obs.count.col[i] <- NA\n    }\n   }\n   phi.norm.mean[k] <- mean(count.col)\n   obs.phi.norm.mean[k] <- mean(obs.count.col)\n   phi.norm.median[k] <- median(count.col)\n   obs.phi.norm.median[k] <- median(obs.count.col)\n   FDR.mean[k] <- ifelse(phi.norm.mean[k]/obs.phi.norm.mean[k] < 1, phi.norm.mean[k]/obs.phi.norm.mean[k], \n    1)\n   FDR.median[k] <- ifelse(phi.norm.median[k]/obs.phi.norm.median[k] < 1, \n    phi.norm.median[k]/obs.phi.norm.median[k], 1)\n  }\n\n  # adjust q-values\n\n  if (adjust.FDR.q.val == T) {\n   pos.nes <- length(NES[NES >= 0])\n   min.FDR.mean <- FDR.mean[pos.nes]\n   min.FDR.median <- FDR.median[pos.nes]\n   for (k in seq(pos.nes - 1, 1, -1)) {\n    if (FDR.mean[k] < min.FDR.mean) {\n      min.FDR.mean <- FDR.mean[k]\n    }\n    if (min.FDR.mean < FDR.mean[k]) {\n      FDR.mean[k] <- min.FDR.mean\n    }\n   }\n\n   neg.nes <- pos.nes + 1\n   min.FDR.mean <- FDR.mean[neg.nes]\n   min.FDR.median <- FDR.median[neg.nes]\n   for (k in seq(neg.nes + 1, Ng)) {\n    if (FDR.mean[k] < min.FDR.mean) {\n      min.FDR.mean <- FDR.mean[k]\n    }\n    if (min.FDR.mean < FDR.mean[k]) {\n      FDR.mean[k] <- min.FDR.mean\n    }\n   }\n  }\n\n  FDR.mean <- signif(FDR.mean, digits = 5)\n  FDR.median <- signif(FDR.median, digits = 5)\n\n  dataset_calculations <- cbind(dataset_calculations, `MCC FDR` = FDR.mean)\n  # dataset_calculations <- cbind(dataset_calculations, `MCC FDR (Median)` =\n  # FDR.median)\n }\n\n dataset_calculations <- as.data.frame(cbind(dataset_calculations, `ssGSEA Score Wilcox pValue` = \"\", \n  stringsAsFactors = FALSE))\n for (i in 1:dim(dataset_calculations)[1]) {\n  dataset_calculations[i, dim(dataset_calculations)[2]] <- as.numeric(wilcox.test(as.numeric(dataset_transposed[1:eval(t[1]), \n   dataset_calculations[i, 1]]), as.numeric(dataset_transposed[eval(1 + \n   t[1]):eval(t[1] + t[2]), dataset_calculations[i, 1]]))[3])\n }\n\n return(list(filenames = filenames, auc = dataset_calculations, dataset = dataset_transposed, \n  sigfigs = sigfigs, class.labels = class.labels, t = t))\n}\n\nresult <- ssauc(ssmatrix, clsfile, reverse)\n\nfilenames <- result$filenames\n\ndataset_calculations <- result$auc\n\ndataset <- result$dataset\nsigfigs <- result$sigfigs\nclass.labels <- result$class.labels\nt <- result$t\n\nnames <- c(paste0(names(t)[1], \" (N=\", t[[1]], \")\"), paste0(names(t)[2], \" (N=\", \n t[[2]], \")\"))\nnames2 <- paste0(names(t)[1], \" (N=\", t[[1]], \") vs. \", names(t)[2], \" (N=\", t[[2]], \n \")\")\n\n# plotnsets=dim(dataset)[2]\n\nif (plotnsets > dim(dataset)[2]) {\n # message('More sets selcted than available in input, plotting results for all\n # sets.')\n plotnsets <- dim(dataset)[2]\n}\nplotsets <- unique(c(head(dataset_calculations[, c(1)], plotnsets), tail(dataset_calculations[, \n c(1)], plotnsets)))\n\ndirection = paste0(names(t)[1], \"vs\", names(t)[2])\n\nwrite.table(dataset_calculations, paste0(filenames, \".\", direction, \".Results.tsv\"), \n quote = FALSE, col.names = TRUE, row.names = FALSE, sep = \"\\t\")\n\n\npdf(file = paste0(filenames, \".\", direction, \".Plots.pdf\"), width = 14)\nfor (i in 1:length(plotsets)) {\n\n if ((as.numeric(dataset_calculations[dataset_calculations[c(1)] == plotsets[i], \n  c(\"AUC\")]) >= 0.5) && (as.numeric(dataset_calculations[dataset_calculations[c(1)] == \n  plotsets[i], c(\"Matthews Correlation (MCC)\")]) >= 0)) {\n  direction_color = \"red\"\n  legendloc = \"bottomright\"\n  adjloc = c(-0.05, 1)\n } else if ((as.numeric(dataset_calculations[dataset_calculations[c(1)] == plotsets[i], \n  c(\"AUC\")]) < 0.5) && (as.numeric(dataset_calculations[dataset_calculations[c(1)] == \n  plotsets[i], c(\"Matthews Correlation (MCC)\")]) < 0)) {\n  direction_color = \"blue\"\n  legendloc = \"topleft\"\n  adjloc = c(1.05, -1)\n } else {\n  direction_color = \"darkgray\"\n  legendloc = \"bottomright\"\n  adjloc = c(-0.05, 1)\n }\n pred <- prediction(as.numeric(eval(parse(text = paste0(\"dataset$\", dataset_calculations[dataset_calculations[c(1)] == \n  plotsets[i], 1])))), as.integer(class.labels))\n perf <- performance(pred, \"tpr\", \"fpr\")\n par(mfrow = c(1, 2))\n plot(perf, main = paste0(dataset_calculations[dataset_calculations[c(1)] == plotsets[i], \n  1], \"\\n\", names2, \" ROC\"), type = \"l\", col = direction_color, cex.main = 1)\n points(1 - as.numeric(dataset_calculations[dataset_calculations[c(1)] == plotsets[i], \n  c(\"Specificity\")]), as.numeric(dataset_calculations[dataset_calculations[c(1)] == \n  plotsets[i], c(\"Sensitivity\")]), col = \"slategrey\", pch = 20)\n text(1 - as.numeric(dataset_calculations[dataset_calculations[c(1)] == plotsets[i], \n  c(\"Specificity\")]), as.numeric(dataset_calculations[dataset_calculations[c(1)] == \n  plotsets[i], c(\"Sensitivity\")]), col = \"slategrey\", labels = paste0(\"cutoff value (Youden Index): \", \n  round(as.numeric(dataset_calculations[dataset_calculations[c(1)] == plotsets[i], \n   c(\"cutoff value (Youden Index)\")]), 5)), adj = adjloc, cex = 0.8)\n\n legend(legendloc, c(paste0(\"AUC: \", format(round(as.numeric(dataset_calculations[dataset_calculations[c(1)] == \n  plotsets[i], c(\"AUC\")]), 5), nsmall = 5)), paste0(\"MCC: \", format(round(as.numeric(dataset_calculations[dataset_calculations[c(1)] == \n  plotsets[i], c(\"Matthews Correlation (MCC)\")]), 5), nsmall = 5))), bty = \"n\", \n  cex = 0.8)\n abline(a = 0, b = 1)\n boxplot(as.numeric(dataset[1:eval(t[1]), dataset_calculations[dataset_calculations[c(1)] == \n  plotsets[i], 1]]), as.numeric(dataset[eval(1 + t[1]):eval(t[1] + t[2]), dataset_calculations[dataset_calculations[c(1)] == \n  plotsets[i], 1]]), names = names, ylab = \"Enrichment Score (ssGSEA)\", xlab = paste0(\"Wilcox pValue: \", \n  format(as.numeric(dataset_calculations[dataset_calculations[c(1)] == plotsets[i], \n   c(\"ssGSEA Score Wilcox pValue\")]), format = \"e\", digits = sigfigs, flag = \"#\")))\n title(paste0(dataset_calculations[dataset_calculations[c(1)] == plotsets[i], \n  1], \"\\nssGSEA Scores\"), cex.main = 1)\n}\nsuppressMessages(suppressWarnings(dev.off()))\n# message(paste0('Plots saved as: ', filenames, '.', direction, '.Plots.pdf'))"}, {"role": "assistant", "content": "#ssGSEA_ROC\n#Thu Feb 25 19:27:18 UTC 2021\nJVMLevel=\nLSID=urn\\:lsid\\:broad.mit.edu\\:cancer.software.genepattern.module.analysis\\:00414\\:999999999\nauthor=Anthony S. Castanza;UCSD-MesirovLab\ncategories=statistical methods;gsea\ncommandLine=<Rscript> <libdir>ssGSEA_ROC.R --ssmatrix <PROJ.gct> --clsfile <CLS> --reverse <Reverse> --plotnsets <Plot.Top.Results>\ncpuType=any\ndescription=Generate ROC curves and calculate the AUC from ssGSEA results and a binary phenotype classification.\nfileFormat=pdf;tsv\njob.docker.image=genepattern/ssgsea_roc:1.1\nlanguage=any\nname=ssGSEA.ROC\nos=any\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=PROJ.gct result from ssGSEA.\np1_fileFormat=gct\np1_flag=--ssmatrix\np1_name=PROJ.gct\np1_numValues=1..1\np1_optional=\np1_prefix=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\np2_MODE=IN\np2_TYPE=FILE\np2_default_value=\np2_description=Two Phenotype CLS file for classifying the ssGSEA projections.\np2_fileFormat=cls\np2_flag=--clsfile\np2_name=CLS\np2_numValues=1..1\np2_optional=\np2_prefix=\np2_prefix_when_specified=\np2_type=java.io.File\np2_value=\np3_MODE=\np3_TYPE=TEXT\np3_default_value=FALSE\np3_description=Reverse direction of the projections. <br> By default (FALSE) ROCR will calculate statistics for the first phenotype in the cls vs. the second phenotype. <br> Setting this flag to \"TRUE\" will calculate the second phenotype vs. the first phenotype.\np3_fileFormat=\np3_flag=--reverse\np3_name=Reverse\np3_numValues=1..1\np3_optional=\np3_prefix=\np3_prefix_when_specified=\np3_type=java.lang.String\np3_value=FALSE\\=FALSE;TRUE\\=TRUE\np4_MODE=\np4_TYPE=Integer\np4_default_value=20\np4_description=Plot ROC curves for the top N gene sets in each direction.\np4_fileFormat=\np4_flag=--plotnsets\np4_name=Plot.Top.Results\np4_numValues=1..1\np4_optional=\np4_prefix=\np4_prefix_when_specified=\np4_range=1+\np4_type=java.lang.Integer\np4_value=\nprivacy=public\nquality=preproduction\ntaskDoc=ssGSEA_ROC.pdf\ntaskType=beta\nuserid=acastanza\nversion="}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n__tool_name__='STREAM'\nprint('''\n   _____ _______ _____  ______          __  __ \n  / ____|__   __|  __ \\|  ____|   /\\   |  \\/  |\n | (___    | |  | |__) | |__     /  \\  | \\  / |\n  \\___ \\   | |  |  _  /|  __|   / /\\ \\ | |\\/| |\n  ____) |  | |  | | \\ \\| |____ / ____ \\| |  | |\n |_____/   |_|  |_|  \\_\\______/_/    \\_\\_|  |_|\n... Dimension Reduction                                               \n''',flush=True)\n\nimport stream as st\nimport argparse\nimport multiprocessing\nimport os\nfrom slugify import slugify\nimport networkx as nx\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\nimport sys\nimport ast\n\nmpl.use('Agg')\nmpl.rc('pdf', fonttype=42)\n\nos.environ['KMP_DUPLICATE_LIB_OK']='True'\n\n\nprint('- STREAM Single-cell Trajectory Reconstruction And Mapping -',flush=True)\nprint('Version %s\\n' % st.__version__,flush=True)\n    \n\ndef main():\n    sns.set_style('white')\n    sns.set_context('poster')\n    parser = argparse.ArgumentParser(description='%s Parameters' % __tool_name__ ,formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"-m\", \"--data-file\", dest=\"input_filename\",default = None, help=\"input file name, pkl format from Stream preprocessing module\", metavar=\"FILE\")\n    parser.add_argument(\"-of\",\"--of\",dest=\"output_filename_prefix\", default=\"StreamiFSOutput\",  help=\"output file name prefix\")\n\n    parser.add_argument(\"-nb_pct\",\"--percent_neighbor_cells\",dest=\"nb_pct\", type=float, default=None, help=\"\")\n    parser.add_argument(\"-n_comp_k\",dest=\"n_comp_k\", type = int, default=None,  help=\"\")\n    parser.add_argument(\"-feat\",dest=\"feature\", default=None,   help=\"feature\")\n\n    parser.add_argument(\"-method\",dest=\"method\",  default=None,  help=\"\")\n    parser.add_argument(\"-nc_plot\",dest=\"nc_plot\", type=int, default=None,  help=\"\")\n    parser.add_argument(\"-comp1\",dest=\"comp1\", default=None,   help=\"feature\")\n    parser.add_argument(\"-comp2\",dest=\"comp2\", type=int, default=None,  help=\"\")\n    parser.add_argument(\"-fig_width\",dest=\"fig_width\", type=int, default=8, help=\"\")        \n    parser.add_argument(\"-fig_height\",dest=\"fig_height\", type=int, default=8, help=\"\")\n    parser.add_argument(\"-n_jobs\",dest=\"n_jobs\", type=int, default=2,  help=\"\")\n    \n    parser.add_argument(\"-fig_legend_ncol\",dest=\"fig_legend_ncol\", type=int, default=None, help=\"\")                                   \n\n\n    args = parser.parse_args()\n    print(args)\n    \n    print('Starting dimension reduction procedure...')\n\n    workdir = \"./\"\n\n    adata = st.read(file_name=args.input_filename, file_format='pkl', experiment='rna-seq', workdir=workdir)\n    print(\"Feature \" , args.feature, type(args.feature))\n    st.dimension_reduction(adata,method=args.method, feature='var_genes', nb_pct=args.nb_pct,n_components=args.n_comp_k, n_jobs=args.n_jobs ,eigen_solver=None)\n\n    fig_size=(args.fig_width, args.fig_height)\n    st.plot_dimension_reduction(adata, n_components=args.nc_plot, comp1=args.comp1, comp2=args.comp2, save_fig=True, \n                            fig_name=(args.output_filename_prefix + '_stddev_dotplot.png'),\n                            fig_path=\"./\",fig_size=fig_size,fig_legend_ncol=args.fig_legend_ncol)\n\n\n    st.write(adata,file_name=(args.output_filename_prefix + '_stream_result.pkl'),file_path='./',file_format='pkl') \n    print('Output: '+ str(adata.obs.shape[0]) + ' cells, ' + str(adata.var.shape[0]) + ' genes')\n\n    print('Finished computation.')\n\nif __name__ == \"__main__\":\n    main()"}, {"role": "assistant", "content": "#Fri, 22 Jun 2018 09:09:40 -0700\n# STREAM\n#Tues Jun 11 21:02:09 UTC 2019\nJVMLevel=\nLSID=urn:lsid:broad.mit.edu:cancer.software.genepattern.module.analysis:00397:9999999\nauthor=Ted Liefeld, UCSD School of Medicine.\ncategories=SingleCell\n\ncommandLine=python /stream/dimred_command_line.py -m <data.file> -of <output.filename> <percent.neighbor.cells> <num.components.to.keep> <feature>  <method> <num.components.to.plot> <component.x> <component.y> <figure.width> <figure.height>  <figure.legend.num.columns>  -n_jobs <job.cpuCount>\ncpuType=any\ndescription=Perform dimension reduction on the dataset to make it easier to reliably assess similarity or distances between cells. Starting from the genes selected in the STREAM.FeatureSelection module, we project cells to a lower dimensional space using a non-linear dimensionality reduction method.\nfileFormat=pkl\nlanguage=any\nminGenePatternVersion=3.9.13\nname=STREAM.DimensionReduction\nos=any\njob.docker.image=genepattern/stream_dimensionreduction:0.3\njob.cpuCount=2\njob.memory=8 Gb\njob.walltime=1\\:00\\:00\n\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=A STREAM pkl file containing gene expression data\np1_fileFormat=pkl\np1_flag=\np1_name=data.file\np1_numValues=1..1\np1_optional=\np1_prefix=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\n\np2_MODE=\np2_TYPE=TEXT\np2_default_value=\np2_description=output file name prefix\np2_fileFormat=\np2_flag=\np2_name=output.filename\np2_numValues=1..1\np2_optional=\np2_prefix=\np2_prefix_when_specified=  \np2_type=java.lang.String\np2_value=\n\np3_MODE=\np3_TYPE=CHOICE\np3_default_value=\np3_description=The percentage neighbor cells (only valid when 'mlle', 'se', or 'umap' is specified).\np3_fileFormat=\np3_flag=\np3_name=percent.neighbor.cells\np3_numValues=0..1\np3_optional=on\np3_prefix=\np3_prefix_when_specified=-nb_pct   \np3_type=java.lang.String\np3_value=\n\np4_MODE=\np4_TYPE=CHOICE\np4_default_value=3\np4_description=Number of components to keep\np4_fileFormat=\np4_flag=\np4_name=num.components.to.keep\np4_numValues=1..1\np4_optional=\np4_prefix=\np4_prefix_when_specified=-n_comp_k   \np4_type=java.lang.String\np4_value=\n\np5_MODE=\np5_TYPE=CHOICE\np5_default_value=\np5_description=Feature used for dimension reduction. Choose from ['var_genes','top_pcs','all']. 'var_genes': most variable genes. 'top_pcs': top principal components.  'all': all genes\np5_fileFormat=\np5_flag=\np5_name=feature\np5_numValues=1..1\np5_optional=on\np5_prefix=\np5_prefix_when_specified=-feat  \np5_type=java.lang.String\np5_value=var_genes\\=most variable genes;top_pcs\\=top principal components;all\\=all\n\np6_MODE=\np6_TYPE=CHOICE\np6_default_value=\np6_description=Method used for dimension reduction.Choose from {{'mlle','umap','pca'}}\np6_fileFormat=\np6_flag=\np6_name=method\np6_numValues=1..1\np6_optional=\np6_prefix=\np6_prefix_when_specified=-method \np6_type=java.lang.String\np6_value=mlle\\=Modified locally linear embedding algorithm (MLLE);umap\\=Uniform Manifold Approximation and Projection (UMAP);pca\\=Principal component analysis (PCA)\n\n\np7_MODE=\np7_TYPE=CHOICE\np7_default_value=3\np7_description=Number of components to be plotted.\np7_fileFormat=\np7_flag=\np7_name=num.components.to.plot\np7_numValues=1..1\np7_optional=\np7_prefix=\np7_prefix_when_specified=-nc_plot \np7_type=java.lang.String\np7_value=\n\np8_MODE=\np8_TYPE=CHOICE\np8_default_value=0\np8_description=Component used for x axis.\np8_fileFormat=\np8_flag=\np8_name=component.x\np8_numValues=0..1\np8_optional=\np8_prefix=\np8_prefix_when_specified=-comp1  \np8_type=java.lang.String\np8_value=\n\n\np9_MODE=\np9_TYPE=TEXT\np9_default_value=1\np9_description=Component used for y axis.\np9_fileFormat=\np9_flag=\np9_name=component.y\np9_numValues=0..1 \np9_optional=on\np9_prefix=\np9_prefix_when_specified=-comp2  \np9_type=java.lang.String\np9_value=\n\np10_MODE=\np10_TYPE=TEXT\np10_default_value=8\np10_description=figure width \np10_fileFormat=\np10_flag=\np10_name=figure.width\np10_numValues=0..1\np10_optional=on\np10_prefix=\np10_prefix_when_specified=-fig_width   \np10_type=java.lang.String\np10_value=\n\np11_MODE=\np11_TYPE=TEXT\np11_default_value=3\np11_description=The number of columns that the legend has.\np11_fileFormat=\np11_flag=\np11_name=figure.legend.num.columns\np11_numValues=1..1\np11_optional=\np11_prefix=\np11_prefix_when_specified=-fig_legend_ncol  \np11_type=java.lang.String\np11_value=\n\np12_MODE=\np12_TYPE=TEXT\np12_default_value=8\np12_description=figure height\np12_fileFormat=\np12_flag=\np12_name=figure.height\np12_numValues=0..1\np12_optional=on\np12_prefix=\np12_prefix_when_specified=-fig_height  \np12_type=java.lang.String\np12_value=\n\n\nprivacy=public\npublicationDate=06/11/2019 09\\:09 \nquality=beta\nrequiredPatchLSIDs=\nrequiredPatchURLs=\ntaskDoc=doc.html\ntaskType=ScRnaSeq\nuserid=ted\nversion=inital revision"}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "suppressMessages(suppressWarnings(library(\"getopt\")))\nsuppressMessages(suppressWarnings(library(\"optparse\")))\nsuppressMessages(suppressWarnings(library(\"AnVIL\")))\nsuppressMessages(suppressWarnings(library(\"cBioPortalData\")))\n# suppressMessages(suppressWarnings(library('dplyr')))\n\nsink(stdout(), type = \"message\")\n\narguments = commandArgs(trailingOnly = TRUE)\n\noption_list <- list(make_option(\"--id\", dest = \"id\"), make_option(\"--symbol\", dest = \"symbol\"),\n make_option(\"--high\", dest = \"high\", type = \"numeric\"), make_option(\"--low\",\n  dest = \"low\", type = \"numeric\"), make_option(\"--type\", dest = \"type\"), make_option(\"--msigdb\",\n  dest = \"msigdb\", default = \"latest\"))\n\nopt <- parse_args(OptionParser(option_list = option_list), positional_arguments = TRUE,\n args = arguments)$options\n\ntcgasamples = as.character(opt$id)\nsymbol_query = as.character(opt$symbol)\nthreshold_pos = as.numeric(opt$high)\nthreshold_neg = (-1) * abs(as.numeric(opt$low))\ndata.type = as.character(opt$type)\nmsigdbversion = as.character(opt$msigdb)\nassay = \"RNA_Seq_v2_mRNA_median_all_sample_Zscores\"  #linear_CNA could also work # Original assay name\nalt_assay = \"mrna_seq_v2_rsem_zscores_ref_all_samples\"  # Assay was renamed for some reason in November 2021, this is the new name. Script will check for the old name first then fall back to this in case the change is reverted.\n\nset.seed(147)\n\ncbiosamples <- paste0(tolower(tcgasamples), \"_tcga\")\n\n# Getting TCGA Dataset\ndataset = paste0(\"http://gdac.broadinstitute.org/runs/stddata__2016_01_28/data/\",\n tcgasamples, \"/20160128/gdac.broadinstitute.org_\", tcgasamples, \".Merge_rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes__data.Level_3.2016012800.0.0.tar.gz\")\n\nif (msigdbversion == \"latest\") {\n versionquery <- readLines(\"https://software.broadinstitute.org/cancer/software/gsea/wiki/index.php/Version_check\")\n versionquery <- strsplit(versionquery[grep(pattern = \"TCGA_SampleSelection\",\n  versionquery)], \": \")\n msigdbversion <- versionquery[[1]][2]\n}\nmsigdbshortversion = strsplit(msigdbversion, \"\\\\.\")[[1]]\nmsigdbshortversion = as.numeric(paste0(msigdbshortversion[1], \".\", msigdbshortversion[2]))\n\nif (as.numeric(msigdbshortversion) < 7.1) {\n stop(paste0(\"MSigDB Version \", msigdbversion, \" is not supported. Please try a newer version.\"))\n} else if (as.numeric(msigdbshortversion) == 7.1) {\n symbolchip <- read.table(url(paste0(\"https://data.broadinstitute.org/gsea-msigdb/msigdb/annotations_versioned/Human_Symbol_with_Remapping_MSigDB.v\",\n  msigdbversion, \".chip\")), header = TRUE, stringsAsFactors = FALSE, sep = \"\\t\",\n  quote = \"\", fill = TRUE, na = \"\")\n} else if (as.numeric(msigdbshortversion) >= 7.2 && as.numeric(msigdbshortversion) <= 2022) {\n symbolchip <- read.table(url(paste0(\"https://data.broadinstitute.org/gsea-msigdb/msigdb/annotations_versioned/Human_Gene_Symbol_with_Remapping_MSigDB.v\",\n  msigdbversion, \".chip\")), header = TRUE, stringsAsFactors = FALSE, sep = \"\\t\",\n  quote = \"\", fill = TRUE, na = \"\")\n} else {\n symbolchip <- read.table(url(paste0(\"https://data.broadinstitute.org/gsea-msigdb/msigdb/annotations/human/Human_Gene_Symbol_with_Remapping_MSigDB.v\",\n  msigdbversion, \".chip\")), header = TRUE, stringsAsFactors = FALSE, sep = \"\\t\",\n  quote = \"\", fill = TRUE, na = \"\")\n}\n\nsymbolchip <- symbolchip[, -c(3)]\n\nif (symbol_query != \"none\") {\n output <- paste0(c(\"TCGA\", tcgasamples, symbol_query, \"HIGH_stdev_greater_than\",\n  threshold_pos, \"vs\", \"LOW_stdev_less_than_neg\", abs(threshold_neg)), collapse = \"_\")\n\n symbol_mapped <- symbolchip[symbolchip$Probe.Set.ID == symbol_query, ][, c(2)]\n if (length(symbol_mapped) > 1) {\n  message(\"Error: More than one possible mapping was detected for selected gene in the TCGA Dataset\")\n  print(symbol_mapped)\n  stop()\n }\n\n if (length(symbol_mapped) == 0) {\n  stop(paste0(\"The symbol \\\"\", opt$symbol, \"\\\" was not recognised as a valid gene.\"))\n } else if (length(symbol_mapped) == 1) {\n  print(paste0(\"The symbol \\\"\", opt$symbol, \"\\\" was recognised as a valid gene: \",\n   symbol_mapped))\n } else {\n  stop(paste0(\"An error was encountered with the mapping of \\\"\", opt$symbol,\n   \"\\\" to valid gene symbols: \", symbol_mapped))\n }\n} else {\n output <- paste0(c(\"TCGA\", tcgasamples), collapse = \"_\")\n symbol_mapped <- \"none\"\n}\n\ntemp <- tempfile()\nsuppressMessages(suppressWarnings(download.file(dataset, temp)))\nfname_zipped = basename(dataset)\nfnames = as.character(untar(temp, list = TRUE))\nuntar(temp)\nunlink(fnames[basename(fnames) == \"MANIFEST.txt\"])\nfnames = fnames[basename(fnames) != \"MANIFEST.txt\"]\nlst = vector(\"list\", length(fnames))\nfor (i in seq_along(fnames)) {\n lst[[i]] = read.table(fnames[i], stringsAsFactors = FALSE, sep = \"\\t\")\n}\nunlink(fnames)\nunlink(temp)\n\ndata <- lst[[1]]\nnames <- do.call(\"rbind\", strsplit(data[, c(1)], \"|\", fixed = TRUE))\n\nif (data.type == \"scaled_estimate\") {\n data <- cbind(as.data.frame(names[, c(2)], stringsAsFactors = FALSE), data[,\n  data[c(2), ] == \"scaled_estimate\"])\n} else if (data.type == \"raw_count\") {\n data <- cbind(as.data.frame(names[, c(2)], stringsAsFactors = FALSE), data[,\n  data[c(2), ] == \"raw_count\"])\n}\n\n\nnames(data) = data[c(1), ]\ndata <- data[-c(1, 2), ]\n\nif (as.numeric(msigdbshortversion) == 7.1 || as.numeric(msigdbshortversion) == 7.2) {\n chip <- read.table(url(paste0(\"https://data.broadinstitute.org/gsea-msigdb/msigdb/annotations_versioned/Human_NCBI_Entrez_Gene_ID_MSigDB.v\",\n  msigdbversion, \".chip\")), header = TRUE, stringsAsFactors = FALSE, sep = \"\\t\",\n  quote = \"\", fill = TRUE, na = \"\")\n} else if (as.numeric(msigdbshortversion) < 2022) {\n chip <- read.table(url(paste0(\"https://data.broadinstitute.org/gsea-msigdb/msigdb/annotations_versioned/Human_NCBI_Gene_ID_MSigDB.v\",\n  msigdbversion, \".chip\")), header = TRUE, stringsAsFactors = FALSE, sep = \"\\t\",\n  quote = \"\", fill = TRUE, na = \"\")\n} else {\n chip <- read.table(url(paste0(\"https://data.broadinstitute.org/gsea-msigdb/msigdb/annotations/human/Human_NCBI_Gene_ID_MSigDB.v\",\n  msigdbversion, \".chip\")), header = TRUE, stringsAsFactors = FALSE, sep = \"\\t\",\n  quote = \"\", fill = TRUE, na = \"\")\n}\n\nchip <- chip[, -c(3)]\n\nmappeddata <- merge(x = chip, y = data, by.x = 1, by.y = 1, all = FALSE, no.dups = FALSE)\n# ezid_lookup <- mappeddata[mappeddata$Gene.Symbol==symbol_mapped,][,c(1)]\n# if(length(ezid_lookup) > 1) { message('More than one possible EntrezGeneID\n# mapping was detected for selected gene in the TCGA Dataset') stop() }\nmappeddata <- mappeddata[, -c(1)]\n\nmappeddata[, c(2:ncol(mappeddata))] <- sapply(mappeddata[, c(2:ncol(mappeddata))],\n as.numeric)\nmappeddata[is.na(mappeddata)] <- 0\n\nmappeddata <- mappeddata %>%\n group_by(.data$Gene.Symbol) %>%\n summarise_all(sum) %>%\n data.frame()\n\nprint(paste0(\"Unfiltered dataset contains \", ncol(mappeddata) - 1, \" samples.\"))\n\n# Retrieve Sample Expression Thresholding Information from cBioPortal\n\ncbiodata <- suppressMessages(suppressWarnings(cBioDataPack(cbiosamples, ask = FALSE)))\nassays <- assays(cbiodata)\ncbioassay <- assays[[assay]]\nif (is.null(cbioassay)) {\n cbioassay <- assays[[alt_assay]]\n}\ncbioassay <- as.data.frame(cbind(rownames(cbioassay), cbioassay), stringsAsFactors = FALSE)\nmappedcbioassay <- merge(x = symbolchip, y = cbioassay, by.x = 1, by.y = 1, all = FALSE,\n no.dups = FALSE)\nmappedcbioassay <- mappedcbioassay[, -c(1)]\nmappedcbioassay[, c(2:ncol(mappedcbioassay))] <- sapply(mappedcbioassay[, c(2:ncol(mappedcbioassay))],\n as.numeric)\nmappedcbioassay[is.na(mappedcbioassay)] <- 0\nmappedcbioassay <- mappedcbioassay %>%\n group_by(.data$Gene.Symbol) %>%\n summarise_all(max) %>%\n data.frame()\nallnames <- names(mappeddata)\n\nif (symbol_mapped != \"none\") {\n sample_pos <- names(mappedcbioassay)[mappedcbioassay[mappedcbioassay$Gene.Symbol ==\n  symbol_mapped, ] >= as.numeric(threshold_pos)]\n sample_pos <- sample_pos[sample_pos != \"Gene.Symbol\"]\n sample_neg <- names(mappedcbioassay)[mappedcbioassay[mappedcbioassay$Gene.Symbol ==\n  symbol_mapped, ] <= as.numeric(threshold_neg)]\n sample_neg <- sample_neg[sample_neg != \"Gene.Symbol\"]\n\n if (length(sample_pos) == 0) {\n  if (length(sample_neg) == 0) {\n   stop(paste0(\"No samples were selected for either condition.\"))\n  }\n  stop(paste0(\"No samples were selected for the positive condition.\"))\n }\n if (length(sample_neg) == 0) {\n  stop(paste0(\"No samples were selected for the negative condition.\"))\n }\n\n print(paste0(\"Samples selected for the positive condition: \", length(sample_pos)))\n print(paste0(\"Samples selected for the negative condition: \", length(sample_neg)))\n print(paste0(\"Total samples selected: \", length(sample_pos) + length(sample_neg)))\n\n matches_pos <- unique(grep(paste(sample_pos, collapse = \"|\"), allnames, value = TRUE))\n matches_neg <- unique(grep(paste(sample_neg, collapse = \"|\"), allnames, value = TRUE))\n fullnames <- c(matches_pos, matches_neg)\n restricted <- mappeddata[, fullnames]\n\n clslabels <- c(replicate(length(matches_pos), \"HIGH\"), replicate(length(matches_neg),\n  \"LOW\"))\n\n write.table(paste(c(dim(restricted)[2], 2, \"1\"), collapse = \" \"), paste0(output,\n  \".cls\"), sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE)\n write.table(paste(\"#\", paste0(symbol_query, \"_HIGH\"), paste0(symbol_query, \"_LOW\"),\n  collapse = \" \"), paste0(output, \".cls\"), sep = \"\\t\", row.names = FALSE, col.names = FALSE,\n  quote = FALSE, append = TRUE)\n write.table(paste(clslabels, collapse = \" \"), paste0(output, \".cls\"), sep = \"\\t\",\n  row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)\n} else {\n restricted <- mappeddata[, names(mappeddata) != \"Gene.Symbol\"]\n}\n\nmatrix <- as.data.frame(cbind(NAME = mappeddata[, c(1)], Description = mappeddata[,\n c(1)], restricted), stringsAsFactors = FALSE)\n\nif (data.type == \"scaled_estimate\") {\n write.table(\"#1.2\", paste0(output, \".TPM.gct\"), row.names = FALSE, col.names = FALSE,\n  quote = FALSE)\n write.table(t(as.data.frame(dim(restricted))), paste0(output, \".TPM.gct\"), sep = \"\\t\",\n  row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)\n suppressWarnings(write.table(matrix, paste0(output, \".TPM.gct\"), sep = \"\\t\",\n  row.names = FALSE, col.names = TRUE, quote = FALSE, append = TRUE))\n} else if (data.type == \"raw_count\") {\n write.table(\"#1.2\", paste0(output, \".counts.gct\"), row.names = FALSE, col.names = FALSE,\n  quote = FALSE)\n write.table(t(as.data.frame(dim(restricted))), paste0(output, \".counts.gct\"),\n  sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)\n suppressWarnings(write.table(matrix, paste0(output, \".counts.gct\"), sep = \"\\t\",\n  row.names = FALSE, col.names = TRUE, quote = FALSE, append = TRUE))\n}"}, {"role": "assistant", "content": "#TCGA.SampleSelection\n#Thu Feb 25 19:28:34 UTC 2021\nJVMLevel=\nLSID=urn:lsid:genepattern.org:module.analysis:00417\nauthor=Anthony S. Castanza;UCSD-MesirovLab\ncategories=preprocess & utilities;gsea\ncommandLine=Rscript /TCGA_SS/TCGA_Datasets.R --id <TCGA.Collection> --symbol <Gene.Symbol> --high <High.Expression> --low <Low.Expression> --type <Output.Type> --msigdb <MSigDB.Version>\ncpuType=any\ndescription=Retrieve TCGA data from Broad FireBrowse and perform sample selection on the basis of expression levels for specific genes of interest for analysis using GSEA tools.\nfileFormat=cls;gct\njob.docker.image=genepattern/tcga-sampleselection:beta6\nsrc.repo=https://github.com/genepattern/TCGA.SampleSelection/tree/v0.14\nlanguage=any\njob.memory=4 Gb\nname=TCGA.SampleSelection\nos=any\np1_MODE=\np1_TYPE=TEXT\np1_default_value=GBM\np1_description=TCGA Study for sample selection\np1_fileFormat=\np1_flag=--id\np1_name=TCGA.Collection\np1_numValues=1..1\np1_optional=\np1_prefix=\np1_prefix_when_specified=\np1_type=java.lang.String\np1_value=LAML\\=Acute Myeloid Leukemia (LAML);ACC\\=Adrenocortical carcinoma (ACC);BLCA\\=Bladder urothelial carcinoma (BLCA);LGG\\=Brain Lower Grade Glioma (LGG);BRCA\\=Breast invasive carcinoma (BRCA);CESC\\=Cervical and endocervical cancers (CESC);CHOL\\=Cholangiocarcinoma (CHOL);COAD\\=Colon adenocarcinoma (COAD);COADREAD\\=Colorectal adenocarcinoma (COADREAD);ESCA\\=Esophageal carcinoma (ESCA);GBM\\=Glioblastoma multiforme (GBM);GBMLGG\\=Glioma (GBMLGG);HNSC\\=Head and Neck squamous cell carcinoma (HNSC);KICH\\=Kidney Chromophobe (KICH);KIRC\\=Kidney renal clear cell carcinoma (KIRC);KIRP\\=Kidney renal papillary cell carcinoma (KIRP);LIHC\\=Liver hepatocellular carcinoma (LIHC);LUAD\\=Lung adenocarcinoma (LUAD);LUSC\\=Lung squamous cell carcinoma (LUSC);DLBC\\=Lymphoid Neoplasm Diffuse Large B-cell Lymphoma (DLBC);MESO\\=Mesothelioma (MESO);OV\\=Ovarian serous cystadenocarcinoma (OV);KIPAN\\=Pan-kidney cohort (KICH+KIRC+KIRP) (KIPAN);PAAD\\=Pancreatic adenocarcinoma (PAAD);PCPG\\=Pheochromocytoma and Paraganglioma (PCPG);PRAD\\=Prostate adenocarcinoma (PRAD);READ\\=Rectum adenocarcinoma (READ);SARC\\=Sarcoma (SARC);SKCM\\=Skin Cutaneous Melanoma (SKCM);STAD\\=Stomach adenocarcinoma (STAD);STES\\=Stomach and Esophageal carcinoma (STES);TGCT\\=Testicular Germ Cell Tumors (TGCT);THYM\\=Thymoma (THYM);THCA\\=Thyroid carcinoma (THCA);UCS\\=Uterine Carcinosarcoma (UCS);UCEC\\=Uterine Corpus Endometrial Carcinoma (UCEC);UVM\\=Uveal Melanoma (UVM)\np2_MODE=\np2_TYPE=TEXT\np2_default_value=\np2_description=HGNC Gene Symbol to use for expression level thresholding\np2_fileFormat=\np2_flag=--symbol\np2_name=Gene.Symbol\np2_numValues=1..1\np2_optional=\np2_prefix=\np2_prefix_when_specified=\np2_type=java.lang.String\np2_value=\np3_MODE=\np3_TYPE=Floating Point\np3_default_value=1\np3_description=mRNA expression is greater than or equal to x standard deviations above the mean. <br>\\n(mRNA expression z-scores relative to all samples)\np3_fileFormat=\np3_flag=--high\np3_name=High.Expression\np3_numValues=1..1\np3_optional=\np3_prefix=\np3_prefix_when_specified=\np3_range=0+\np3_type=java.lang.Float\np3_value=\np4_MODE=\np4_TYPE=Floating Point\np4_default_value=-1\np4_description=mRNA expression is less than or equal to x standard deviations below the mean. <br>\\n(mRNA expression z-scores relative to all samples)\np4_fileFormat=\np4_flag=--low\np4_name=Low.Expression\np4_numValues=1..1\np4_optional=\np4_prefix=\np4_prefix_when_specified=\np4_range=0-\np4_type=java.lang.Float\np4_value=\np5_MODE=\np5_TYPE=TEXT\np5_default_value=scaled_estimate\np5_description=Type of RSEM quantifications to output\\:\\n<br>TPM (transcripts per million, within sample normalization, useful for ssGSEA)\\n<br> Raw counts (unnormalized counts, usable with DESeq2 or other DEG calculations).\np5_fileFormat=\np5_flag=--type\np5_name=Output.Type\np5_numValues=1..1\np5_optional=\np5_prefix=\np5_prefix_when_specified=\np5_type=java.lang.String\np5_value=scaled_estimate\\=TPM;raw_count\\=Raw Counts\np6_MODE=\np6_TYPE=TEXT\np6_default_value=latest\np6_description=MSigDB version to use for Gene Symbol lookup.<br>\\nThis version should match the version of the gene sets intended for all downstream analysis.<br><a href=\"https://software.broadinstitute.org/cancer/software/gsea/wiki/index.php/Release_Notes\" target=\"_blank\">Click here for a current listing of all MSigDB versions.</a>\np6_fileFormat=\np6_flag=--msigdb\np6_name=MSigDB.Version\np6_numValues=1..1\np6_optional=\np6_prefix=\np6_prefix_when_specified=\np6_type=java.lang.String\np6_value=\nprivacy=public\nquality=preproduction\ntaskDoc=TCGA.SampleSelection.pdf\ntaskType=preprocess & utilities\nuserid=acastanza\nversion= Update for non-float MSigDB version numbers"}]}
{"messages": [{"role": "system", "content": "You are a genius GenePattern developer who writes manifest files based on wrapper scripts. Youwill be fired for any mistakes you make"}, {"role": "user", "content": "# tximport.deseq2.normalize\nsuppressMessages(suppressWarnings(library(\"devtools\")))\nsuppressMessages(suppressWarnings(library(\"tools\")))\nsuppressMessages(suppressWarnings(library(\"tximport\")))\nsuppressMessages(suppressWarnings(library(\"DESeq2\")))\nsuppressMessages(suppressWarnings(library(\"getopt\")))\nsuppressMessages(suppressWarnings(library(\"optparse\")))\n\narguments <- commandArgs(trailingOnly = TRUE)\n\noption_list <- list(\n  make_option(\"--quant\", dest = \"Quantifications\"),\n  make_option(\"--type\", dest = \"Quant.Type\"),\n  make_option(\"--txdb\", dest = \"Transcriptome.Database\", default = NULL),\n  make_option(\"--info\", dest = \"Sample.Info\", default = NULL),\n  make_option(\"--counts\", dest = \"Output.Normalized.Counts\"),\n  make_option(\"--tpm\", dest = \"Output.TPM\"),\n  make_option(\"--basename\", dest = \"output.file.base\"),\n  make_option(\"--annotate\", dest = \"annotate\"),\n  make_option(\"--reverse\", dest = \"reverse\"),\n  make_option(\"--split\", dest = \"Split.Identifiers\"),\n  make_option(\"--filter\", dest = \"filter\", type = \"integer\", default = 1),\n  make_option(\"--seed\", dest = \"random.seed\", type = \"integer\", default = 779948241)\n)\n\nopt <- parse_args(OptionParser(option_list = option_list),\n  positional_arguments = TRUE,\n  args = arguments\n)$options\n\nquanttype <- as.character(opt$Quant.Type)\ncounts <- as.logical(opt$Output.Normalized.Counts)\nTPM <- as.logical(opt$Output.TPM) # nolint\noutfile <- as.character(opt$output.file.base)\nsplit <- as.logical(opt$Split.Identifiers)\nseed <- as.integer(opt$random.seed)\nannotate <- as.logical(opt$annotate)\nreverse <- as.logical(opt$reverse)\n\nif (opt$Transcriptome.Database != \"\") {\n  transcriptome <- opt$Transcriptome.Database\n  suppressMessages(suppressWarnings(library(\"GenomicFeatures\")))\n  txdb <- suppressMessages(suppressWarnings(makeTxDbFromGFF(file = transcriptome)))\n  k <- suppressMessages(suppressWarnings(keys(txdb, keytype = \"TXNAME\")))\n  tx2gene <- suppressMessages(suppressWarnings(select(txdb, k, \"GENEID\", \"TXNAME\")))\n}\n\nset.seed(seed)\n\ntximportfiles <- readLines(opt$Quantifications, warn = FALSE)\n\nif (quanttype == \"RSEM\") {\n  names(tximportfiles) <- gsub(\".gz$\", \"\", basename(tximportfiles))\n  names(tximportfiles) <- gsub(\".genes.results\", \"\", names(tximportfiles))\n  txi <- suppressMessages(suppressWarnings(tximport(tximportfiles,\n    type = \"rsem\",\n    txIn = FALSE, txOut = FALSE\n  )))\n  tpmmatrix <- txi$abundance\n}\n\nif (quanttype == \"SALMON\") {\n  names(tximportfiles) <- gsub(\".gz$\", \"\", basename(tximportfiles))\n  names(tximportfiles) <- gsub(\".quant.sf\", \"\", names(tximportfiles))\n  txi <- suppressMessages(suppressWarnings(tximport(tximportfiles,\n    type = \"salmon\",\n    tx2gene = tx2gene, ignoreAfterBar = TRUE\n  )))\n  tpmmatrix <- txi$abundance\n}\n\nif (quanttype == \"SAILFISH\") {\n  names(tximportfiles) <- gsub(\".gz$\", \"\", basename(tximportfiles))\n  names(tximportfiles) <- gsub(\".quant.sf\", \"\", names(tximportfiles))\n  txi <- suppressMessages(suppressWarnings(tximport(tximportfiles,\n    type = \"sailfish\",\n    tx2gene = tx2gene, ignoreAfterBar = TRUE\n  )))\n  tpmmatrix <- txi$abundance\n}\n\nif (quanttype == \"KallistoH5\") {\n  library(\"rhdf5\")\n  names(tximportfiles) <- gsub(\".gz$\", \"\", basename(tximportfiles))\n  names(tximportfiles) <- gsub(\".abundance.h5\", \"\", names(tximportfiles))\n  txi <- suppressMessages(suppressWarnings(tximport(tximportfiles,\n    type = \"kallisto\",\n    tx2gene = tx2gene, ignoreAfterBar = TRUE\n  )))\n  tpmmatrix <- txi$abundance\n}\n\nif (quanttype == \"KallistoTSV\") {\n  names(tximportfiles) <- gsub(\".gz$\", \"\", basename(tximportfiles))\n  names(tximportfiles) <- gsub(\".abundance.tsv\", \"\", names(tximportfiles))\n  txi <- suppressMessages(suppressWarnings(tximport(tximportfiles,\n    type = \"kallisto\",\n    tx2gene = tx2gene, ignoreAfterBar = TRUE\n  )))\n  tpmmatrix <- txi$abundance\n}\n\n\n# DESeq2 Normalize/Quant\ntxi$length[txi$length == 0] <- 1\n\n\ncoldata <- as.data.frame(colnames(txi$counts), stringsAsFactors = TRUE, header = FALSE)\ncolnames(coldata) <- c(\"EXPERIMENT\")\nrownames(coldata) <- colnames(txi$counts)\nif (opt$Sample.Info == \"\") {\n  dds <- suppressMessages(suppressWarnings(DESeqDataSetFromTximport(txi,\n    colData = coldata,\n    ~1\n  )))\n} else if (opt$Sample.Info != \"\") {\n  info <- read.table(\n    text = gsub(\",\", \"\\t\", readLines(opt$Sample.Info, warn = FALSE)),\n    stringsAsFactors = TRUE\n  )\n  if (dim(info)[1] == 1 + dim(coldata)[1]) {\n    info <- read.table(\n      text = gsub(\",\", \"\\t\", readLines(opt$Sample.Info, warn = FALSE)),\n      stringsAsFactors = TRUE, header = TRUE\n    )\n  }\n  coldata <- merge(x = coldata, y = info, by.x = 1, by.y = 1)\n  rownames(coldata) <- coldata[, 1]\n  levels <- paste(rev(colnames(coldata[2:length(coldata)])), collapse = \" + \")\n  design <- as.formula(paste(\"~\", levels))\n\n  txi$abundance <- txi$abundance[, rownames(coldata)]\n  txi$counts <- txi$counts[, rownames(coldata)]\n  txi$length <- txi$length[, rownames(coldata)]\n  tpmmatrix <- txi$abundance\n  if (txi$countsFromAbundance != \"no\") {\n    txi$countsFromAbundance <- txi$countsFromAbundance[, rownames(coldata)] # nolint\n  }\n\n  dds <- suppressMessages(suppressWarnings(DESeqDataSetFromTximport(txi,\n    colData = coldata,\n    design = design\n  )))\n  dds <- suppressMessages(suppressWarnings(DESeq(dds)))\n  if (reverse == FALSE) {\n    # Compute Log2FC using the first factor vs. the second factor\n    res <- results(dds, contrast = c(\n      colnames(coldata)[2], levels(coldata[, c(2)])[1],\n      levels(coldata[, c(2)])[2]\n    ))\n  } else if (reverse == TRUE) {\n    # Compute Log2FC using the second factor vs. the first factor\n    res <- results(dds, contrast = c(\n      colnames(coldata)[2], levels(coldata[, c(2)])[2],\n      levels(coldata[, c(2)])[1]\n    ))\n  }\n  results <- as.data.frame(res, stringsAsFactors = FALSE)\n  colnames(results) <- res@elementMetadata@listData$description\n\n  if (split == TRUE) {\n    splitids <- rownames(results)\n    splitids <- sub(\"NM_\", \"NM.\", splitids)\n    mat <- do.call(\"rbind\", strsplit(sub(\"_\", \";\", splitids), \";\"))\n    mat[, 1] <- sub(\"NM.\", \"NM_\", mat[, 1])\n    mat <- as.data.frame(mat, stringsAsFactors = FALSE)\n    if (dim(mat)[2] == 1) {\n      mat <- as.data.frame(cbind(mat, mat), stringsAsFactors = FALSE)\n    }\n    if (length(grep(\"^ENS\", mat[, 1])) == length(mat[, 1])) {\n      mat2 <- as.data.frame(do.call(\"rbind\", strsplit(sub(\"[.]\", \";\", mat[\n        ,\n        1\n      ]), \";\")))\n      mat[, 1] <- mat2[, 1]\n    }\n\n    colnames(mat) <- c(\"NAME\", \"Description\")\n  } else if (split == FALSE) {\n    mat <- as.data.frame(rownames(results), stringsAsFactors = FALSE)\n    mat <- as.data.frame(cbind(mat, Description = \"na\"), stringsAsFactors = FALSE)\n\n    if (length(grep(\"^ENS\", mat[, 1])) == length(mat[, 1])) {\n      mat2 <- as.data.frame(do.call(\"rbind\", strsplit(sub(\"[.]\", \";\", mat[\n        ,\n        1\n      ]), \";\")))\n      mat[, 2] <- mat[, 1]\n      mat[, 1] <- mat2[, 1]\n    }\n\n    colnames(mat) <- c(\"NAME\", \"Description\")\n  }\n\n  if (annotate == FALSE) {\n    degmatrix <- as.data.frame(cbind(mat, results), stringsAsFactors = FALSE)\n    colnames(degmatrix)[1] <- \"Gene_ID\"\n    colnames(degmatrix)[2] <- \"Details\"\n    degmatrix <- degmatrix[order(degmatrix$\"BH adjusted p-values\", decreasing = FALSE), ]\n    suppressWarnings(write.table(degmatrix, paste0(outfile, \".Differential.Expression.txt\"),\n      sep = \"\\t\", row.names = FALSE, col.names = TRUE, quote = FALSE\n    ))\n  } else if (annotate == TRUE) {\n    if (opt$Transcriptome.Database != \"\") {\n      gtf_db <- as.data.frame(rtracklayer::import(transcriptome), stringsAsFactors = FALSE)\n      gtf_db2 <- unique(gtf_db[, c(\"gene_id\", \"gene_name\")])\n      degmatrix <- as.data.frame(cbind(mat, results), stringsAsFactors = FALSE)\n      degmatrix_ann <- merge(\n        x = gtf_db2, y = degmatrix, by.x = 1, by.y = 0,\n        all.x = FALSE, all.y = TRUE\n      )\n      degmatrix_ann <- degmatrix_ann[, -c(1)]\n      degmatrix_ann <- degmatrix_ann[,c(2,1,3:ncol(degmatrix_ann))]\n      colnames(degmatrix_ann)[1] <- \"Gene_ID\"\n      colnames(degmatrix_ann)[2] <- \"Gene_Symbol\"\n      colnames(degmatrix_ann)[3] <- \"Gene_Details\"\n      degmatrix_ann <- degmatrix_ann[order(degmatrix_ann$\"BH adjusted p-values\",\n        decreasing = FALSE\n      ), ]\n      suppressWarnings(write.table(degmatrix_ann, paste0(outfile, \".Differential.Expression.txt\"),\n        sep = \"\\t\", row.names = FALSE, col.names = TRUE, quote = FALSE\n      ))\n    } else {\n      message(\"No GTF provided. Unable to annotate results with gene symbols.\")\n      degmatrix <- as.data.frame(cbind(mat, results), stringsAsFactors = FALSE)\n      colnames(degmatrix)[1] <- \"Gene_ID\"\n      colnames(degmatrix)[2] <- \"Details\"\n      degmatrix <- degmatrix[order(degmatrix$\"BH adjusted p-values\", decreasing = FALSE), ]\n      suppressWarnings(write.table(degmatrix, paste0(outfile, \".Differential.Expression.txt\"),\n        sep = \"\\t\", row.names = FALSE, col.names = TRUE, quote = FALSE\n      ))\n    }\n  }\n\n  write.table(paste(c(dim(coldata)[1], length(unique(coldata[, c(2)])), \"1\"), collapse = \" \"),\n    paste0(outfile, \".cls\"),\n    sep = \"\\t\", row.names = FALSE, col.names = FALSE,\n    quote = FALSE\n  )\n  write.table(paste(\"#\", paste(unique(coldata[, c(2)]), collapse = \" \"), collapse = \" \"),\n    paste0(outfile, \".cls\"),\n    sep = \"\\t\", row.names = FALSE, col.names = FALSE,\n    quote = FALSE, append = TRUE\n  )\n  write.table(paste(coldata[, c(2)], collapse = \" \"), paste0(outfile, \".cls\"),\n    sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE\n  )\n}\n\nif (as.integer(opt$filter) > 0) {\n  keep <- rowSums(counts(dds)) >= as.integer(opt$filter)\n  dds <- dds[keep, ]\n}\n\ndds <- suppressMessages(suppressWarnings(estimateSizeFactors(dds)))\nnorm_counts <- suppressMessages(suppressWarnings(counts(dds, normalized = TRUE)))\n\nif (split == TRUE) {\n  splitids <- rownames(norm_counts)\n  splitids <- sub(\"NM_\", \"NM.\", splitids)\n  mat <- do.call(\"rbind\", strsplit(sub(\"_\", \";\", splitids), \";\"))\n  mat[, 1] <- sub(\"NM.\", \"NM_\", mat[, 1])\n  mat <- as.data.frame(mat, stringsAsFactors = FALSE)\n  if (dim(mat)[2] == 1) {\n    mat <- as.data.frame(cbind(mat, mat), stringsAsFactors = FALSE)\n  }\n  if (length(grep(\"^ENS\", mat[, 1])) == length(mat[, 1])) {\n    mat2 <- as.data.frame(do.call(\"rbind\", strsplit(\n      sub(\"[.]\", \";\", mat[, 1]),\n      \";\"\n    )))\n    mat[, 1] <- mat2[, 1]\n  }\n\n  colnames(mat) <- c(\"NAME\", \"Description\")\n} else if (split == FALSE) {\n  mat <- as.data.frame(rownames(norm_counts), stringsAsFactors = FALSE)\n  mat <- as.data.frame(cbind(mat, Description = \"na\"), stringsAsFactors = FALSE)\n\n  if (length(grep(\"^ENS\", mat[, 1])) == length(mat[, 1])) {\n    mat2 <- as.data.frame(do.call(\"rbind\", strsplit(\n      sub(\"[.]\", \";\", mat[, 1]),\n      \";\"\n    )))\n    mat[, 2] <- mat[, 1]\n    mat[, 1] <- mat2[, 1]\n  }\n\n  colnames(mat) <- c(\"NAME\", \"Description\")\n}\n\nif (counts == TRUE) {\n  countmatrix <- as.data.frame(cbind(mat, norm_counts), stringsAsFactors = FALSE)\n  write.table(\"#1.2\", paste0(outfile, \".Normalized.Counts.gct\"),\n    row.names = FALSE,\n    col.names = FALSE, quote = FALSE\n  )\n  write.table(t(as.data.frame(dim(norm_counts))), paste0(outfile, \".Normalized.Counts.gct\"),\n    sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE\n  )\n  suppressWarnings(write.table(countmatrix, paste0(outfile, \".Normalized.Counts.gct\"),\n    sep = \"\\t\", row.names = FALSE, col.names = TRUE, quote = FALSE, append = TRUE\n  ))\n}\n\nif (TPM == TRUE) {\n  # TPM\n  if (split == TRUE) {\n    splitids <- rownames(tpmmatrix)\n    splitids <- sub(\"NM_\", \"NM.\", splitids)\n    mat <- do.call(\"rbind\", strsplit(sub(\"_\", \";\", splitids), \";\"))\n    mat[, 1] <- sub(\"NM.\", \"NM_\", mat[, 1])\n    mat <- as.data.frame(mat, stringsAsFactors = FALSE)\n    if (dim(mat)[2] == 1) {\n      mat <- as.data.frame(cbind(mat, mat), stringsAsFactors = FALSE)\n    }\n    if (length(grep(\"^ENS\", mat[, 1])) == length(mat[, 1])) {\n      mat2 <- as.data.frame(do.call(\"rbind\", strsplit(sub(\"[.]\", \";\", mat[\n        ,\n        1\n      ]), \";\")))\n      mat[, 1] <- mat2[, 1]\n    }\n\n    colnames(mat) <- c(\"NAME\", \"Description\")\n  } else if (split == FALSE) {\n    mat <- as.data.frame(rownames(tpmmatrix), stringsAsFactors = FALSE)\n    mat <- as.data.frame(cbind(mat, Description = \"na\"), stringsAsFactors = FALSE)\n\n    if (length(grep(\"^ENS\", mat[, 1])) == length(mat[, 1])) {\n      mat2 <- as.data.frame(do.call(\"rbind\", strsplit(sub(\"[.]\", \";\", mat[\n        ,\n        1\n      ]), \";\")))\n      mat[, 2] <- mat[, 1]\n      mat[, 1] <- mat2[, 1]\n    }\n\n    colnames(mat) <- c(\"NAME\", \"Description\")\n  }\n  tpmmatrix <- as.data.frame(cbind(mat, tpmmatrix), stringsAsFactors = FALSE)\n  write.table(\"#1.2\", paste0(outfile, \".TPM.gct\"),\n    row.names = FALSE, col.names = FALSE,\n    quote = FALSE\n  )\n  write.table(t(as.data.frame(dim(txi$abundance))), paste0(outfile, \".TPM.gct\"),\n    sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE\n  )\n  suppressWarnings(write.table(tpmmatrix, paste0(outfile, \".TPM.gct\"),\n    sep = \"\\t\",\n    row.names = FALSE, col.names = TRUE, quote = FALSE, append = TRUE\n  ))\n}"}, {"role": "assistant", "content": "#tximport.DESeq2.Normalize\n#Mon Nov 23 22:31:05 UTC 2020\nJVMLevel=\nLSID=urn\\:lsid\\:genepattern.org\\:module.analysis\\:00422\\:4\nauthor=Anthony S. Castanza;UCSD-MesirovLab\ncategories=differential expression\ncommandLine=<Rscript> <libdir>tximport.deseq2.R --quant\\=<Quantifications> --type\\=<Quant.Type> --txdb\\=<Transcriptome.Database> --info\\=<Sample.Info> --counts\\=<Output.Normalized.Counts> --tpm\\=<Output.TPM> --basename\\=<output.file.base> --annotate\\=<Annotate.DEGs> --reverse\\=<Reverse.Sign> --split\\=<Split.Identifiers>  --filter\\=<Min.Count.Filter> --seed\\=<random.seed>\ncpuType=any\ndescription=Imports RNA-seq quantifications from frequently used pipelines using the tximport package and outputs a DESeq2 \"normalized counts\" file in .GCT format suitable for use with GSEA, and/or a TPM .GCT suitable for ssGSEA.<br>\\nIf a Sample Info file is provided containing assignments of samples to phenotypes, gene level differential expression will be calculated using DESeq2 for the two phenotypes.\ndocumentationUrl=https\\://github.com/genepattern/tximport.DESeq2/blob/main/docs/v1/index.md\nfileFormat=cls;gct;txt\njob.docker.image=genepattern/tximport_deseq2\\:1.0\nlanguage=any\nname=tximport.DESeq2\nos=any\np10_MODE=\np10_TYPE=TEXT\np10_default_value=TRUE\np10_description=Some pipelines produce a gene label that combines a reference ID and a Gene Symbol joined by an underscore (e.g. ENSG00000141510_TP53).\\n<br>\\n<b>TRUE</b> will attempt to split these into the reference ID and the Gene Symbol. The reference ID will be used as the NAME column of the GCT and the Gene Symbol will be used as the Description.\\n<br>\\n<b>FALSE</b> will leave the identifiers as-is.\\n\np10_fileFormat=\np10_flag=--split\np10_name=Split.Identifiers\np10_numValues=1..1\np10_optional=\np10_prefix=\np10_prefix_when_specified=\np10_type=java.lang.String\np10_value=TRUE\\=TRUE;FALSE\\=FALSE\np11_MODE=\np11_TYPE=Integer\np11_default_value=1\np11_description=Keep genes with more than <Min.Count.Filter> counts summed over all samples (default\\: 1 count; 0 \\= disabled)\np11_fileFormat=\np11_flag=--filter\np11_name=Min.Count.Filter\np11_numValues=1..1\np11_optional=\np11_prefix=\np11_prefix_when_specified=\np11_range=0+\np11_type=java.lang.Integer\np11_value=\np12_MODE=\np12_TYPE=TEXT\np12_default_value=779948241\np12_description=Integer used to configure the workspace. Setting this to a constant ensures uniformity for any operations that use random numbers.\np12_fileFormat=\np12_flag=--seed\np12_name=random.seed\np12_numValues=1..1\np12_optional=\np12_prefix=\np12_prefix_when_specified=\np12_type=java.lang.String\np12_value=\np1_MODE=IN\np1_TYPE=FILE\np1_default_value=\np1_description=Output files from the respective pipeline. Files must be named with the sample ID and the appropriate extension for the quantification tool.\\n<br>\\nExample\\:\\n\".genes.results\" files output from RSEM\\: Sample_1.genes.results\\n<br>\\n\".quant.sf\" or \".quant.sf.gz\" files output from Salmon/Sailfish\\: Sample_1.quant.sf/Sample_1.quant.sf.gz\\n<br>\\n\".abundance.h5\" or \".abundance.tsv\" files output from Kallisto\\: Sample_1.abundance.h5/Sample_1.abundance.h5.gz/Sample_1.abundance.tsv/Sample_1.abundance.tsv.gz\\n<br><br>\\nAll files must have been quantified using the same application and the same transcriptome.\\n<br>\\nSupports gzip (.gz) files.\np1_fileFormat=gz;h5;results;sf;tsv\np1_flag=--quant\np1_name=Quantifications\np1_numValues=1+\np1_optional=\np1_prefix=\np1_prefix_when_specified=\np1_type=java.io.File\np1_value=\np2_MODE=IN\np2_TYPE=FILE\np2_default_value=\np2_description=<b>Optional</b> tab delimited text file containing Sample ID to Phenotype mappings. Sample IDs should match exactly the ID used in the input file (without the file extension).<br>\\nIf provided, this file will be used to compute deferentially expressed genes using DESeq2.\\n<br>By default, Log2(FC) will be calculated for the first Factor level vs the second Factor level (Phenotype_A vs. Phenotype_B).\\n<br><br>\\n<style type\\=\"text/css\">\\n.tg  {border-collapse\\:collapse;border-spacing\\:0;}\\n.tg td{border-color\\:black;border-style\\:solid;border-width\\:1px;font-family\\:Arial, sans-serif;font-size\\:12px;}\\n.tg th{border-color\\:black;border-style\\:solid;border-width\\:1px;font-family\\:Arial, sans-serif;font-size\\:12px;\\n  font-weight\\:normal;}\\n.tg .tg-0pky{border-color\\:inherit;text-align\\:left;vertical-align\\:top}\\n</style>\\n<table class\\=\"tg\">\\n<tbody>\\n  <tr>\\n    <th class\\=\"tg-0pky\">SampleID</th>\\n    <th class\\=\"tg-0pky\">Factor</th>\\n  </tr>\\n  <tr>\\n    <td class\\=\"tg-0pky\">Sample_1</td>\\n    <td class\\=\"tg-0pky\">Phenotype_A</td>\\n  </tr>\\n  <tr>\\n    <td class\\=\"tg-0pky\">Sample_2</td>\\n    <td class\\=\"tg-0pky\">Phenotype_A</td>\\n  </tr>\\n  <tr>\\n    <td class\\=\"tg-0pky\">Sample_3</td>\\n    <td class\\=\"tg-0pky\">Phenotype_B</td>\\n  </tr>\\n  <tr>\\n    <td class\\=\"tg-0pky\">Sample_4</td>\\n    <td class\\=\"tg-0pky\">Phenotype_B</td>\\n  </tr>\\n</tbody>\\n</table>\\n<br>\\nCovariates can be provided as additional \"Factor\" columns. The first factor column (the second column in the table) will always be used as the primary factor for the differential expression analysis.\np2_fileFormat=txt\np2_flag=--info\np2_name=Sample.Info\np2_numValues=0..1\np2_optional=on\np2_prefix=\np2_prefix_when_specified=\np2_type=java.io.File\np2_value=\np3_MODE=\np3_TYPE=TEXT\np3_default_value=SALMON\np3_description=Select the type of quantifications to be imported.\np3_fileFormat=\np3_flag=--type\np3_name=Quant.Type\np3_numValues=1..1\np3_optional=\np3_prefix=\np3_prefix_when_specified=\np3_type=java.lang.String\np3_value=RSEM\\=RSEM .genes.results;SALMON\\=Salmon .quant.sf;SAILFISH\\=Sailfish .quant.sf;KallistoH5\\=Kallisto .abundance.h5;KallistoTSV\\=Kallisto .abundance.tsv\np4_MODE=IN\np4_TYPE=FILE\np4_default_value=\np4_description=For Salmon/Sailfish/Kallisto data providing the transcriptome file used to quantify the data is <b>required</b> and must be provided in GTF/GFF3 format. This parameter is not utilized for RSEM data.<br/>(Supports gzip [.gz] files).<br/>\np4_fileFormat=gff3;gtf;gz\np4_flag=--txdb\np4_name=Transcriptome.Database\np4_numValues=0..1\np4_optional=on\np4_prefix=\np4_prefix_when_specified=\np4_type=java.io.File\np4_value=\np5_MODE=\np5_TYPE=TEXT\np5_default_value=TRUE\np5_description=Compute count normalization with DESeq2 and output the normalized matrix. This is the ideal output for compatibility with GSEA.\np5_fileFormat=\np5_flag=--counts\np5_name=Output.Normalized.Counts\np5_numValues=1..1\np5_optional=\np5_prefix=\np5_prefix_when_specified=\np5_type=java.lang.String\np5_value=TRUE\\=TRUE;FALSE\\=FALSE\np6_MODE=\np6_TYPE=TEXT\np6_default_value=TRUE\np6_description=Transcripts per million (TPM) quantifications will be extracted and output. This is the ideal output for compatibility with ssGSEA.\np6_fileFormat=\np6_flag=--tpm\np6_name=Output.TPM\np6_numValues=1..1\np6_optional=\np6_prefix=\np6_prefix_when_specified=\np6_type=java.lang.String\np6_value=TRUE\\=TRUE;FALSE\\=FALSE\np7_MODE=\np7_TYPE=TEXT\np7_default_value=Merged.Data\np7_description=The base name of the output file(s). File extensions will be added automatically.\np7_fileFormat=\np7_flag=--basename\np7_name=output.file.base\np7_numValues=1..1\np7_optional=\np7_prefix=\np7_prefix_when_specified=\np7_type=java.lang.String\np7_value=\np8_MODE=\np8_TYPE=TEXT\np8_default_value=FALSE\np8_description=If computing differentially expressed genes, by default, Log2(FC) will be calculated for the first Factor level vs the second Factor level (Phenotype_A vs. Phenotype_B). Setting Reverse.Sign \\= TRUE will reverse the direction of the calculation and Log2(FC) will be calculated for the second Factor level vs the first Factor level (Phenotype_B vs. Phenotype_A).\np8_fileFormat=\np8_flag=--reverse\np8_name=Reverse.Sign\np8_numValues=1..1\np8_optional=\np8_prefix=\np8_prefix_when_specified=\np8_type=java.lang.String\np8_value=TRUE\\=TRUE;FALSE\\=FALSE\np9_MODE=\np9_TYPE=TEXT\np9_default_value=TRUE\np9_description=If a Sample Info file and a Transcriptome Database have been provided, setting Annotate DEGs to TRUE will attempt to add gene symbols to the computed differential expression analysis.<br>Note\\: This does not affect the .GCT files which will still output only the underlying Gene IDs.\np9_fileFormat=\np9_flag=--annotate\np9_name=Annotate.DEGs\np9_numValues=1..1\np9_optional=\np9_prefix=\np9_prefix_when_specified=\np9_type=java.lang.String\np9_value=TRUE\\=TRUE;FALSE\\=FALSE\nprivacy=public\nquality=preproduction\ntaskDoc=tximport.DESeq2.pdf\ntaskType=differential expression\nuserid=acastanza\nversion="}]}
